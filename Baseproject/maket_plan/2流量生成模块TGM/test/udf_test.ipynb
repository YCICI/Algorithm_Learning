{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 获取测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/yuchuchu/machine/machine_algo/用户管理中心/2流量生成模块/'\n",
    "test_file = base_path + 'test0514.csv'\n",
    "test_data = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plan_pra(plan_level):\n",
    "    \"\"\"返回不同档位的参数值\n",
    "\n",
    "    Args:\n",
    "        plan_level: 方案档位, low, medium, high, max\n",
    "\n",
    "    Returns:\n",
    "        _type_: 返回月度clv阈值(month_clv_threshold), \n",
    "                返回年度clv阈值year_clv_threshold, \n",
    "                返回渠道放大系数channel_max_adjust, \n",
    "                返回渠道偏好系数channel_preference\n",
    "    \"\"\"\n",
    "    # 月度clv阈值\n",
    "    # 年度clv等级\n",
    "    # 渠道上限调节, 999表示取上限，1.5表示均值的1.5倍，1.2表示均值的1.2倍，等等\n",
    "    # 渠道倾向 channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "    \n",
    "    # plan_pra_dict = {'max' : [50, '1', 999, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'high' : [50, '1', 1.5, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'medium' : [50, '1', 1.2, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'low' : [50, '1', 1.0, [1.0, 1.0, 1.0, 1.0,1.0]]}\n",
    "    \n",
    "    if plan_level == 'max':\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 999  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    elif plan_level == 'high':\n",
    "        month_clv_threshold = 50\n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 1.5 \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    elif plan_level == 'medium':\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 1.2  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    else:\n",
    "        plan_level = 'lowv2'\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1' \n",
    "        channel_max_adjust = 1.0  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "\n",
    "    return month_clv_threshold, year_clv_threshold, channel_max_adjust, channel_preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.测试保量函数  \n",
    "* 测试样例测试保量函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BasicGuarantee(data):\n",
    "    com_login_cnt_last_month = data['com_login_cnt_last_month']\n",
    "    free_login_cnt_last_month = data['free_login_cnt_last_month']\n",
    "    strong_ctrl_login_cnt_last_month =  data['strong_ctrl_login_cnt_last_month']\n",
    "    normal_ctrl_login_cnt_last_month = data['normal_ctrl_login_cnt_last_month']\n",
    "    no_ctrl_login_cnt_last_month = data['no_ctrl_login_cnt_last_month']\n",
    "\n",
    "    # 新增 #\n",
    "    com_login_cnt_last_month = com_login_cnt_last_month if com_login_cnt_last_month>=0 else 0\n",
    "    free_login_cnt_last_month = free_login_cnt_last_month if free_login_cnt_last_month>=0 else 0\n",
    "    strong_ctrl_login_cnt_last_month = strong_ctrl_login_cnt_last_month if strong_ctrl_login_cnt_last_month>=0 else 0\n",
    "    normal_ctrl_login_cnt_last_month = normal_ctrl_login_cnt_last_month if normal_ctrl_login_cnt_last_month>=0 else 0\n",
    "    no_ctrl_login_cnt_last_month = no_ctrl_login_cnt_last_month if no_ctrl_login_cnt_last_month>=0 else 0\n",
    "    # 新增 #\n",
    "    \n",
    "    channel_guaranteed = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    \n",
    "    channel_guaranteed['com'] = max(math.ceil(com_login_cnt_last_month),0)\n",
    "    channel_guaranteed['free'] = max(math.ceil(free_login_cnt_last_month),0)\n",
    "    channel_guaranteed['strong_ctrl'] = max(math.ceil(strong_ctrl_login_cnt_last_month),0)\n",
    "    channel_guaranteed['normal_ctrl'] = max(math.ceil(normal_ctrl_login_cnt_last_month),0)\n",
    "    channel_guaranteed['no_ctrl'] = max(math.ceil(no_ctrl_login_cnt_last_month),0)\n",
    "    \n",
    "    return channel_guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_login_cnt_last_month</th>\n",
       "      <th>free_login_cnt_last_month</th>\n",
       "      <th>strong_ctrl_login_cnt_last_month</th>\n",
       "      <th>normal_ctrl_login_cnt_last_month</th>\n",
       "      <th>no_ctrl_login_cnt_last_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   com_login_cnt_last_month  free_login_cnt_last_month  \\\n",
       "0                       1.2                          3   \n",
       "1                       2.0                          4   \n",
       "\n",
       "   strong_ctrl_login_cnt_last_month  normal_ctrl_login_cnt_last_month  \\\n",
       "0                               1.0                                 3   \n",
       "1                               NaN                                 4   \n",
       "\n",
       "   no_ctrl_login_cnt_last_month  \n",
       "0                             3  \n",
       "1                             4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {'com_login_cnt_last_month': [1.2, 2],\n",
    "      'free_login_cnt_last_month': [3, 4],\n",
    "      'strong_ctrl_login_cnt_last_month': [1, None],\n",
    "      'normal_ctrl_login_cnt_last_month': [3, 4],\n",
    "      'no_ctrl_login_cnt_last_month': [3, 4]}\n",
    "test_data = pd.DataFrame(df)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'com': 2, 'free': 3, 'strong_ctrl': 1, 'normal_ctrl': 3, 'no_ctrl': 3},\n",
       " {'com': 2, 'free': 4, 'strong_ctrl': 0, 'normal_ctrl': 4, 'no_ctrl': 4}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['basic_result'] = test_data.apply(BasicGuarantee, \n",
    "                                            axis = 1, #逐行执行BasicGuarantee函数\n",
    "                                            )\n",
    "\n",
    "list(test_data['basic_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BasicGuarantee保量函数，没有处理异常值的能力，比如nan、9999以及负数，需要增加；\n",
    "\n",
    "2.测试业务补量函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BusinessRuleSupplement(basic_result, user_label,  year_clv_threshold, gmv_year, clv, month_clv_threshold, \n",
    "                           com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                           normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month, \n",
    "                           my_hash_code,month_hash):\n",
    "    \"\"\"根据用户逻辑进行方案调整\n",
    "\n",
    "    \"\"\"\n",
    "    channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "    businessrule_no_allocation_channel = []\n",
    "    businessrule_plan = basic_result\n",
    "    channel_businessrule_max = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    channel_businessrule_max_add = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    \n",
    "   \n",
    "    year_clv_threshold = 600.0\n",
    "\n",
    "    if user_label == 'A1':\n",
    "        # 根据业务逻辑调整渠道上限\n",
    "        com_adjust_pra = 1.2\n",
    "        hash_precent = 28\n",
    "        msg_add = 1\n",
    "    \n",
    "        # 京东可控置0 \n",
    "        businessrule_no_allocation_channel.append('normal_ctrl')\n",
    "\n",
    "        # 商业化渠道补量\n",
    "        # A1人群的商业化补量不超过20%\n",
    "        # 商业化在上月基础上调整1.2倍的抽样分配结果\n",
    "        com_adjust_day = sampling_supplement(channel_days = com_login_cnt_last_month,\n",
    "                                             adjust_day = com_adjust_pra * com_login_cnt_last_month, # 1.2\n",
    "                                             my_hash_code = my_hash_code)\n",
    "        \n",
    "        channel_businessrule_max['com'] = com_adjust_day  # A1人群的商业化补量不超过20%\n",
    "   \n",
    "        # 免费渠道补量\n",
    "        businessrule_plan['free'] +=  1 \n",
    "        channel_businessrule_max_add['free'] +=1\n",
    "        \n",
    "        # 短信渠道补量\n",
    "        if (my_hash_code <= hash_precent):\n",
    "            businessrule_plan['strong_ctrl'] += msg_add\n",
    "            channel_businessrule_max_add['strong_ctrl'] += msg_add     \n",
    "        else:\n",
    "            pass\n",
    "       \n",
    "    elif user_label == 'A2':\n",
    "        if clv <= month_clv_threshold:\n",
    "            businessrule_plan = basic_result\n",
    "            \n",
    "            # clv<50, 如果京东可控保量=0 则按月维度抽样（50%+1）\n",
    "            if businessrule_plan['normal_ctrl'] == 0  and month_hash < 50:\n",
    "                businessrule_plan['normal_ctrl'] +=1\n",
    "                channel_businessrule_max_add['normal_ctrl'] += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    elif user_label == 'B':\n",
    "        # 返回基础方案 所有渠道不分配\n",
    "        businessrule_plan =  basic_result \n",
    "        businessrule_no_allocation_channel += channel_type      \n",
    "\n",
    "    elif user_label == 'C':\n",
    "        if gmv_year <= year_clv_threshold:\n",
    "            # 返回基础方案 所有渠道不分配\n",
    "            businessrule_plan = basic_result\n",
    "            businessrule_no_allocation_channel += channel_type \n",
    "        else:\n",
    "            businessrule_plan['normal_ctrl'] = min(20, 1.5 * normal_ctrl_login_cnt_last_month, businessrule_plan['normal_ctrl'])\n",
    "    \n",
    "    return businessrule_plan, businessrule_no_allocation_channel, channel_businessrule_max, channel_businessrule_max_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ed1da0cae66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-05-14'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "day1_ago_runday = datetime.datetime.strftime(datetime.datetime.strptime(run_day,'%Y-%M-%d') - timedelta(days=1),'%Y-%M-%d')\n",
    "day1_ago_runday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-15\n",
      "0\n",
      ">>>>>>>>>> 进行首日分配\n",
      "2022-05-16\n",
      "1\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-17\n",
      "2\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-18\n",
      "3\n",
      ">>>>>>>>>> 进行高活用户 渠道内调整\n",
      "2022-05-19\n",
      "4\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-20\n",
      "5\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-21\n",
      "6\n",
      ">>>>>>>>>> 进行高活用户 渠道内调整\n",
      "2022-05-22\n",
      "7\n",
      ">>>>>>>>>> 进行高活用户 渠道间调整\n",
      "2022-05-23\n",
      "8\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-24\n",
      "9\n",
      ">>>>>>>>>> 进行高活用户 渠道内调整\n",
      "2022-05-25\n",
      "10\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-26\n",
      "11\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-27\n",
      "12\n",
      ">>>>>>>>>> 进行高活用户 渠道内调整\n",
      "2022-05-28\n",
      "13\n",
      ">>>>>>>>>> 进行高活用户 渠道间调整\n",
      "2022-05-29\n",
      "14\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n",
      "2022-05-30\n",
      "15\n",
      ">>>>>>>>>> 进行高活用户 渠道内调整\n",
      "2022-05-31\n",
      "16\n",
      ">>>>>>>>>> 非首日，非调控期，取昨日分区减去昨日已完成\n"
     ]
    }
   ],
   "source": [
    "# 测试5月选择的分配方式是否合理\n",
    "\n",
    "\n",
    "\n",
    "#run_day = datetime.datetime.strptime(run_day,'%Y-%M-%d')\n",
    "for num in range(17):\n",
    "    run_day = datetime.datetime.strftime(first_allocation_day+ timedelta(days=num),'%Y-%M-%d')\n",
    "    print(run_day)\n",
    "    delta_day = (datetime.datetime.strptime(run_day, '%Y-%M-%d')-first_allocation_day).days\n",
    "    print(delta_day)\n",
    "    \n",
    "    if delta_day == 0:\n",
    "        #  首日分配\n",
    "        print(\">\"*10,\"进行首日分配\") \n",
    "\n",
    "    elif delta_day%3 == 0:\n",
    "        # 3日-高活 渠道内调整 执行首日分配算法\n",
    "        print(\">\"*10,\"进行高活用户 渠道内调整\") \n",
    "\n",
    "\n",
    "    elif (delta_day==7) or ( (delta_day > 7) & ((delta_day-7)%6==0)):\n",
    "        # 7日 监控期，然后高活6d周期 渠道间调整\n",
    "        print(\">\"*10,\"进行高活用户 渠道间调整\") \n",
    "\n",
    "\n",
    "    elif delta_day%3 > 0:\n",
    "        # 非首日 非调控期 取昨日分区减去昨日已完成\n",
    "        print(\">\"*10,\"非首日，非调控期，取昨日分区减去昨日已完成\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 测试渠道间调整函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "com\n",
      "free\n",
      "up\n",
      "strong_ctrl\n",
      "up\n",
      "normal_ctrl\n",
      "down\n",
      "no_ctrl\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "this_month_shengu_day = 4\n",
    "between_channel_adjust = 1\n",
    "\n",
    "channel_max_login_days = {'com' :10,\n",
    "                              'free':10,\n",
    "                              'strong_ctrl':10,\n",
    "                              'normal_ctrl':10,\n",
    "                              'no_ctrl':10}\n",
    "\n",
    "channel_login_cnt_mtd = {'com' :5,\n",
    "                            'free':9,\n",
    "                            'strong_ctrl':9,\n",
    "                            'normal_ctrl':1,\n",
    "                            'no_ctrl':2}\n",
    "\n",
    "\n",
    "if between_channel_adjust==1:\n",
    "    \n",
    "    \n",
    "    for adjust_channel in channel_max_login_days:\n",
    "        print(adjust_channel)\n",
    "        if channel_max_login_days[adjust_channel] - channel_login_cnt_mtd[adjust_channel]<=2:\n",
    "            print(\"up\")\n",
    "            channel_max_login_days[adjust_channel] = max(math.ceil(channel_max_login_days[adjust_channel] * 1.1),channel_login_cnt_mtd[adjust_channel]+2)\n",
    "        \n",
    "        elif channel_max_login_days[adjust_channel] - channel_login_cnt_mtd[adjust_channel] >= this_month_shengu_day*1.5 :\n",
    "            print(\"down\")\n",
    "            channel_max_login_days[adjust_channel] = max(math.ceil(channel_max_login_days[adjust_channel] * 0.9),math.ceil(this_month_shengu_day*1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'com': 10, 'free': 11, 'strong_ctrl': 11, 'normal_ctrl': 9, 'no_ctrl': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_max_login_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date: 2022-04-20\n",
    "# updta: 2022-05-10\n",
    "# author: niujianxing,yuchuchu\n",
    "\n",
    "\"\"\"\n",
    "用户管理中心-算法输出中间表\n",
    "\"\"\"\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# old_time放在程序运行开始的地方\n",
    "old_time = time.time()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, MapType\n",
    "from pyspark.sql.functions import col, lit, array\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# import os\n",
    "# os.environ['PYSPARK_PYTHON'] = \"/usr/local/anaconda3/bin/python3.6\"\n",
    "\n",
    "\n",
    "spark = (SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"test-dockerlinuxcontainer\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"1000\") \\\n",
    "    .getOrCreate())\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\", \"true\")\n",
    "spark.conf.set(\"hive.exec.dynamic.partition\", \"true\")\n",
    "spark.conf.set(\"hive.exec.dynamic.partition.mode\", \"true\")\n",
    "spark.sql(\"\"\"ADD JAR hdfs://ns1009/user/mart_jypt/mart_jypt_usr_grow/liuyang266/hiveudf-1.0-SNAPSHOT-jar-with-dependencies.jar\"\"\")\n",
    "spark.sql(\"\"\"CREATE TEMPORARY FUNCTION hash_sub AS 'com.jd.bdptools.ly.HashMonthly'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_data(part_dt,part_month):\n",
    "    \"\"\"获取sql文件\n",
    "\n",
    "    Args:\n",
    "        part_dt (_type_): 表格分区\n",
    "\n",
    "    Returns:\n",
    "        _type_: 返回执行sql\n",
    "    \"\"\"\n",
    "    used_sql = \"\"\"\n",
    "    SELECT\n",
    "        user.dt,\n",
    "        user.user_log_acct,\n",
    "        user.my_hash_code,\n",
    "        user.month_hash,\n",
    "        --格子粒度\n",
    "        user.user_life_cycle_type_1st,\n",
    "        user.model_a_1st,\n",
    "        user.model_b_1st,\n",
    "        user.goal_group_1st,\n",
    "        user.annual_clv_1st,\n",
    "        user.grid_name_1st,\n",
    "        user.area_b_1st,\n",
    "\n",
    "        --格子粒度2\n",
    "        user.user_life_cycle_type,\n",
    "        user.model_a,\n",
    "        user.model_b,\n",
    "        user.model_c,\n",
    "        user.model_l,\n",
    "        user.priority_type,\n",
    "        \n",
    "        user.is_malice_user,\n",
    "        \n",
    "        -- 目标登录次数\n",
    "        COALESCE(grid.lower_lift_login_cnt,0) as lower_lift_login_cnt,\n",
    "        COALESCE(user.natural_pred_login_cnt_rest,0) as natural_pred_login_cnt_rest,\n",
    "        COALESCE(user.natural_pred_login_cnt_n30d,0) as natural_pred_login_cnt_n30d,\n",
    "        \n",
    "        -- 自然相关\n",
    "        COALESCE(user.natural_login_cnt_last_month,0) as natural_login_cnt_last_month,\n",
    "        COALESCE(grid.natural_max_login_cnt,0) as natural_max_login_cnt,\n",
    "        COALESCE(grid.natural_login_cnt_per_month,0) as natural_login_cnt_per_month,\n",
    "        COALESCE(grid.natural_quality_coeff,0) as natural_quality_coeff,\n",
    "        COALESCE(grid.natural_login_cnt_per_dau,0) as natural_login_cnt_per_dau,\n",
    "\n",
    "        --当月引流登端次数\n",
    "        COALESCE(user.login_cnt_mtd,0) as login_cnt_mtd,\n",
    "        user.natural_login_cnt_mtd,\n",
    "        user.com_login_cnt_mtd,\n",
    "        user.free_login_cnt_mtd,\n",
    "        user.strong_ctrl_login_cnt_mtd,\n",
    "        user.normal_ctrl_login_cnt_mtd,\n",
    "        user.no_ctrl_login_cnt_mtd,\n",
    "\n",
    "        --渠道是否可达\n",
    "        user.is_acce_by_com,\n",
    "        user.is_acce_by_free,\n",
    "        user.is_acce_by_strong_ctrl,\n",
    "        user.is_acce_by_normal_ctrl,\n",
    "        user.is_acce_by_no_ctrl,\n",
    "\n",
    "        --clv\n",
    "        user.clv_pred_1m,\n",
    "        user.clv_mtd,\n",
    "\n",
    "        --上月人均干预次数\n",
    "        COALESCE(login_cnt_last_month,0)         as login_cnt_last_month,\n",
    "        COALESCE(com_login_cnt_last_month,0) as com_login_cnt_last_month,\n",
    "        COALESCE(free_login_cnt_last_month,0) as free_login_cnt_last_month,\n",
    "        COALESCE(strong_ctrl_login_cnt_last_month,0) as strong_ctrl_login_cnt_last_month,\n",
    "        COALESCE(normal_ctrl_login_cnt_last_month,0) as normal_ctrl_login_cnt_last_month,\n",
    "        COALESCE(no_ctrl_login_cnt_last_month,0) as no_ctrl_login_cnt_last_month,\n",
    "        \n",
    "        --gmv\n",
    "        cast(COALESCE(gmv_year,0.0) as double)  as gmv_year,\n",
    "        cast(COALESCE(last_year_gmv,0.0) as double) as last_year_gmv,\n",
    "                \n",
    "        --渠道上限\n",
    "        COALESCE(grid.com_max_login_count,2) as com_max_login_count,\n",
    "        COALESCE(grid.free_max_login_count,2) as free_max_login_count,\n",
    "        COALESCE(grid.strong_ctrl_max_login_count,0) as strong_ctrl_max_login_count,\n",
    "        COALESCE(grid.normal_ctrl_max_login_count,0) as normal_ctrl_max_login_count,\n",
    "        COALESCE(grid.no_ctrl_max_login_count,0) as no_ctrl_max_login_count,\n",
    "\n",
    "        --渠道成本\n",
    "        COALESCE(grid.com_login_cost,-3) as com_login_cost,\n",
    "        COALESCE(grid.free_login_cost,0) as free_login_cost,\n",
    "        COALESCE(grid.no_ctrl_login_cost,0.9) as no_ctrl_login_cost,\n",
    "        COALESCE(grid.strong_ctrl_login_cost,0.8) as strong_ctrl_login_cost,\n",
    "        COALESCE(grid.normal_login_cost,0.6) as normal_login_cost,\n",
    "\n",
    "        --渠道成本质量因子\n",
    "        com_quality_coeff,\n",
    "        free_quality_coeff,\n",
    "        strong_ctrl_quality_coeff,\n",
    "        normal_ctrl_quality_coeff,\n",
    "        no_ctrl_quality_coeff,\n",
    "\n",
    "\n",
    "        --渠道dau映射\n",
    "        COALESCE(grid.com_login_cnt_per_dau,0.5)            as com_login_cnt_per_dau,\n",
    "        COALESCE(grid.free_login_cnt_per_dau,0.5)           as free_login_cnt_per_dau,\n",
    "        COALESCE(grid.no_ctrl_login_cnt_per_dau,0.5)        as no_ctrl_login_cnt_per_dau,\n",
    "        COALESCE(grid.strong_ctrl_login_cnt_per_dau,0.5)    as strong_ctrl_login_cnt_per_dau,\n",
    "        COALESCE(grid.normal_ctrl_login_cnt_per_dau,0.5)         as normal_ctrl_login_cnt_per_dau,\n",
    "        grid.total_login_dau_ratio,\n",
    "\n",
    "        -- 格子用户数& 渠道月均引流 for 保量\n",
    "        case when grid.user_cnt <-100 then 1 else grid.user_cnt end as user_cnt,\n",
    "        case when grid.com_login_cnt_per_month <-100 then 1 else grid.com_login_cnt_per_month end as com_login_cnt_per_month,\n",
    "        case when grid.free_login_cnt_per_month <-100 then 1 else grid.free_login_cnt_per_month end as free_login_cnt_per_month,\n",
    "        case when grid.no_ctrl_login_cnt_per_month <-100 then 1 else grid.no_ctrl_login_cnt_per_month end as no_ctrl_login_cnt_per_month,\n",
    "        case when grid.strong_ctrl_login_cnt_per_month <-100 then 1 else grid.strong_ctrl_login_cnt_per_month end as strong_ctrl_login_cnt_per_month,\n",
    "        case when grid.normal_ctrl_login_cnt_per_month <-100 then 1 else grid.normal_ctrl_login_cnt_per_month end as normal_ctrl_login_cnt_per_month,\n",
    "\n",
    "        -- 上月人均引流次数（按格子统计）\n",
    "        case when grid.com_base_cnt         <-100 then 0 else grid.com_base_cnt end as         com_base_cnt,\n",
    "        case when grid.free_base_cnt        <-100 then 0 else grid.free_base_cnt end as        free_base_cnt,\n",
    "        case when grid.no_ctrl_base_cnt     <-100 then 0 else grid.no_ctrl_base_cnt end as     no_ctrl_base_cnt,\n",
    "        case when grid.strong_ctrl_base_cnt  <-100 then 0 else grid.strong_ctrl_base_cnt end as strong_ctrl_base_cnt,\n",
    "        case when grid.normal_ctrl_base_cnt <-100 then 0 else grid.normal_ctrl_base_cnt end as normal_ctrl_base_cnt\n",
    "\n",
    "    FROM\n",
    "    (\n",
    "    SELECT\n",
    "        dt,\n",
    "        user_log_acct,\n",
    "        hash_sub(concat(lower(trim(user_log_acct)),'{part_dt}')) as my_hash_code,\n",
    "        hash_sub(concat(lower(trim(user_log_acct)),'{part_month}')) as month_hash,\n",
    "        --格子粒度\n",
    "        user_life_cycle_type_1st,\n",
    "        model_a_1st,\n",
    "        model_b_1st,\n",
    "        goal_group_1st,\n",
    "        case when annual_clv_1st is null then '0' else annual_clv_1st end as annual_clv_1st,\n",
    "        grid_name_1st,\n",
    "        area_b_1st,\n",
    "\n",
    "        user_life_cycle_type,\n",
    "        model_a,\n",
    "        model_b,\n",
    "        model_c,\n",
    "        model_l,\n",
    "        priority_type,\n",
    "        is_malice_user,\n",
    "        \n",
    "        -- 自然登录\n",
    "        case when natural_pred_login_cnt_rest<-100 then 0\n",
    "             else natural_pred_login_cnt_rest end as natural_pred_login_cnt_rest,\n",
    "        case when natural_pred_login_cnt_n30d<-100 then 0\n",
    "             else natural_pred_login_cnt_n30d end as natural_pred_login_cnt_n30d,\n",
    "\n",
    "        \n",
    "        --当月引流登端次数\n",
    "        case when login_cnt_mtd<-100 then 0\n",
    "             else login_cnt_mtd end as login_cnt_mtd,\n",
    "        case when natural_login_cnt_mtd <-100 then 0 else natural_login_cnt_mtd end as natural_login_cnt_mtd,\n",
    "        case when com_login_cnt_mtd <-100 then 0 else com_login_cnt_mtd end as com_login_cnt_mtd,\n",
    "        case when free_login_cnt_mtd <-100 then 0 else free_login_cnt_mtd end as free_login_cnt_mtd,\n",
    "        case when strong_ctrl_login_cnt_mtd <-100 then 0 else strong_ctrl_login_cnt_mtd end as strong_ctrl_login_cnt_mtd,\n",
    "        case when normal_ctrl_login_cnt_mtd <-100 then 0 else normal_ctrl_login_cnt_mtd end as normal_ctrl_login_cnt_mtd,\n",
    "        case when no_ctrl_login_cnt_mtd <-100 then 0 else no_ctrl_login_cnt_mtd end as no_ctrl_login_cnt_mtd,\n",
    "        \n",
    "        --渠道是否可达\n",
    "        case when is_acce_by_com <-100 then 1 else is_acce_by_com end as is_acce_by_com,\n",
    "        case when is_acce_by_free <-100 then 1 else is_acce_by_free end as is_acce_by_free,\n",
    "        case when is_acce_by_strong_ctrl <-100 then 1 else is_acce_by_strong_ctrl end as is_acce_by_strong_ctrl,\n",
    "        case when is_acce_by_normal_ctrl <-100 then 1 else is_acce_by_normal_ctrl end as is_acce_by_normal_ctrl,\n",
    "        case when is_acce_by_no_ctrl <-100 then 1 else is_acce_by_no_ctrl end as is_acce_by_no_ctrl,\n",
    "        \n",
    "        --clv\n",
    "        case when clv_pred_1m <-100 then 0 else clv_pred_1m end as clv_pred_1m, --0\n",
    "        case when clv_mtd <-100 then 0 else clv_mtd end as clv_mtd, --0\n",
    "\n",
    "        --上月人均干预次数\n",
    "        case when login_cnt_last_month <-100 then 0 else login_cnt_last_month end                         as login_cnt_last_month,\n",
    "        case when natural_login_cnt_last_month <-100 then 0 else natural_login_cnt_last_month end         as natural_login_cnt_last_month,\n",
    "        case when com_login_cnt_last_month <-100 then 0 else com_login_cnt_last_month end                 as com_login_cnt_last_month,\n",
    "        case when free_login_cnt_last_month <-100 then 0 else free_login_cnt_last_month end               as free_login_cnt_last_month,\n",
    "        case when strong_ctrl_login_cnt_last_month<-100 then 0 else strong_ctrl_login_cnt_last_month end  as strong_ctrl_login_cnt_last_month,\n",
    "        case when normal_ctrl_login_cnt_last_month<-100 then 0 else normal_ctrl_login_cnt_last_month end  as normal_ctrl_login_cnt_last_month,\n",
    "        case when no_ctrl_login_cnt_last_month<-100 then 0 else no_ctrl_login_cnt_last_month end          as no_ctrl_login_cnt_last_month,\n",
    "        case when clv_year<-100 then 0 else clv_year           end as gmv_year,\n",
    "        case when last_year_gmv<-100 then 0 else last_year_gmv end as last_year_gmv\n",
    "        \n",
    "    FROM\n",
    "    app.app_yhzz_umc_unit_user\n",
    "    WHERE\n",
    "    dt = '{part_dt}'\n",
    "    and priority_type in('A1','A2' )\n",
    "    limit 100\n",
    "   -- and user_log_acct in (select user_log_acct from app.app_yhzz_umc_algo_pin_interim WHERE dt = '2022-05-01' and dp='low')\n",
    "    )user\n",
    "\n",
    "    JOIN\n",
    "\n",
    "    (\n",
    "    SELECT\n",
    "        grid_name_1st,\n",
    "        \n",
    "        --阶跃下限\n",
    "        max(case when lower_lift_login_cnt <-100 then 0 else lower_lift_login_cnt end) as lower_lift_login_cnt,\n",
    "             \n",
    "\n",
    "        --渠道上限\n",
    "        max(case when natural_max_login_cnt <-100 then 2 else natural_max_login_cnt end )  as natural_max_login_cnt,\n",
    "        max(case when com_max_login_cnt <-100 then 2 else com_max_login_cnt end )  as com_max_login_count,\n",
    "        max(case when free_max_login_cnt <-100 then 2 else free_max_login_cnt end ) as free_max_login_count,\n",
    "        max(case when strong_ctrl_max_login_count <-100 then 0 else strong_ctrl_max_login_count end ) as strong_ctrl_max_login_count,\n",
    "        max(case when normal_ctrl_max_login_count <-100 then 0 else normal_ctrl_max_login_count end ) as normal_ctrl_max_login_count,\n",
    "        max(case when no_ctrl_max_login_count <-100 then 0 else no_ctrl_max_login_count end ) as no_ctrl_max_login_count,\n",
    "        \n",
    "        --渠道成本\n",
    "        max(case when natural_login_cost <-100 then -3 else natural_login_cost end ) as  natural_login_cost,\n",
    "        max(case when com_login_cost <-100 then -3 else (-1 * com_login_cost) end ) as  com_login_cost,\n",
    "        max(case when free_login_cost <-100 then 0 else free_login_cost end ) as free_login_cost,\n",
    "        max(case when no_ctrl_login_cost <-100 then 0.8 else no_ctrl_login_cost end ) as no_ctrl_login_cost,\n",
    "        max(case when strong_ctrl_login_cost <-100 then 0.6 else strong_ctrl_login_cost end ) as strong_ctrl_login_cost,\n",
    "        max(case when normal_login_cost <-100 then 0.9 else normal_login_cost end ) as normal_login_cost,\n",
    "\n",
    "        --渠道成本质量因子\n",
    "        \n",
    "        max(case when natural_quality_coeff <-100 then 1 else natural_quality_coeff end ) as natural_quality_coeff,\n",
    "        max(case when com_quality_coeff <-100 then 0.28 else com_quality_coeff end ) as com_quality_coeff,\n",
    "        max(case when free_quality_coeff <-100 then 0.64 else free_quality_coeff end ) as free_quality_coeff,\n",
    "        max(case when strong_ctrl_quality_coeff <-100 then 2.2 else strong_ctrl_quality_coeff end ) as strong_ctrl_quality_coeff,\n",
    "        max(case when normal_ctrl_quality_coeff <-100 then 0.25 else normal_ctrl_quality_coeff end ) as normal_ctrl_quality_coeff,\n",
    "        max(case when no_ctrl_quality_coeff <-100 then 0.88 else no_ctrl_quality_coeff end ) as no_ctrl_quality_coeff,\n",
    "        \n",
    "        --渠道dau映射\n",
    "        \n",
    "        max(case when natural_login_cnt_per_dau <-100 then 0.478 else natural_login_cnt_per_dau end ) as natural_login_cnt_per_dau,\n",
    "        max(case when com_login_cnt_per_dau <-100 then 0.460 else com_login_cnt_per_dau end ) as com_login_cnt_per_dau,\n",
    "        max(case when free_login_cnt_per_dau <-100 then 0.462 else free_login_cnt_per_dau end ) as free_login_cnt_per_dau,\n",
    "        max(case when no_ctrl_login_cnt_per_dau <-100 then 0.434 else no_ctrl_login_cnt_per_dau end ) as no_ctrl_login_cnt_per_dau,\n",
    "        max(case when strong_ctrl_login_cnt_per_dau <-100 then 0.596 else strong_ctrl_login_cnt_per_dau end ) as strong_ctrl_login_cnt_per_dau,\n",
    "        max(case when normal_login_cnt_per_dau <-100 then 0.507 else normal_login_cnt_per_dau end ) as normal_ctrl_login_cnt_per_dau,\n",
    "         --dau映射\n",
    "        max(case when total_login_dau_ratio <-100 then 0.8 else total_login_dau_ratio end) as total_login_dau_ratio,\n",
    "\n",
    "        -- 格子用户数& 渠道月均引流 for 保量\n",
    "        max(user_cnt) as user_cnt,\n",
    "        max(natural_login_cnt_per_month) as natural_login_cnt_per_month,\n",
    "        max(com_login_cnt_per_month) as com_login_cnt_per_month,\n",
    "        max(free_login_cnt_per_month) as free_login_cnt_per_month,\n",
    "        max(no_ctrl_login_cnt_per_month) as no_ctrl_login_cnt_per_month,\n",
    "        max(strong_ctrl_login_cnt_per_month) as strong_ctrl_login_cnt_per_month,\n",
    "        max(normal_ctrl_login_cnt_per_month) as normal_ctrl_login_cnt_per_month,\n",
    "        max(cast(natural_login_cnt_per_month as  double)/user_cnt)         as natural_base_cnt,\n",
    "        max(cast(com_login_cnt_per_month as  double)/user_cnt)         as com_base_cnt,\n",
    "        max(cast(free_login_cnt_per_month as  double)/user_cnt)        as free_base_cnt,\n",
    "        max(cast(no_ctrl_login_cnt_per_month as  double)/user_cnt)     as no_ctrl_base_cnt,\n",
    "        max(cast(strong_ctrl_login_cnt_per_month as  double)/user_cnt) as strong_ctrl_base_cnt,\n",
    "        max(cast(normal_ctrl_login_cnt_per_month as  double)/user_cnt) as normal_ctrl_base_cnt\n",
    "\n",
    "        \n",
    "    FROM\n",
    "        app.app_yhzz_umc_unit_grid\n",
    "    WHERE\n",
    "        dt = '{part_dt}'\n",
    "        AND grid_name_1st is not null\n",
    "        AND is_grid_valid =1 \n",
    "        group by\n",
    "        grid_name_1st\n",
    "    )grid on user.grid_name_1st = grid.grid_name_1st\n",
    "\n",
    "    \"\"\".format(part_dt = part_dt,part_month = part_month)\n",
    "    print(\"used sql\", used_sql)\n",
    "    data = spark.sql(used_sql)\n",
    "    data.cache()\n",
    "    # print(\"data columns\", data.columns)\n",
    "    print(\"data dtypes\", data.dtypes)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used sql \n",
      "    SELECT\n",
      "        user.dt,\n",
      "        user.user_log_acct,\n",
      "        user.my_hash_code,\n",
      "        user.month_hash,\n",
      "        --格子粒度\n",
      "        user.user_life_cycle_type_1st,\n",
      "        user.model_a_1st,\n",
      "        user.model_b_1st,\n",
      "        user.goal_group_1st,\n",
      "        user.annual_clv_1st,\n",
      "        user.grid_name_1st,\n",
      "        user.area_b_1st,\n",
      "\n",
      "        --格子粒度2\n",
      "        user.user_life_cycle_type,\n",
      "        user.model_a,\n",
      "        user.model_b,\n",
      "        user.model_c,\n",
      "        user.model_l,\n",
      "        user.priority_type,\n",
      "        \n",
      "        user.is_malice_user,\n",
      "        \n",
      "        -- 目标登录次数\n",
      "        COALESCE(grid.lower_lift_login_cnt,0) as lower_lift_login_cnt,\n",
      "        COALESCE(user.natural_pred_login_cnt_rest,0) as natural_pred_login_cnt_rest,\n",
      "        COALESCE(user.natural_pred_login_cnt_n30d,0) as natural_pred_login_cnt_n30d,\n",
      "        \n",
      "        -- 自然相关\n",
      "        COALESCE(user.natural_login_cnt_last_month,0) as natural_login_cnt_last_month,\n",
      "        COALESCE(grid.natural_max_login_cnt,0) as natural_max_login_cnt,\n",
      "        COALESCE(grid.natural_login_cnt_per_month,0) as natural_login_cnt_per_month,\n",
      "        COALESCE(grid.natural_quality_coeff,0) as natural_quality_coeff,\n",
      "        COALESCE(grid.natural_login_cnt_per_dau,0) as natural_login_cnt_per_dau,\n",
      "\n",
      "        --当月引流登端次数\n",
      "        COALESCE(user.login_cnt_mtd,0) as login_cnt_mtd,\n",
      "        user.natural_login_cnt_mtd,\n",
      "        user.com_login_cnt_mtd,\n",
      "        user.free_login_cnt_mtd,\n",
      "        user.strong_ctrl_login_cnt_mtd,\n",
      "        user.normal_ctrl_login_cnt_mtd,\n",
      "        user.no_ctrl_login_cnt_mtd,\n",
      "\n",
      "        --渠道是否可达\n",
      "        user.is_acce_by_com,\n",
      "        user.is_acce_by_free,\n",
      "        user.is_acce_by_strong_ctrl,\n",
      "        user.is_acce_by_normal_ctrl,\n",
      "        user.is_acce_by_no_ctrl,\n",
      "\n",
      "        --clv\n",
      "        user.clv_pred_1m,\n",
      "        user.clv_mtd,\n",
      "\n",
      "        --上月人均干预次数\n",
      "        COALESCE(login_cnt_last_month,0)         as login_cnt_last_month,\n",
      "        COALESCE(com_login_cnt_last_month,0) as com_login_cnt_last_month,\n",
      "        COALESCE(free_login_cnt_last_month,0) as free_login_cnt_last_month,\n",
      "        COALESCE(strong_ctrl_login_cnt_last_month,0) as strong_ctrl_login_cnt_last_month,\n",
      "        COALESCE(normal_ctrl_login_cnt_last_month,0) as normal_ctrl_login_cnt_last_month,\n",
      "        COALESCE(no_ctrl_login_cnt_last_month,0) as no_ctrl_login_cnt_last_month,\n",
      "        \n",
      "        --gmv\n",
      "        cast(COALESCE(gmv_year,0.0) as double)  as gmv_year,\n",
      "        cast(COALESCE(last_year_gmv,0.0) as double) as last_year_gmv,\n",
      "                \n",
      "        --渠道上限\n",
      "        COALESCE(grid.com_max_login_count,2) as com_max_login_count,\n",
      "        COALESCE(grid.free_max_login_count,2) as free_max_login_count,\n",
      "        COALESCE(grid.strong_ctrl_max_login_count,0) as strong_ctrl_max_login_count,\n",
      "        COALESCE(grid.normal_ctrl_max_login_count,0) as normal_ctrl_max_login_count,\n",
      "        COALESCE(grid.no_ctrl_max_login_count,0) as no_ctrl_max_login_count,\n",
      "\n",
      "        --渠道成本\n",
      "        COALESCE(grid.com_login_cost,-3) as com_login_cost,\n",
      "        COALESCE(grid.free_login_cost,0) as free_login_cost,\n",
      "        COALESCE(grid.no_ctrl_login_cost,0.9) as no_ctrl_login_cost,\n",
      "        COALESCE(grid.strong_ctrl_login_cost,0.8) as strong_ctrl_login_cost,\n",
      "        COALESCE(grid.normal_login_cost,0.6) as normal_login_cost,\n",
      "\n",
      "        --渠道成本质量因子\n",
      "        com_quality_coeff,\n",
      "        free_quality_coeff,\n",
      "        strong_ctrl_quality_coeff,\n",
      "        normal_ctrl_quality_coeff,\n",
      "        no_ctrl_quality_coeff,\n",
      "\n",
      "\n",
      "        --渠道dau映射\n",
      "        COALESCE(grid.com_login_cnt_per_dau,0.5)            as com_login_cnt_per_dau,\n",
      "        COALESCE(grid.free_login_cnt_per_dau,0.5)           as free_login_cnt_per_dau,\n",
      "        COALESCE(grid.no_ctrl_login_cnt_per_dau,0.5)        as no_ctrl_login_cnt_per_dau,\n",
      "        COALESCE(grid.strong_ctrl_login_cnt_per_dau,0.5)    as strong_ctrl_login_cnt_per_dau,\n",
      "        COALESCE(grid.normal_ctrl_login_cnt_per_dau,0.5)         as normal_ctrl_login_cnt_per_dau,\n",
      "        grid.total_login_dau_ratio,\n",
      "\n",
      "        -- 格子用户数& 渠道月均引流 for 保量\n",
      "        case when grid.user_cnt <-100 then 1 else grid.user_cnt end as user_cnt,\n",
      "        case when grid.com_login_cnt_per_month <-100 then 1 else grid.com_login_cnt_per_month end as com_login_cnt_per_month,\n",
      "        case when grid.free_login_cnt_per_month <-100 then 1 else grid.free_login_cnt_per_month end as free_login_cnt_per_month,\n",
      "        case when grid.no_ctrl_login_cnt_per_month <-100 then 1 else grid.no_ctrl_login_cnt_per_month end as no_ctrl_login_cnt_per_month,\n",
      "        case when grid.strong_ctrl_login_cnt_per_month <-100 then 1 else grid.strong_ctrl_login_cnt_per_month end as strong_ctrl_login_cnt_per_month,\n",
      "        case when grid.normal_ctrl_login_cnt_per_month <-100 then 1 else grid.normal_ctrl_login_cnt_per_month end as normal_ctrl_login_cnt_per_month,\n",
      "\n",
      "        -- 上月人均引流次数（按格子统计）\n",
      "        case when grid.com_base_cnt         <-100 then 0 else grid.com_base_cnt end as         com_base_cnt,\n",
      "        case when grid.free_base_cnt        <-100 then 0 else grid.free_base_cnt end as        free_base_cnt,\n",
      "        case when grid.no_ctrl_base_cnt     <-100 then 0 else grid.no_ctrl_base_cnt end as     no_ctrl_base_cnt,\n",
      "        case when grid.strong_ctrl_base_cnt  <-100 then 0 else grid.strong_ctrl_base_cnt end as strong_ctrl_base_cnt,\n",
      "        case when grid.normal_ctrl_base_cnt <-100 then 0 else grid.normal_ctrl_base_cnt end as normal_ctrl_base_cnt\n",
      "\n",
      "    FROM\n",
      "    (\n",
      "    SELECT\n",
      "        dt,\n",
      "        user_log_acct,\n",
      "        hash_sub(concat(lower(trim(user_log_acct)),'2022-05-20')) as my_hash_code,\n",
      "        hash_sub(concat(lower(trim(user_log_acct)),'5')) as month_hash,\n",
      "        --格子粒度\n",
      "        user_life_cycle_type_1st,\n",
      "        model_a_1st,\n",
      "        model_b_1st,\n",
      "        goal_group_1st,\n",
      "        case when annual_clv_1st is null then '0' else annual_clv_1st end as annual_clv_1st,\n",
      "        grid_name_1st,\n",
      "        area_b_1st,\n",
      "\n",
      "        user_life_cycle_type,\n",
      "        model_a,\n",
      "        model_b,\n",
      "        model_c,\n",
      "        model_l,\n",
      "        priority_type,\n",
      "        is_malice_user,\n",
      "        \n",
      "        -- 自然登录\n",
      "        case when natural_pred_login_cnt_rest<-100 then 0\n",
      "             else natural_pred_login_cnt_rest end as natural_pred_login_cnt_rest,\n",
      "        case when natural_pred_login_cnt_n30d<-100 then 0\n",
      "             else natural_pred_login_cnt_n30d end as natural_pred_login_cnt_n30d,\n",
      "\n",
      "        \n",
      "        --当月引流登端次数\n",
      "        case when login_cnt_mtd<-100 then 0\n",
      "             else login_cnt_mtd end as login_cnt_mtd,\n",
      "        case when natural_login_cnt_mtd <-100 then 0 else natural_login_cnt_mtd end as natural_login_cnt_mtd,\n",
      "        case when com_login_cnt_mtd <-100 then 0 else com_login_cnt_mtd end as com_login_cnt_mtd,\n",
      "        case when free_login_cnt_mtd <-100 then 0 else free_login_cnt_mtd end as free_login_cnt_mtd,\n",
      "        case when strong_ctrl_login_cnt_mtd <-100 then 0 else strong_ctrl_login_cnt_mtd end as strong_ctrl_login_cnt_mtd,\n",
      "        case when normal_ctrl_login_cnt_mtd <-100 then 0 else normal_ctrl_login_cnt_mtd end as normal_ctrl_login_cnt_mtd,\n",
      "        case when no_ctrl_login_cnt_mtd <-100 then 0 else no_ctrl_login_cnt_mtd end as no_ctrl_login_cnt_mtd,\n",
      "        \n",
      "        --渠道是否可达\n",
      "        case when is_acce_by_com <-100 then 1 else is_acce_by_com end as is_acce_by_com,\n",
      "        case when is_acce_by_free <-100 then 1 else is_acce_by_free end as is_acce_by_free,\n",
      "        case when is_acce_by_strong_ctrl <-100 then 1 else is_acce_by_strong_ctrl end as is_acce_by_strong_ctrl,\n",
      "        case when is_acce_by_normal_ctrl <-100 then 1 else is_acce_by_normal_ctrl end as is_acce_by_normal_ctrl,\n",
      "        case when is_acce_by_no_ctrl <-100 then 1 else is_acce_by_no_ctrl end as is_acce_by_no_ctrl,\n",
      "        \n",
      "        --clv\n",
      "        case when clv_pred_1m <-100 then 0 else clv_pred_1m end as clv_pred_1m, --0\n",
      "        case when clv_mtd <-100 then 0 else clv_mtd end as clv_mtd, --0\n",
      "\n",
      "        --上月人均干预次数\n",
      "        case when login_cnt_last_month <-100 then 0 else login_cnt_last_month end                         as login_cnt_last_month,\n",
      "        case when natural_login_cnt_last_month <-100 then 0 else natural_login_cnt_last_month end         as natural_login_cnt_last_month,\n",
      "        case when com_login_cnt_last_month <-100 then 0 else com_login_cnt_last_month end                 as com_login_cnt_last_month,\n",
      "        case when free_login_cnt_last_month <-100 then 0 else free_login_cnt_last_month end               as free_login_cnt_last_month,\n",
      "        case when strong_ctrl_login_cnt_last_month<-100 then 0 else strong_ctrl_login_cnt_last_month end  as strong_ctrl_login_cnt_last_month,\n",
      "        case when normal_ctrl_login_cnt_last_month<-100 then 0 else normal_ctrl_login_cnt_last_month end  as normal_ctrl_login_cnt_last_month,\n",
      "        case when no_ctrl_login_cnt_last_month<-100 then 0 else no_ctrl_login_cnt_last_month end          as no_ctrl_login_cnt_last_month,\n",
      "        case when clv_year<-100 then 0 else clv_year           end as gmv_year,\n",
      "        case when last_year_gmv<-100 then 0 else last_year_gmv end as last_year_gmv\n",
      "        \n",
      "    FROM\n",
      "    app.app_yhzz_umc_unit_user\n",
      "    WHERE\n",
      "    dt = '2022-05-20'\n",
      "    and priority_type in('A1','A2' )\n",
      "    limit 100\n",
      "   -- and user_log_acct in (select user_log_acct from app.app_yhzz_umc_algo_pin_interim WHERE dt = '2022-05-01' and dp='low')\n",
      "    )user\n",
      "\n",
      "    JOIN\n",
      "\n",
      "    (\n",
      "    SELECT\n",
      "        grid_name_1st,\n",
      "        \n",
      "        --阶跃下限\n",
      "        max(case when lower_lift_login_cnt <-100 then 0 else lower_lift_login_cnt end) as lower_lift_login_cnt,\n",
      "             \n",
      "\n",
      "        --渠道上限\n",
      "        max(case when natural_max_login_cnt <-100 then 2 else natural_max_login_cnt end )  as natural_max_login_cnt,\n",
      "        max(case when com_max_login_cnt <-100 then 2 else com_max_login_cnt end )  as com_max_login_count,\n",
      "        max(case when free_max_login_cnt <-100 then 2 else free_max_login_cnt end ) as free_max_login_count,\n",
      "        max(case when strong_ctrl_max_login_count <-100 then 0 else strong_ctrl_max_login_count end ) as strong_ctrl_max_login_count,\n",
      "        max(case when normal_ctrl_max_login_count <-100 then 0 else normal_ctrl_max_login_count end ) as normal_ctrl_max_login_count,\n",
      "        max(case when no_ctrl_max_login_count <-100 then 0 else no_ctrl_max_login_count end ) as no_ctrl_max_login_count,\n",
      "        \n",
      "        --渠道成本\n",
      "        max(case when natural_login_cost <-100 then -3 else natural_login_cost end ) as  natural_login_cost,\n",
      "        max(case when com_login_cost <-100 then -3 else (-1 * com_login_cost) end ) as  com_login_cost,\n",
      "        max(case when free_login_cost <-100 then 0 else free_login_cost end ) as free_login_cost,\n",
      "        max(case when no_ctrl_login_cost <-100 then 0.8 else no_ctrl_login_cost end ) as no_ctrl_login_cost,\n",
      "        max(case when strong_ctrl_login_cost <-100 then 0.6 else strong_ctrl_login_cost end ) as strong_ctrl_login_cost,\n",
      "        max(case when normal_login_cost <-100 then 0.9 else normal_login_cost end ) as normal_login_cost,\n",
      "\n",
      "        --渠道成本质量因子\n",
      "        \n",
      "        max(case when natural_quality_coeff <-100 then 1 else natural_quality_coeff end ) as natural_quality_coeff,\n",
      "        max(case when com_quality_coeff <-100 then 0.28 else com_quality_coeff end ) as com_quality_coeff,\n",
      "        max(case when free_quality_coeff <-100 then 0.64 else free_quality_coeff end ) as free_quality_coeff,\n",
      "        max(case when strong_ctrl_quality_coeff <-100 then 2.2 else strong_ctrl_quality_coeff end ) as strong_ctrl_quality_coeff,\n",
      "        max(case when normal_ctrl_quality_coeff <-100 then 0.25 else normal_ctrl_quality_coeff end ) as normal_ctrl_quality_coeff,\n",
      "        max(case when no_ctrl_quality_coeff <-100 then 0.88 else no_ctrl_quality_coeff end ) as no_ctrl_quality_coeff,\n",
      "        \n",
      "        --渠道dau映射\n",
      "        \n",
      "        max(case when natural_login_cnt_per_dau <-100 then 0.478 else natural_login_cnt_per_dau end ) as natural_login_cnt_per_dau,\n",
      "        max(case when com_login_cnt_per_dau <-100 then 0.460 else com_login_cnt_per_dau end ) as com_login_cnt_per_dau,\n",
      "        max(case when free_login_cnt_per_dau <-100 then 0.462 else free_login_cnt_per_dau end ) as free_login_cnt_per_dau,\n",
      "        max(case when no_ctrl_login_cnt_per_dau <-100 then 0.434 else no_ctrl_login_cnt_per_dau end ) as no_ctrl_login_cnt_per_dau,\n",
      "        max(case when strong_ctrl_login_cnt_per_dau <-100 then 0.596 else strong_ctrl_login_cnt_per_dau end ) as strong_ctrl_login_cnt_per_dau,\n",
      "        max(case when normal_login_cnt_per_dau <-100 then 0.507 else normal_login_cnt_per_dau end ) as normal_ctrl_login_cnt_per_dau,\n",
      "         --dau映射\n",
      "        max(case when total_login_dau_ratio <-100 then 0.8 else total_login_dau_ratio end) as total_login_dau_ratio,\n",
      "\n",
      "        -- 格子用户数& 渠道月均引流 for 保量\n",
      "        max(user_cnt) as user_cnt,\n",
      "        max(natural_login_cnt_per_month) as natural_login_cnt_per_month,\n",
      "        max(com_login_cnt_per_month) as com_login_cnt_per_month,\n",
      "        max(free_login_cnt_per_month) as free_login_cnt_per_month,\n",
      "        max(no_ctrl_login_cnt_per_month) as no_ctrl_login_cnt_per_month,\n",
      "        max(strong_ctrl_login_cnt_per_month) as strong_ctrl_login_cnt_per_month,\n",
      "        max(normal_ctrl_login_cnt_per_month) as normal_ctrl_login_cnt_per_month,\n",
      "        max(cast(natural_login_cnt_per_month as  double)/user_cnt)         as natural_base_cnt,\n",
      "        max(cast(com_login_cnt_per_month as  double)/user_cnt)         as com_base_cnt,\n",
      "        max(cast(free_login_cnt_per_month as  double)/user_cnt)        as free_base_cnt,\n",
      "        max(cast(no_ctrl_login_cnt_per_month as  double)/user_cnt)     as no_ctrl_base_cnt,\n",
      "        max(cast(strong_ctrl_login_cnt_per_month as  double)/user_cnt) as strong_ctrl_base_cnt,\n",
      "        max(cast(normal_ctrl_login_cnt_per_month as  double)/user_cnt) as normal_ctrl_base_cnt\n",
      "\n",
      "        \n",
      "    FROM\n",
      "        app.app_yhzz_umc_unit_grid\n",
      "    WHERE\n",
      "        dt = '2022-05-20'\n",
      "        AND grid_name_1st is not null\n",
      "        AND is_grid_valid =1 \n",
      "        group by\n",
      "        grid_name_1st\n",
      "    )grid on user.grid_name_1st = grid.grid_name_1st\n",
      "\n",
      "    \n",
      "data dtypes [('dt', 'string'), ('user_log_acct', 'string'), ('my_hash_code', 'int'), ('month_hash', 'int'), ('user_life_cycle_type_1st', 'string'), ('model_a_1st', 'string'), ('model_b_1st', 'string'), ('goal_group_1st', 'string'), ('annual_clv_1st', 'string'), ('grid_name_1st', 'string'), ('area_b_1st', 'bigint'), ('user_life_cycle_type', 'string'), ('model_a', 'string'), ('model_b', 'string'), ('model_c', 'string'), ('model_l', 'string'), ('priority_type', 'string'), ('is_malice_user', 'int'), ('lower_lift_login_cnt', 'bigint'), ('natural_pred_login_cnt_rest', 'bigint'), ('natural_pred_login_cnt_n30d', 'bigint'), ('natural_login_cnt_last_month', 'bigint'), ('natural_max_login_cnt', 'bigint'), ('natural_login_cnt_per_month', 'bigint'), ('natural_quality_coeff', 'decimal(18,6)'), ('natural_login_cnt_per_dau', 'decimal(18,6)'), ('login_cnt_mtd', 'bigint'), ('natural_login_cnt_mtd', 'bigint'), ('com_login_cnt_mtd', 'bigint'), ('free_login_cnt_mtd', 'bigint'), ('strong_ctrl_login_cnt_mtd', 'bigint'), ('normal_ctrl_login_cnt_mtd', 'bigint'), ('no_ctrl_login_cnt_mtd', 'bigint'), ('is_acce_by_com', 'int'), ('is_acce_by_free', 'int'), ('is_acce_by_strong_ctrl', 'int'), ('is_acce_by_normal_ctrl', 'int'), ('is_acce_by_no_ctrl', 'int'), ('clv_pred_1m', 'decimal(28,6)'), ('clv_mtd', 'decimal(28,6)'), ('login_cnt_last_month', 'bigint'), ('com_login_cnt_last_month', 'bigint'), ('free_login_cnt_last_month', 'bigint'), ('strong_ctrl_login_cnt_last_month', 'bigint'), ('normal_ctrl_login_cnt_last_month', 'bigint'), ('no_ctrl_login_cnt_last_month', 'bigint'), ('gmv_year', 'double'), ('last_year_gmv', 'double'), ('com_max_login_count', 'bigint'), ('free_max_login_count', 'bigint'), ('strong_ctrl_max_login_count', 'bigint'), ('normal_ctrl_max_login_count', 'bigint'), ('no_ctrl_max_login_count', 'bigint'), ('com_login_cost', 'decimal(30,6)'), ('free_login_cost', 'decimal(28,6)'), ('no_ctrl_login_cost', 'decimal(28,6)'), ('strong_ctrl_login_cost', 'decimal(28,6)'), ('normal_login_cost', 'decimal(28,6)'), ('com_quality_coeff', 'decimal(18,6)'), ('free_quality_coeff', 'decimal(18,6)'), ('strong_ctrl_quality_coeff', 'decimal(18,6)'), ('normal_ctrl_quality_coeff', 'decimal(18,6)'), ('no_ctrl_quality_coeff', 'decimal(18,6)'), ('com_login_cnt_per_dau', 'decimal(18,6)'), ('free_login_cnt_per_dau', 'decimal(18,6)'), ('no_ctrl_login_cnt_per_dau', 'decimal(18,6)'), ('strong_ctrl_login_cnt_per_dau', 'decimal(18,6)'), ('normal_ctrl_login_cnt_per_dau', 'decimal(18,6)'), ('total_login_dau_ratio', 'decimal(18,6)'), ('user_cnt', 'bigint'), ('com_login_cnt_per_month', 'bigint'), ('free_login_cnt_per_month', 'bigint'), ('no_ctrl_login_cnt_per_month', 'bigint'), ('strong_ctrl_login_cnt_per_month', 'bigint'), ('normal_ctrl_login_cnt_per_month', 'bigint'), ('com_base_cnt', 'double'), ('free_base_cnt', 'double'), ('no_ctrl_base_cnt', 'double'), ('strong_ctrl_base_cnt', 'double'), ('normal_ctrl_base_cnt', 'double')]\n"
     ]
    }
   ],
   "source": [
    "day_ago_1 = '2022-05-20'\n",
    "now_month = 5\n",
    "data = get_base_data(part_dt = day_ago_1,\n",
    "                     part_month= now_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+----------------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+----------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+-------------------+-------------------+------------------+--------------------+--------------------+\n",
      "|        dt|  user_log_acct|my_hash_code|month_hash|user_life_cycle_type_1st|model_a_1st|model_b_1st|goal_group_1st|annual_clv_1st|         grid_name_1st|area_b_1st|user_life_cycle_type|model_a|model_b|model_c|model_l|priority_type|is_malice_user|lower_lift_login_cnt|natural_pred_login_cnt_rest|natural_pred_login_cnt_n30d|natural_login_cnt_last_month|natural_max_login_cnt|natural_login_cnt_per_month|natural_quality_coeff|natural_login_cnt_per_dau|login_cnt_mtd|natural_login_cnt_mtd|com_login_cnt_mtd|free_login_cnt_mtd|strong_ctrl_login_cnt_mtd|normal_ctrl_login_cnt_mtd|no_ctrl_login_cnt_mtd|is_acce_by_com|is_acce_by_free|is_acce_by_strong_ctrl|is_acce_by_normal_ctrl|is_acce_by_no_ctrl|clv_pred_1m|   clv_mtd|login_cnt_last_month|com_login_cnt_last_month|free_login_cnt_last_month|strong_ctrl_login_cnt_last_month|normal_ctrl_login_cnt_last_month|no_ctrl_login_cnt_last_month|gmv_year|last_year_gmv|com_max_login_count|free_max_login_count|strong_ctrl_max_login_count|normal_ctrl_max_login_count|no_ctrl_max_login_count|com_login_cost|free_login_cost|no_ctrl_login_cost|strong_ctrl_login_cost|normal_login_cost|com_quality_coeff|free_quality_coeff|strong_ctrl_quality_coeff|normal_ctrl_quality_coeff|no_ctrl_quality_coeff|com_login_cnt_per_dau|free_login_cnt_per_dau|no_ctrl_login_cnt_per_dau|strong_ctrl_login_cnt_per_dau|normal_ctrl_login_cnt_per_dau|total_login_dau_ratio|user_cnt|com_login_cnt_per_month|free_login_cnt_per_month|no_ctrl_login_cnt_per_month|strong_ctrl_login_cnt_per_month|normal_ctrl_login_cnt_per_month|       com_base_cnt|      free_base_cnt|  no_ctrl_base_cnt|strong_ctrl_base_cnt|normal_ctrl_base_cnt|\n",
      "+----------+---------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+----------------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+----------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+-------------------+-------------------+------------------+--------------------+--------------------+\n",
      "|2022-05-20|jd_SCoAQWGCtuEw|          74|         3|                  成长期|          5|          3|      都市蓝领|             4| 成长期|5|3|4|都市蓝领|         1|              成长期|      5|      1|      4|      5|           A2|             0|                  62|                         10|                          0|                          63|                   35|                    3095077|             1.000000|                 0.441297|           18|                   17|                0|                 0|                        0|                        0|                    1|             1|              1|                     1|                     1|                 1|   0.000000|  0.000000|                  63|                       0|                        0|                               0|                               0|                           0| 2246.97|      2915.81|                 13|                   9|                          3|                         16|                      9|     -1.808646|       0.000000|          0.900000|              0.785658|         0.588748|         0.285000|          0.628100|                 1.952500|                 0.255000|             0.895100|             0.407966|              0.483593|                 0.526717|                     0.610676|                     0.511341|             0.842007|  307042|                1433404|                  365366|                     955273|                           8257|                        1657874|  4.668429726226379| 1.1899544687697448|3.1112127982490994|0.026892086424658516|   5.399502348212948|\n",
      "|2022-05-20|jd_SFeUXPkWhucn|          92|        15|                  成长期|         41|          3|      小镇中产|             3|成长期|41|3|3|小镇中产|         1|              成长期|     41|      1|      2|      5|           A2|             0|                  27|                          1|                          0|                           2|                    8|                     596294|             1.000000|                 0.633141|            2|                    2|                0|                 0|                        0|                        0|                    0|             1|              0|                     1|                     1|                 1|   0.000000|  0.000000|                   2|                       0|                        0|                               0|                               0|                           0| 1177.62|       4199.0|                  3|                   4|                          2|                          3|                      4|     -2.206824|       0.000000|          0.900000|              3.600229|         0.466169|         0.285000|          0.628100|                 1.952500|                 0.255000|             0.895100|             0.707815|              0.556506|                 0.687280|                     0.799712|                     0.747023|             0.906151|  271759|                  80816|                   60227|                     181701|                           3892|                         123654|0.29738113549137285|0.22161915520737124| 0.668610791178949|0.014321512810983261|  0.4550134494165787|\n",
      "|2022-05-20|jd_SEDEvvIwwGvs|          79|        40|                  成长期|         43|          4|      学生一族|             3|成长期|43|4|3|学生一族|         0|              成长期|      5|      4|      4|      5|           A2|             0|                  37|                          0|                          0|                           0|                   16|                     364688|             1.000000|                 0.536926|            0|                    0|                0|                 0|                        0|                        0|                    0|             1|              0|                     1|                     1|                 1|  50.000000|  0.000000|                   0|                       0|                        0|                               0|                               0|                           0|  1071.9|      1707.41|                  4|                   7|                          2|                          6|                      6|     -1.597952|       0.000000|          0.900000|              2.010685|         0.515156|         0.285000|          0.628100|                 1.952500|                 0.255000|             0.895100|             0.645979|              0.457509|                 0.568245|                     0.673166|                     0.635150|             0.883597|   63309|                  51469|                   68056|                     135957|                           1244|                         103544| 0.8129807768247801|  1.074981440237565|2.1475145713879544| 0.01964965486739642|  1.6355336524032917|\n",
      "|2022-05-20|jd_SLwtOZaoLkWS|          45|        39|                  成长期|         42|          3|      小镇青年|             3|成长期|42|3|3|小镇青年|         1|              成长期|     42|      4|      3|      4|           A2|             0|                  29|                          1|                          0|                           3|                   10|                    2607328|             1.000000|                 0.641349|           12|                    2|                1|                 0|                        0|                        0|                    9|             1|              1|                     1|                     1|                 1| 497.000000|497.000000|                   8|                       2|                        0|                               0|                               0|                           3|  1076.2|        187.6|                  4|                   4|                          2|                          4|                      4|     -1.659096|       0.000000|          0.900000|              2.763604|         0.484178|         0.285000|          0.628100|                 1.952500|                 0.255000|             0.895100|             0.704483|              0.589868|                 0.707574|                     0.785035|                     0.739421|             0.904633|  847779|                 447734|                  218640|                     796010|                           7707|                         679136| 0.5281258441173938| 0.2578974001479159|0.9389357367898945|0.009090812582052634|  0.8010766956954584|\n",
      "|2022-05-20|jd_SKiqIIDNiJti|          73|        79|                  成长期|         42|          3|      小镇青年|             3|成长期|42|3|3|小镇青年|         1|              成长期|     43|      3|      3|      4|           A2|             0|                  29|                          4|                          0|                           6|                   10|                    2607328|             1.000000|                 0.641349|            9|                    7|                2|                 0|                        0|                        0|                    0|             1|              1|                     1|                     1|                 1|   0.000000|  0.000000|                   8|                       0|                        1|                               0|                               0|                           1|  930.66|        732.3|                  4|                   4|                          2|                          4|                      4|     -1.659096|       0.000000|          0.900000|              2.763604|         0.484178|         0.285000|          0.628100|                 1.952500|                 0.255000|             0.895100|             0.704483|              0.589868|                 0.707574|                     0.785035|                     0.739421|             0.904633|  847779|                 447734|                  218640|                     796010|                           7707|                         679136| 0.5281258441173938| 0.2578974001479159|0.9389357367898945|0.009090812582052634|  0.8010766956954584|\n",
      "+----------+---------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+----------------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+----------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+-------------------+-------------------+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1_data = data.filter(\"priority_type like 'A1' or priority_type like 'A2'\")\n",
    "test1_data.filter( \"priority_type like 'A2'\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o267.showString.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2178)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2207)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2226)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:386)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3397)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3378)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:81)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:128)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:76)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3377)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2772)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:262)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:299)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b7e51e2bcf6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest1_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o267.showString.\n: java.lang.IllegalStateException: SparkContext has been shutdown\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2178)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2207)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2226)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:386)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3397)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3378)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:81)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:128)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:76)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3377)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2772)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:262)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:299)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "test1_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_list = ('A1','A2','B','C')\n",
    "sql = \"\"\" sel\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+-------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+-------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+------------+-------------+----------------+--------------------+--------------------+\n",
      "| dt|user_log_acct|my_hash_code|month_hash|user_life_cycle_type_1st|model_a_1st|model_b_1st|goal_group_1st|annual_clv_1st|grid_name_1st|area_b_1st|user_life_cycle_type|model_a|model_b|model_c|model_l|priority_type|is_malice_user|lower_lift_login_cnt|natural_pred_login_cnt_rest|natural_pred_login_cnt_n30d|natural_login_cnt_last_month|natural_max_login_cnt|natural_login_cnt_per_month|natural_quality_coeff|natural_login_cnt_per_dau|login_cnt_mtd|natural_login_cnt_mtd|com_login_cnt_mtd|free_login_cnt_mtd|strong_ctrl_login_cnt_mtd|normal_ctrl_login_cnt_mtd|no_ctrl_login_cnt_mtd|is_acce_by_com|is_acce_by_free|is_acce_by_strong_ctrl|is_acce_by_normal_ctrl|is_acce_by_no_ctrl|clv_pred_1m|clv_mtd|login_cnt_last_month|com_login_cnt_last_month|free_login_cnt_last_month|strong_ctrl_login_cnt_last_month|normal_ctrl_login_cnt_last_month|no_ctrl_login_cnt_last_month|gmv_year|last_year_gmv|com_max_login_count|free_max_login_count|strong_ctrl_max_login_count|normal_ctrl_max_login_count|no_ctrl_max_login_count|com_login_cost|free_login_cost|no_ctrl_login_cost|strong_ctrl_login_cost|normal_login_cost|com_quality_coeff|free_quality_coeff|strong_ctrl_quality_coeff|normal_ctrl_quality_coeff|no_ctrl_quality_coeff|com_login_cnt_per_dau|free_login_cnt_per_dau|no_ctrl_login_cnt_per_dau|strong_ctrl_login_cnt_per_dau|normal_ctrl_login_cnt_per_dau|total_login_dau_ratio|user_cnt|com_login_cnt_per_month|free_login_cnt_per_month|no_ctrl_login_cnt_per_month|strong_ctrl_login_cnt_per_month|normal_ctrl_login_cnt_per_month|com_base_cnt|free_base_cnt|no_ctrl_base_cnt|strong_ctrl_base_cnt|normal_ctrl_base_cnt|\n",
      "+---+-------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+-------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+-------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+------------+-------------+----------------+--------------------+--------------------+\n",
      "+---+-------------+------------+----------+------------------------+-----------+-----------+--------------+--------------+-------------+----------+--------------------+-------+-------+-------+-------+-------------+--------------+--------------------+---------------------------+---------------------------+----------------------------+---------------------+---------------------------+---------------------+-------------------------+-------------+---------------------+-----------------+------------------+-------------------------+-------------------------+---------------------+--------------+---------------+----------------------+----------------------+------------------+-----------+-------+--------------------+------------------------+-------------------------+--------------------------------+--------------------------------+----------------------------+--------+-------------+-------------------+--------------------+---------------------------+---------------------------+-----------------------+--------------+---------------+------------------+----------------------+-----------------+-----------------+------------------+-------------------------+-------------------------+---------------------+---------------------+----------------------+-------------------------+-----------------------------+-----------------------------+---------------------+--------+-----------------------+------------------------+---------------------------+-------------------------------+-------------------------------+------------+-------------+----------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2_data = data.filter(\"priority_type like 'C'\")\n",
    "test2_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Cannot resolve column name \"dt\" among (user_log_acct, my_hash_code);'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o267.unionByName.\n: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"dt\" among (user_log_acct, my_hash_code);\n\tat org.apache.spark.sql.Dataset$$anonfun$23$$anonfun$apply$10.apply(Dataset.scala:1920)\n\tat org.apache.spark.sql.Dataset$$anonfun$23$$anonfun$apply$10.apply(Dataset.scala:1920)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.Dataset$$anonfun$23.apply(Dataset.scala:1919)\n\tat org.apache.spark.sql.Dataset$$anonfun$23.apply(Dataset.scala:1918)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.Dataset.unionByName(Dataset.scala:1918)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a6c5bb355bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest3_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_log_acct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'my_hash_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest3_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36munionByName\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \"\"\"\n\u001b[0;32m-> 1500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Cannot resolve column name \"dt\" among (user_log_acct, my_hash_code);'"
     ]
    }
   ],
   "source": [
    "test3_data = test1_data[['user_log_acct','my_hash_code']]\n",
    "test = test1_data.unionByName(test3_data)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-a4be3cc8c6e7>\", line 206, in <module>\n",
      "    @udf(returnType=MapType(StringType(), IntegerType()))\n",
      "NameError: name 'udf' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2016, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/posixpath.py\", line 376, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# date: 2022-04-20\n",
    "# updta: 2022-05-10\n",
    "# author: niujianxing,yuchuchu\n",
    "\n",
    "\"\"\"\n",
    "用户管理中心-算法输出中间表\n",
    "\"\"\"\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# old_time放在程序运行开始的地方\n",
    "old_time = time.time()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, MapType\n",
    "from pyspark.sql.functions import col, lit, array\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# import os\n",
    "# os.environ['PYSPARK_PYTHON'] = \"/usr/local/anaconda3/bin/python3.6\"\n",
    "\n",
    "\n",
    "spark = (SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"test-dockerlinuxcontainer\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"1000\") \\\n",
    "    .getOrCreate())\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\", \"true\")\n",
    "spark.conf.set(\"hive.exec.dynamic.partition\", \"true\")\n",
    "spark.conf.set(\"hive.exec.dynamic.partition.mode\", \"true\")\n",
    "spark.sql(\"\"\"ADD JAR hdfs://ns1009/user/mart_jypt/mart_jypt_usr_grow/liuyang266/hiveudf-1.0-SNAPSHOT-jar-with-dependencies.jar\"\"\")\n",
    "spark.sql(\"\"\"CREATE TEMPORARY FUNCTION hash_sub AS 'com.jd.bdptools.ly.HashMonthly'\"\"\")\n",
    "\n",
    "# applicationId:spark程序的唯一标识符，其格式取决于调度程序的实现\n",
    "app_id = spark.sparkContext.applicationId \n",
    "print(app_id)\n",
    "print(spark.version)\n",
    "\n",
    "def get_base_data(part_dt,part_month):\n",
    "    \"\"\"获取sql文件\n",
    "\n",
    "    Args:\n",
    "        part_dt (_type_): 表格分区\n",
    "\n",
    "    Returns:\n",
    "        _type_: 返回执行sql\n",
    "    \"\"\"\n",
    "    used_sql = \"\"\"\n",
    "    SELECT\n",
    "        user.dt,\n",
    "        user.user_log_acct,\n",
    "        user.my_hash_code,\n",
    "        user.month_hash,\n",
    "        --格子粒度\n",
    "        user.user_life_cycle_type_1st,\n",
    "        user.model_a_1st,\n",
    "        user.model_b_1st,\n",
    "        user.goal_group_1st,\n",
    "        user.annual_clv_1st,\n",
    "        user.grid_name_1st,\n",
    "        user.area_b_1st,\n",
    "\n",
    "        --格子粒度2\n",
    "        user.user_life_cycle_type,\n",
    "        user.model_a,\n",
    "        user.model_b,\n",
    "        user.model_c,\n",
    "        user.model_l,\n",
    "        user.priority_type,\n",
    "        \n",
    "        user.is_malice_user,\n",
    "        \n",
    "        -- 目标登录次数\n",
    "        COALESCE(grid.lower_lift_login_cnt,0) as lower_lift_login_cnt,\n",
    "        COALESCE(user.natural_pred_login_cnt_rest,0) as natural_pred_login_cnt_rest,\n",
    "        COALESCE(user.natural_pred_login_cnt_n30d,0) as natural_pred_login_cnt_n30d,\n",
    "        \n",
    "        -- 自然相关\n",
    "        COALESCE(user.natural_login_cnt_last_month,0) as natural_login_cnt_last_month,\n",
    "        COALESCE(grid.natural_max_login_cnt,0) as natural_max_login_cnt,\n",
    "        COALESCE(grid.natural_login_cnt_per_month,0) as natural_login_cnt_per_month,\n",
    "        COALESCE(grid.natural_quality_coeff,0) as natural_quality_coeff,\n",
    "        COALESCE(grid.natural_login_cnt_per_dau,0) as natural_login_cnt_per_dau,\n",
    "\n",
    "        --当月引流登端次数\n",
    "        COALESCE(user.login_cnt_mtd,0) as login_cnt_mtd,\n",
    "        user.natural_login_cnt_mtd,\n",
    "        user.com_login_cnt_mtd,\n",
    "        user.free_login_cnt_mtd,\n",
    "        user.strong_ctrl_login_cnt_mtd,\n",
    "        user.normal_ctrl_login_cnt_mtd,\n",
    "        user.no_ctrl_login_cnt_mtd,\n",
    "\n",
    "        --渠道是否可达\n",
    "        user.is_acce_by_com,\n",
    "        user.is_acce_by_free,\n",
    "        user.is_acce_by_strong_ctrl,\n",
    "        user.is_acce_by_normal_ctrl,\n",
    "        user.is_acce_by_no_ctrl,\n",
    "\n",
    "        --clv\n",
    "        user.clv_pred_1m,\n",
    "        user.clv_mtd,\n",
    "\n",
    "        --上月人均干预次数\n",
    "        COALESCE(login_cnt_last_month,0)         as login_cnt_last_month,\n",
    "        COALESCE(com_login_cnt_last_month,0) as com_login_cnt_last_month,\n",
    "        COALESCE(free_login_cnt_last_month,0) as free_login_cnt_last_month,\n",
    "        COALESCE(strong_ctrl_login_cnt_last_month,0) as strong_ctrl_login_cnt_last_month,\n",
    "        COALESCE(normal_ctrl_login_cnt_last_month,0) as normal_ctrl_login_cnt_last_month,\n",
    "        COALESCE(no_ctrl_login_cnt_last_month,0) as no_ctrl_login_cnt_last_month,\n",
    "        \n",
    "        --gmv\n",
    "        cast(COALESCE(gmv_year,0.0) as double)  as gmv_year,\n",
    "        cast(COALESCE(last_year_gmv,0.0) as double) as last_year_gmv,\n",
    "                \n",
    "        --渠道上限\n",
    "        COALESCE(grid.com_max_login_count,2) as com_max_login_count,\n",
    "        COALESCE(grid.free_max_login_count,2) as free_max_login_count,\n",
    "        COALESCE(grid.strong_ctrl_max_login_count,0) as strong_ctrl_max_login_count,\n",
    "        COALESCE(grid.normal_ctrl_max_login_count,0) as normal_ctrl_max_login_count,\n",
    "        COALESCE(grid.no_ctrl_max_login_count,0) as no_ctrl_max_login_count,\n",
    "\n",
    "        --渠道成本\n",
    "        COALESCE(grid.com_login_cost,-3) as com_login_cost,\n",
    "        COALESCE(grid.free_login_cost,0) as free_login_cost,\n",
    "        COALESCE(grid.no_ctrl_login_cost,0.9) as no_ctrl_login_cost,\n",
    "        COALESCE(grid.strong_ctrl_login_cost,0.8) as strong_ctrl_login_cost,\n",
    "        COALESCE(grid.normal_login_cost,0.6) as normal_login_cost,\n",
    "\n",
    "        --渠道成本质量因子\n",
    "        com_quality_coeff,\n",
    "        free_quality_coeff,\n",
    "        strong_ctrl_quality_coeff,\n",
    "        normal_ctrl_quality_coeff,\n",
    "        no_ctrl_quality_coeff,\n",
    "\n",
    "\n",
    "        --渠道dau映射\n",
    "        COALESCE(grid.com_login_cnt_per_dau,0.5)            as com_login_cnt_per_dau,\n",
    "        COALESCE(grid.free_login_cnt_per_dau,0.5)           as free_login_cnt_per_dau,\n",
    "        COALESCE(grid.no_ctrl_login_cnt_per_dau,0.5)        as no_ctrl_login_cnt_per_dau,\n",
    "        COALESCE(grid.strong_ctrl_login_cnt_per_dau,0.5)    as strong_ctrl_login_cnt_per_dau,\n",
    "        COALESCE(grid.normal_ctrl_login_cnt_per_dau,0.5)         as normal_ctrl_login_cnt_per_dau,\n",
    "        grid.total_login_dau_ratio,\n",
    "\n",
    "        -- 格子用户数& 渠道月均引流 for 保量\n",
    "        case when grid.user_cnt <-100 then 1 else grid.user_cnt end as user_cnt,\n",
    "        case when grid.com_login_cnt_per_month <-100 then 1 else grid.com_login_cnt_per_month end as com_login_cnt_per_month,\n",
    "        case when grid.free_login_cnt_per_month <-100 then 1 else grid.free_login_cnt_per_month end as free_login_cnt_per_month,\n",
    "        case when grid.no_ctrl_login_cnt_per_month <-100 then 1 else grid.no_ctrl_login_cnt_per_month end as no_ctrl_login_cnt_per_month,\n",
    "        case when grid.strong_ctrl_login_cnt_per_month <-100 then 1 else grid.strong_ctrl_login_cnt_per_month end as strong_ctrl_login_cnt_per_month,\n",
    "        case when grid.normal_ctrl_login_cnt_per_month <-100 then 1 else grid.normal_ctrl_login_cnt_per_month end as normal_ctrl_login_cnt_per_month,\n",
    "\n",
    "        -- 上月人均引流次数（按格子统计）\n",
    "        case when grid.com_base_cnt         <-100 then 0 else grid.com_base_cnt end as         com_base_cnt,\n",
    "        case when grid.free_base_cnt        <-100 then 0 else grid.free_base_cnt end as        free_base_cnt,\n",
    "        case when grid.no_ctrl_base_cnt     <-100 then 0 else grid.no_ctrl_base_cnt end as     no_ctrl_base_cnt,\n",
    "        case when grid.strong_ctrl_base_cnt  <-100 then 0 else grid.strong_ctrl_base_cnt end as strong_ctrl_base_cnt,\n",
    "        case when grid.normal_ctrl_base_cnt <-100 then 0 else grid.normal_ctrl_base_cnt end as normal_ctrl_base_cnt\n",
    "\n",
    "    FROM\n",
    "    (\n",
    "    SELECT\n",
    "        dt,\n",
    "        user_log_acct,\n",
    "        hash_sub(concat(lower(trim(user_log_acct)),'{part_dt}')) as my_hash_code,\n",
    "        hash_sub(concat(lower(trim(user_log_acct)),'{part_month}')) as month_hash,\n",
    "        --格子粒度\n",
    "        user_life_cycle_type_1st,\n",
    "        model_a_1st,\n",
    "        model_b_1st,\n",
    "        goal_group_1st,\n",
    "        case when annual_clv_1st is null then '0' else annual_clv_1st end as annual_clv_1st,\n",
    "        grid_name_1st,\n",
    "        area_b_1st,\n",
    "\n",
    "        user_life_cycle_type,\n",
    "        model_a,\n",
    "        model_b,\n",
    "        model_c,\n",
    "        model_l,\n",
    "        priority_type,\n",
    "        is_malice_user,\n",
    "        \n",
    "        -- 自然登录\n",
    "        case when natural_pred_login_cnt_rest<-100 then 0\n",
    "             else natural_pred_login_cnt_rest end as natural_pred_login_cnt_rest,\n",
    "        case when natural_pred_login_cnt_n30d<-100 then 0\n",
    "             else natural_pred_login_cnt_n30d end as natural_pred_login_cnt_n30d,\n",
    "\n",
    "        \n",
    "        --当月引流登端次数\n",
    "        case when login_cnt_mtd<-100 then 0\n",
    "             else login_cnt_mtd end as login_cnt_mtd,\n",
    "        case when natural_login_cnt_mtd <-100 then 0 else natural_login_cnt_mtd end as natural_login_cnt_mtd,\n",
    "        case when com_login_cnt_mtd <-100 then 0 else com_login_cnt_mtd end as com_login_cnt_mtd,\n",
    "        case when free_login_cnt_mtd <-100 then 0 else free_login_cnt_mtd end as free_login_cnt_mtd,\n",
    "        case when strong_ctrl_login_cnt_mtd <-100 then 0 else strong_ctrl_login_cnt_mtd end as strong_ctrl_login_cnt_mtd,\n",
    "        case when normal_ctrl_login_cnt_mtd <-100 then 0 else normal_ctrl_login_cnt_mtd end as normal_ctrl_login_cnt_mtd,\n",
    "        case when no_ctrl_login_cnt_mtd <-100 then 0 else no_ctrl_login_cnt_mtd end as no_ctrl_login_cnt_mtd,\n",
    "        \n",
    "        --渠道是否可达\n",
    "        case when is_acce_by_com <-100 then 1 else is_acce_by_com end as is_acce_by_com,\n",
    "        case when is_acce_by_free <-100 then 1 else is_acce_by_free end as is_acce_by_free,\n",
    "        case when is_acce_by_strong_ctrl <-100 then 1 else is_acce_by_strong_ctrl end as is_acce_by_strong_ctrl,\n",
    "        case when is_acce_by_normal_ctrl <-100 then 1 else is_acce_by_normal_ctrl end as is_acce_by_normal_ctrl,\n",
    "        case when is_acce_by_no_ctrl <-100 then 1 else is_acce_by_no_ctrl end as is_acce_by_no_ctrl,\n",
    "        \n",
    "        --clv\n",
    "        case when clv_pred_1m <-100 then 0 else clv_pred_1m end as clv_pred_1m, --0\n",
    "        case when clv_mtd <-100 then 0 else clv_mtd end as clv_mtd, --0\n",
    "\n",
    "        --上月人均干预次数\n",
    "        case when login_cnt_last_month <-100 then 0 else login_cnt_last_month end                         as login_cnt_last_month,\n",
    "        case when natural_login_cnt_last_month <-100 then 0 else natural_login_cnt_last_month end         as natural_login_cnt_last_month,\n",
    "        case when com_login_cnt_last_month <-100 then 0 else com_login_cnt_last_month end                 as com_login_cnt_last_month,\n",
    "        case when free_login_cnt_last_month <-100 then 0 else free_login_cnt_last_month end               as free_login_cnt_last_month,\n",
    "        case when strong_ctrl_login_cnt_last_month<-100 then 0 else strong_ctrl_login_cnt_last_month end  as strong_ctrl_login_cnt_last_month,\n",
    "        case when normal_ctrl_login_cnt_last_month<-100 then 0 else normal_ctrl_login_cnt_last_month end  as normal_ctrl_login_cnt_last_month,\n",
    "        case when no_ctrl_login_cnt_last_month<-100 then 0 else no_ctrl_login_cnt_last_month end          as no_ctrl_login_cnt_last_month,\n",
    "        case when clv_year<-100 then 0 else clv_year           end as gmv_year,\n",
    "        case when last_year_gmv<-100 then 0 else last_year_gmv end as last_year_gmv\n",
    "        \n",
    "    FROM\n",
    "    app.app_yhzz_umc_unit_user\n",
    "    WHERE\n",
    "    dt = '{part_dt}'\n",
    "    and priority_type in('A1','A2' )\n",
    "   -- and user_log_acct in (select user_log_acct from app.app_yhzz_umc_algo_pin_interim WHERE dt = '2022-05-01' and dp='low')\n",
    "    )user\n",
    "\n",
    "    JOIN\n",
    "\n",
    "    (\n",
    "    SELECT\n",
    "        grid_name_1st,\n",
    "        \n",
    "        --阶跃下限\n",
    "        max(case when lower_lift_login_cnt <-100 then 0 else lower_lift_login_cnt end) as lower_lift_login_cnt,\n",
    "             \n",
    "\n",
    "        --渠道上限\n",
    "        max(case when natural_max_login_cnt <-100 then 2 else natural_max_login_cnt end )  as natural_max_login_cnt,\n",
    "        max(case when com_max_login_cnt <-100 then 2 else com_max_login_cnt end )  as com_max_login_count,\n",
    "        max(case when free_max_login_cnt <-100 then 2 else free_max_login_cnt end ) as free_max_login_count,\n",
    "        max(case when strong_ctrl_max_login_count <-100 then 0 else strong_ctrl_max_login_count end ) as strong_ctrl_max_login_count,\n",
    "        max(case when normal_ctrl_max_login_count <-100 then 0 else normal_ctrl_max_login_count end ) as normal_ctrl_max_login_count,\n",
    "        max(case when no_ctrl_max_login_count <-100 then 0 else no_ctrl_max_login_count end ) as no_ctrl_max_login_count,\n",
    "        \n",
    "        --渠道成本\n",
    "        max(case when natural_login_cost <-100 then -3 else natural_login_cost end ) as  natural_login_cost,\n",
    "        max(case when com_login_cost <-100 then -3 else (-1 * com_login_cost) end ) as  com_login_cost,\n",
    "        max(case when free_login_cost <-100 then 0 else free_login_cost end ) as free_login_cost,\n",
    "        max(case when no_ctrl_login_cost <-100 then 0.8 else no_ctrl_login_cost end ) as no_ctrl_login_cost,\n",
    "        max(case when strong_ctrl_login_cost <-100 then 0.6 else strong_ctrl_login_cost end ) as strong_ctrl_login_cost,\n",
    "        max(case when normal_login_cost <-100 then 0.9 else normal_login_cost end ) as normal_login_cost,\n",
    "\n",
    "        --渠道成本质量因子\n",
    "        \n",
    "        max(case when natural_quality_coeff <-100 then 1 else natural_quality_coeff end ) as natural_quality_coeff,\n",
    "        max(case when com_quality_coeff <-100 then 0.28 else com_quality_coeff end ) as com_quality_coeff,\n",
    "        max(case when free_quality_coeff <-100 then 0.64 else free_quality_coeff end ) as free_quality_coeff,\n",
    "        max(case when strong_ctrl_quality_coeff <-100 then 2.2 else strong_ctrl_quality_coeff end ) as strong_ctrl_quality_coeff,\n",
    "        max(case when normal_ctrl_quality_coeff <-100 then 0.25 else normal_ctrl_quality_coeff end ) as normal_ctrl_quality_coeff,\n",
    "        max(case when no_ctrl_quality_coeff <-100 then 0.88 else no_ctrl_quality_coeff end ) as no_ctrl_quality_coeff,\n",
    "        \n",
    "        --渠道dau映射\n",
    "        \n",
    "        max(case when natural_login_cnt_per_dau <-100 then 0.478 else natural_login_cnt_per_dau end ) as natural_login_cnt_per_dau,\n",
    "        max(case when com_login_cnt_per_dau <-100 then 0.460 else com_login_cnt_per_dau end ) as com_login_cnt_per_dau,\n",
    "        max(case when free_login_cnt_per_dau <-100 then 0.462 else free_login_cnt_per_dau end ) as free_login_cnt_per_dau,\n",
    "        max(case when no_ctrl_login_cnt_per_dau <-100 then 0.434 else no_ctrl_login_cnt_per_dau end ) as no_ctrl_login_cnt_per_dau,\n",
    "        max(case when strong_ctrl_login_cnt_per_dau <-100 then 0.596 else strong_ctrl_login_cnt_per_dau end ) as strong_ctrl_login_cnt_per_dau,\n",
    "        max(case when normal_login_cnt_per_dau <-100 then 0.507 else normal_login_cnt_per_dau end ) as normal_ctrl_login_cnt_per_dau,\n",
    "         --dau映射\n",
    "        max(case when total_login_dau_ratio <-100 then 0.8 else total_login_dau_ratio end) as total_login_dau_ratio,\n",
    "\n",
    "        -- 格子用户数& 渠道月均引流 for 保量\n",
    "        max(user_cnt) as user_cnt,\n",
    "        max(natural_login_cnt_per_month) as natural_login_cnt_per_month,\n",
    "        max(com_login_cnt_per_month) as com_login_cnt_per_month,\n",
    "        max(free_login_cnt_per_month) as free_login_cnt_per_month,\n",
    "        max(no_ctrl_login_cnt_per_month) as no_ctrl_login_cnt_per_month,\n",
    "        max(strong_ctrl_login_cnt_per_month) as strong_ctrl_login_cnt_per_month,\n",
    "        max(normal_ctrl_login_cnt_per_month) as normal_ctrl_login_cnt_per_month,\n",
    "        max(cast(natural_login_cnt_per_month as  double)/user_cnt)         as natural_base_cnt,\n",
    "        max(cast(com_login_cnt_per_month as  double)/user_cnt)         as com_base_cnt,\n",
    "        max(cast(free_login_cnt_per_month as  double)/user_cnt)        as free_base_cnt,\n",
    "        max(cast(no_ctrl_login_cnt_per_month as  double)/user_cnt)     as no_ctrl_base_cnt,\n",
    "        max(cast(strong_ctrl_login_cnt_per_month as  double)/user_cnt) as strong_ctrl_base_cnt,\n",
    "        max(cast(normal_ctrl_login_cnt_per_month as  double)/user_cnt) as normal_ctrl_base_cnt\n",
    "\n",
    "        \n",
    "    FROM\n",
    "        app.app_yhzz_umc_unit_grid\n",
    "    WHERE\n",
    "        dt = '{part_dt}'\n",
    "        AND grid_name_1st is not null\n",
    "        AND is_grid_valid =1 \n",
    "        group by\n",
    "        grid_name_1st\n",
    "    )grid on user.grid_name_1st = grid.grid_name_1st\n",
    "\n",
    "    \"\"\".format(part_dt = part_dt,part_month = part_month)\n",
    "    print(\"used sql\", used_sql)\n",
    "    data = spark.sql(used_sql)\n",
    "    data.cache()\n",
    "    print(\"data columns\", data.columns)\n",
    "    print(\"data dtypes\", data.dtypes)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_plan_pra(plan_level):\n",
    "    \"\"\"返回不同档位的参数值\n",
    "\n",
    "    Args:\n",
    "        plan_level: 方案档位, low, medium, high, max\n",
    "\n",
    "    Returns:\n",
    "        _type_: 返回月度clv阈值(month_clv_threshold), \n",
    "                返回年度clv阈值year_clv_threshold, \n",
    "                返回渠道放大系数channel_max_adjust, \n",
    "                返回渠道偏好系数channel_preference\n",
    "    \"\"\"\n",
    "    # 月度clv阈值\n",
    "    # 年度clv等级\n",
    "    # 渠道上限调节, 999表示取上限，1.5表示均值的1.5倍，1.2表示均值的1.2倍，等等\n",
    "    # 渠道倾向 channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "    \n",
    "    # plan_pra_dict = {'max' : [50, '1', 999, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'high' : [50, '1', 1.5, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'medium' : [50, '1', 1.2, [1.0, 1.0, 1.0, 1.0,1.0]],\n",
    "    #                  'low' : [50, '1', 1.0, [1.0, 1.0, 1.0, 1.0,1.0]]}\n",
    "    \n",
    "    if plan_level == 'max':\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 999  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    elif plan_level == 'high':\n",
    "        month_clv_threshold = 50\n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 1.5 \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    elif plan_level == 'medium':\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1'  \n",
    "        channel_max_adjust = 1.2  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "    else:\n",
    "        plan_level = 'lowv3'\n",
    "        month_clv_threshold = 50  \n",
    "        year_clv_threshold = '1' \n",
    "        channel_max_adjust = 1.0  \n",
    "        channel_preference = [1.0, 1.0, 1.0, 1.0,\n",
    "                              1.0]  \n",
    "\n",
    "    return month_clv_threshold, year_clv_threshold, channel_max_adjust, channel_preference\n",
    "\n",
    "def add_channel_result_col(data, this_month_end):\n",
    "    \"\"\"数据新增列\n",
    "\n",
    "    Args:\n",
    "        data(dataframe): 基础数据\n",
    "\n",
    "    Returns:\n",
    "        dataframe: 新增分配结果列 的数据\n",
    "    \"\"\"\n",
    "    channel_type = [\"com\", \"free\", \"strong_ctrl\", \"normal_ctrl\", \"no_ctrl\"]\n",
    "    data = data.withColumn(\"pred_total_dau\",lit(0.0))\n",
    "    for channel_name in channel_type:\n",
    "        # 干预次数\n",
    "        data = data.withColumn('%s_login_cnt'%channel_name, \n",
    "                                         data[\"result\"].getItem(channel_name))\n",
    "        # DAU\n",
    "        data = data.withColumn(\"pred_%s_dau\"%channel_name, \n",
    "                                         col(\"%s_login_cnt\"%channel_name) * col(\"%s_login_cnt_per_dau\"%channel_name))\n",
    "        # total_DAU\n",
    "        data = data.withColumn(\"pred_total_dau\",\n",
    "                                         col(\"pred_total_dau\") + col(\"%s_login_cnt_per_dau\"%channel_name))\n",
    "    # 增加自然端的数据\n",
    "    data = data.withColumn(\"pred_natural_dau\",col(\"natural_pred_login_cnt_rest\") * col(\"natural_login_cnt_per_dau\"))\n",
    "    data = data.withColumn(\"pred_total_dau\",col(\"pred_total_dau\") + col(\"pred_natural_dau\"))\n",
    "    \n",
    "\n",
    "    data = data.withColumn(\"pred_total_dau\", col(\"pred_total_dau\") * col(\"total_login_dau_ratio\"))\n",
    "    data = data.withColumn('is_solvable', data[\"result\"].getItem(\"flag\"))\n",
    "\n",
    "    # TODO 优先级 P1\n",
    "    data = data.withColumn('priority_level', lit(50))\n",
    "    data = data.withColumn(\"end_time\", lit(this_month_end))  # 本月最后1s\n",
    "    \n",
    "    # TODO 保量相关信息传出\n",
    "    data = data.withColumn('is_guaranteed_by_com', lit(1))\n",
    "    data = data.withColumn('is_guaranteed_by_free', lit(1))\n",
    "    data = data.withColumn('is_guaranteed_by_strong_ctrl', lit(1))\n",
    "    data = data.withColumn('is_guaranteed_by_normal_ctrl', lit(1))\n",
    "    data = data.withColumn('is_guaranteed_by_no_ctrl', lit(1))\n",
    "    \n",
    "   \n",
    "    # 算法中间值\n",
    "    algo_total_info = \"\"\"{\"guaranteed\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0},\n",
    "                            \"channel_max_login_days\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0},\n",
    "                            \"channel_min_login_days\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0},\n",
    "                            \"channel_login_costs\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0},\n",
    "                            \"greedy_result\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0},\n",
    "                            \"result\":{\"com\": 0, \"free\": 0, \"strong_ctrl\": 0, \"normal_ctrl\": 0, \"no_ctrl\": 0}}\"\"\"\n",
    "    \n",
    "    data = data.withColumn(\"algo_total_info\", lit(algo_total_info)) \n",
    "    \n",
    "    # 字段名称修正\n",
    "    rename_cols_dict = {'natural_login_cnt_last_month':'natural_user_last_month_login_cnt',\\\n",
    "                        'com_login_cnt_last_month':'com_user_last_month_login_cnt',\\\n",
    "                        'free_login_cnt_last_month':'free_user_last_month_login_cnt',\\\n",
    "                        'strong_ctrl_login_cnt_last_month':'strong_ctrl_user_last_month_login_cnt',\\\n",
    "                        'normal_ctrl_login_cnt_last_month':'normal_ctrl_user_last_month_login_cnt',\\\n",
    "                        'no_ctrl_login_cnt_last_month':'no_ctrl_user_last_month_login_cnt',\\\n",
    "                        \n",
    "                        'is_guaranteed_by_com':'com_user_base_guarteed_cnt',\\\n",
    "                        'is_guaranteed_by_free':'free_user_base_guarteed_cnt',\\\n",
    "                        'is_guaranteed_by_strong_ctrl':'strong_ctrl_user_base_guarteed_cnt',\\\n",
    "                        'is_guaranteed_by_normal_ctrl':'normal_ctrl_user_base_guarteed_cnt',\\\n",
    "                        'is_guaranteed_by_no_ctrl':'no_ctrl_user_base_guarteed_cnt',\\\n",
    "                        'is_acce_by_com':'com_user_acce_flag',\\\n",
    "                        'is_acce_by_free':'free_user_acce_flag',\\\n",
    "                        'is_acce_by_strong_ctrl':'strong_ctrl_user_acce_flag',\\\n",
    "                        'is_acce_by_normal_ctrl':'normal_ctrl_user_acce_flag',\\\n",
    "                        'is_acce_by_no_ctrl':'no_ctrl_user_acce_flag',\\\n",
    "                            \n",
    "                        'natural_max_login_cnt':'natural_grid_max_login_cnt',\\\n",
    "                        'com_max_login_count':'com_grid_max_login_cnt',\\\n",
    "                        'free_max_login_count':'free_grid_max_login_cnt',\\\n",
    "                        'strong_ctrl_max_login_count':'strong_ctrl_grid_max_login_cnt',\\\n",
    "                        'normal_ctrl_max_login_count':'normal_ctrl_grid_max_login_cnt',\\\n",
    "                        'no_ctrl_max_login_count':'no_ctrl_grid_max_login_cnt',\\\n",
    "                            \n",
    "                        'natural_login_cnt_per_month':'natural_grid_last_month_total_cnt',\\\n",
    "                        'com_login_cnt_per_month':'com_grid_last_month_total_cnt',\\\n",
    "                        'free_login_cnt_per_month':'free_grid_last_month_total_cnt',\\\n",
    "                        'strong_ctrl_login_cnt_per_month':'strong_ctrl_grid_last_month_total_cnt',\\\n",
    "                        'normal_ctrl_login_cnt_per_month':'normal_ctrl_grid_last_month_total_cnt',\\\n",
    "                        'no_ctrl_login_cnt_per_month':'no_ctrl_grid_last_month_total_cnt',\\\n",
    "                            \n",
    "                        'natural_login_cost':'natural_last_login_cost',\\\n",
    "                        'com_login_cost':'com_grid_last_login_cost',\\\n",
    "                        'free_login_cost':'free_grid_last_login_cost',\\\n",
    "                        'strong_ctrl_login_cost':'strong_ctrl_grid_last_login_cost',\\\n",
    "                        'normal_login_cost':'normal_ctrl_grid_last_login_cost',\\\n",
    "                        'no_ctrl_login_cost':'no_ctrl_grid_last_login_cost',\\\n",
    "                            \n",
    "                        'natural_quality_coeff':'natural_grid_quality_coeff',\\\n",
    "                        'com_quality_coeff':'com_grid_quality_coeff',\\\n",
    "                        'free_quality_coeff':'free_grid_quality_coeff',\\\n",
    "                        'strong_ctrl_quality_coeff':'strong_ctrl_grid_quality_coeff',\\\n",
    "                        'normal_ctrl_quality_coeff':'normal_ctrl_grid_quality_coeff',\\\n",
    "                        'no_ctrl_quality_coeff':'no_ctrl_grid_quality_coeff',\\\n",
    "                        \n",
    "                        'natural_login_cnt_per_dau':'natural_grid_login_cnt_per_dau',\\\n",
    "                        'com_login_cnt_per_dau':'com_grid_login_cnt_per_dau',\\\n",
    "                        'free_login_cnt_per_dau':'free_grid_login_cnt_per_dau',\\\n",
    "                        'strong_ctrl_login_cnt_per_dau':'strong_ctrl_grid_login_cnt_per_dau',\\\n",
    "                        'normal_ctrl_login_cnt_per_dau':'normal_grid_login_cnt_per_dau',\\\n",
    "                        'no_ctrl_login_cnt_per_dau':'no_ctrl_grid_login_cnt_per_dau'}\n",
    "    \n",
    "    print('rename_cols_dict',rename_cols_dict)\n",
    "    print(data.columns)\n",
    "\n",
    "    if isinstance(rename_cols_dict, dict):\n",
    "        for old_name, new_name in rename_cols_dict.items():\n",
    "            if old_name in list(data.columns):\n",
    "                print(old_name, new_name)\n",
    "                data = data.withColumnRenamed(old_name, new_name)\n",
    "            else:\n",
    "                print(\"%s not in data\"%old_name)\n",
    "    else:\n",
    "        raise ValueError(\"'columns' should be a dict, like {'old_name_1':'new_name_1', 'old_name_2':'new_name_2'}\")\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "def data_insert_table(data ,table_name ,table_dt ,tabel_dp):\n",
    "    table_cols = ['user_log_acct','user_life_cycle_type_1st','model_a_1st','model_b_1st','goal_group_1st','annual_clv_1st','grid_name_1st','clv_pred_1m',\n",
    "                  'model_a','model_b','model_c','model_l','user_life_cycle_type',\n",
    "                  'login_cnt_mtd','natural_login_cnt_mtd','com_login_cnt_mtd','free_login_cnt_mtd',\n",
    "                  'strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                  'com_user_last_month_login_cnt','free_user_last_month_login_cnt',\n",
    "                  'strong_ctrl_user_last_month_login_cnt','normal_ctrl_user_last_month_login_cnt',\n",
    "                  'no_ctrl_user_last_month_login_cnt','com_user_base_guarteed_cnt','free_user_base_guarteed_cnt',\n",
    "                  'strong_ctrl_user_base_guarteed_cnt','normal_ctrl_user_base_guarteed_cnt','no_ctrl_user_base_guarteed_cnt',\n",
    "                  'com_user_acce_flag','free_user_acce_flag',\n",
    "                  'strong_ctrl_user_acce_flag','normal_ctrl_user_acce_flag','no_ctrl_user_acce_flag',\n",
    "                  'com_grid_max_login_cnt','free_grid_max_login_cnt',\n",
    "                  'strong_ctrl_grid_max_login_cnt','normal_ctrl_grid_max_login_cnt','no_ctrl_grid_max_login_cnt',\n",
    "                  'com_grid_last_month_total_cnt','free_grid_last_month_total_cnt','strong_ctrl_grid_last_month_total_cnt',\n",
    "                  'normal_ctrl_grid_last_month_total_cnt','no_ctrl_grid_last_month_total_cnt',\n",
    "                  'com_grid_quality_coeff','free_grid_quality_coeff','strong_ctrl_grid_quality_coeff',\n",
    "                  'normal_ctrl_grid_quality_coeff','no_ctrl_grid_quality_coeff',  \n",
    "                  'com_grid_login_cnt_per_dau','free_grid_login_cnt_per_dau','strong_ctrl_grid_login_cnt_per_dau',\n",
    "                  'normal_grid_login_cnt_per_dau','no_ctrl_grid_login_cnt_per_dau',\n",
    "                  'com_grid_last_login_cost','free_grid_last_login_cost','strong_ctrl_grid_last_login_cost',\n",
    "                  'normal_ctrl_grid_last_login_cost','no_ctrl_grid_last_login_cost',\n",
    "                  'algo_total_info','natural_pred_login_cnt_rest',\n",
    "                  'com_login_cnt','free_login_cnt','strong_ctrl_login_cnt','normal_ctrl_login_cnt','no_ctrl_login_cnt',\n",
    "                  'priority_level','pred_com_dau','pred_free_dau','pred_strong_ctrl_dau','pred_normal_ctrl_dau','pred_no_ctrl_dau',\n",
    "                  'total_login_dau_ratio','pred_total_dau','is_solvable','end_time','is_malice_user','pred_natural_dau','priority_type'] # 修正1 增加恶意用户 增加pred_natural_dau \n",
    "    print('table_cols', table_cols)\n",
    "    result_data = data[table_cols]\n",
    "    result_data.createOrReplaceTempView('result_data_tmp')\n",
    "\n",
    "    \n",
    "    sql = \"\"\"\n",
    "       INSERT OVERWRITE TABLE {table_name} PARTITION (dt='{part_dt}', priority_type, dp)\n",
    "\n",
    "        select\n",
    "         *,\n",
    "         '{part_dp}' as dp\n",
    "        from\n",
    "        result_data_tmp\n",
    "    \"\"\".format(table_name=table_name, part_dt=table_dt, part_dp=tabel_dp)\n",
    "    print(sql)\n",
    "    spark.sql(sql)\n",
    "    print(\"successful data insert tabel\")\n",
    "    return \n",
    "\n",
    "def juge_how_allocation(run_day, base_data):\n",
    "    \n",
    "    # TODO 5月临时方案 修改为整体方案\n",
    "    first_allocation_day = datetime.datetime.strptime('2022-05-15','%Y-%M-%d')\n",
    "    run_day = datetime.datetime.strptime(run_day,'%Y-%M-%d')\n",
    "    day1_ago_runday = datetime.datetime.strftime(run_day- timedelta(days=1),'%Y-%M-%d')\n",
    "    \n",
    "    delta_day = (run_day-first_allocation_day).days\n",
    "    \n",
    "    if delta_day == 0:\n",
    "        #  首日分配\n",
    "        print(\">\"*10,\"进行首日分配\") \n",
    "        final_data = base_data.withColumn('result',get_allocation_result('dt','month_clv_threshold','year_clv_threshold','channel_max_adjust',\n",
    "                                                         'channel_preference','a1_threshold','priority_type','my_hash_code',\n",
    "                                                         'lower_lift_login_cnt','natural_pred_login_cnt_rest','login_cnt_mtd','natural_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                                                         'is_acce_by_com','is_acce_by_free','is_acce_by_strong_ctrl',\n",
    "                                                         'is_acce_by_normal_ctrl','is_acce_by_no_ctrl',\n",
    "                                                         'com_max_login_count','free_max_login_count','strong_ctrl_max_login_count',\n",
    "                                                         'normal_ctrl_max_login_count','no_ctrl_max_login_count',\n",
    "                                                         'com_login_cost','free_login_cost','strong_ctrl_login_cost','normal_login_cost',\n",
    "                                                         'no_ctrl_login_cost',\n",
    "                                                         'com_quality_coeff','free_quality_coeff','strong_ctrl_quality_coeff',\n",
    "                                                         'normal_ctrl_quality_coeff','no_ctrl_quality_coeff',\n",
    "                                                         'com_login_cnt_per_dau','free_login_cnt_per_dau',\n",
    "                                                         'strong_ctrl_login_cnt_per_dau','normal_ctrl_login_cnt_per_dau',\n",
    "                                                         'no_ctrl_login_cnt_per_dau',\n",
    "                                                         'clv_pred_1m','gmv_year',\n",
    "                                                         'login_cnt_last_month','natural_login_cnt_last_month','com_login_cnt_last_month','free_login_cnt_last_month','strong_ctrl_login_cnt_last_month','normal_ctrl_login_cnt_last_month','no_ctrl_login_cnt_last_month',\n",
    "                                                         'com_login_cnt_mtd','free_login_cnt_mtd','strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','month_hash'))\n",
    "\n",
    "    elif delta_day%3 == 0:\n",
    "        # TODO 高活和低活的调整周期不一样 现在只写了高活\n",
    "        # 3日-高活 渠道内调整 执行首日分配算法\n",
    "        print(\">\"*10,\"进行高活用户 渠道内调整\") \n",
    "        final_data = base_data.withColumn('result',get_allocation_result('dt','month_clv_threshold','year_clv_threshold','channel_max_adjust',\n",
    "                                                         'channel_preference','a1_threshold','priority_type','my_hash_code',\n",
    "                                                         'lower_lift_login_cnt','natural_pred_login_cnt_rest','login_cnt_mtd','natural_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                                                         'is_acce_by_com','is_acce_by_free','is_acce_by_strong_ctrl',\n",
    "                                                         'is_acce_by_normal_ctrl','is_acce_by_no_ctrl',\n",
    "                                                         'com_max_login_count','free_max_login_count','strong_ctrl_max_login_count',\n",
    "                                                         'normal_ctrl_max_login_count','no_ctrl_max_login_count',\n",
    "                                                         'com_login_cost','free_login_cost','strong_ctrl_login_cost','normal_login_cost',\n",
    "                                                         'no_ctrl_login_cost',\n",
    "                                                         'com_quality_coeff','free_quality_coeff','strong_ctrl_quality_coeff',\n",
    "                                                         'normal_ctrl_quality_coeff','no_ctrl_quality_coeff',\n",
    "                                                         'com_login_cnt_per_dau','free_login_cnt_per_dau',\n",
    "                                                         'strong_ctrl_login_cnt_per_dau','normal_ctrl_login_cnt_per_dau',\n",
    "                                                         'no_ctrl_login_cnt_per_dau',\n",
    "                                                         'clv_pred_1m','gmv_year',\n",
    "                                                         'login_cnt_last_month','natural_login_cnt_last_month','com_login_cnt_last_month','free_login_cnt_last_month','strong_ctrl_login_cnt_last_month','normal_ctrl_login_cnt_last_month','no_ctrl_login_cnt_last_month',\n",
    "                                                         'com_login_cnt_mtd','free_login_cnt_mtd','strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','month_hash'))\n",
    "   \n",
    "    elif (delta_day==7) or (delta_day-7)%6==0:\n",
    "        # TODO 无渠道间调整 重复取数 是否可优化\n",
    "        # 7日 监控期，然后高活6d周期 渠道间调整\n",
    "        print(\">\"*10,\"进行高活用户 渠道间调整\") \n",
    "        lastday_data = get_lastday_data_no_allocation(dp, day1_ago_runday)\n",
    "        final_data = lastday_data\n",
    "    \n",
    "    elif delta_day%3 > 0:\n",
    "        # 非首日 非调控期 取昨日分区减去昨日已完成\n",
    "        print(\">\"*10,\"非首日，非调控期，取昨日分区减去昨日已完成\") \n",
    "        lastday_data = get_lastday_data_no_allocation(dp, day1_ago_runday)\n",
    "        final_data = lastday_data\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "@udf(returnType=MapType(StringType(), IntegerType()))\n",
    "def get_allocation_result(part_dt,month_clv_threshold,year_clv_threshold,channel_max_adjust,channel_preference,a1_threshold,priority_type,my_hash_code,\n",
    "                lower_lift_login_cnt, natural_pred_login_cnt_rest,login_cnt_mtd,natural_login_cnt_mtd,no_ctrl_login_cnt_mtd,\n",
    "                is_acce_by_com, is_acce_by_free, is_acce_by_strong_ctrl, is_acce_by_normal_ctrl,is_acce_by_no_ctrl,\n",
    "                com_max_login_count, free_max_login_count, strong_ctrl_max_login_count,normal_ctrl_max_login_count,no_ctrl_max_login_count,\n",
    "                com_login_cost, free_login_cost, strong_ctrl_login_cost, normal_login_cost,no_ctrl_login_cost, \n",
    "                com_quality_coeff,free_quality_coeff,strong_ctrl_quality_coeff,normal_ctrl_quality_coeff,no_ctrl_quality_coeff,\n",
    "                com_login_cnt_per_dau, free_login_cnt_per_dau,  strong_ctrl_login_cnt_per_dau, normal_ctrl_login_cnt_per_dau, no_ctrl_login_cnt_per_dau,\n",
    "                clv_pred_1m,gmv_year,\n",
    "                login_cnt_last_month, natural_login_cnt_last_month,com_login_cnt_last_month,free_login_cnt_last_month,strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month,\n",
    "                com_login_cnt_mtd,free_login_cnt_mtd,strong_ctrl_login_cnt_mtd,normal_ctrl_login_cnt_mtd,month_hash):\n",
    "    \n",
    "\n",
    "    # 用户价值\n",
    "    clv = get_user_clv(clv_pred_1m)\n",
    "    user_label = priority_type\n",
    "    \n",
    "    # 第一层 基础保量\n",
    "    basic_result = BasicGuarantee(com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                                  normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month)\n",
    "    \n",
    "    # 第二层 业务规则  输出业务结果以及对阶跃渠道上限处理\n",
    "    businessrule_result, businessrule_no_allocation_channel, channel_businessrule_max, channel_businessrule_max_add = BusinessRuleSupplement(basic_result, user_label,  year_clv_threshold, gmv_year, clv, month_clv_threshold, \n",
    "                                                com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                                                normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month, \n",
    "                                                my_hash_code, month_hash)\n",
    "    \n",
    "    # 第三层 贪心求解阶跃\n",
    "    # 目标 TODO 获取目标 渠道上限 以及成本写为一个类\n",
    "    # part_dt,lift_login, natura_login, current_login,no_ctrl_login\n",
    "    channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "    target_login_days = get_target_allocation_login(part_dt=part_dt,\n",
    "                                                    lift_login=lower_lift_login_cnt,\n",
    "                                                    natura_login=natural_pred_login_cnt_rest , #用上月自然登录次数替代本月预测v4 (natural_login_cnt_last_month - natural_login_cnt_mtd)\n",
    "                                                    current_login=login_cnt_mtd,\n",
    "                                                    no_ctrl_login=(no_ctrl_login_cnt_last_month - no_ctrl_login_cnt_mtd))\n",
    "\n",
    "    # 获取阶跃渠道上限 & 参数调整（业务加量以及渠道放大）\n",
    "    channel_max_login_days   = get_user_channel_max_func(priority_type, my_hash_code, channel_businessrule_max_add, channel_businessrule_max,  \n",
    "                                                            com_max_login_count, free_max_login_count, strong_ctrl_max_login_count, normal_ctrl_max_login_count,no_ctrl_max_login_count,\n",
    "                                                            com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month, normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month,\n",
    "                                                            is_acce_by_com, is_acce_by_free, is_acce_by_strong_ctrl, is_acce_by_normal_ctrl, is_acce_by_no_ctrl,\n",
    "                                                            month_clv_threshold,channel_max_adjust,channel_preference)\n",
    "    # 渠道成本\n",
    "    channel_login_costs = get_channel_login_costs(channel_type, com_login_cost, free_login_cost, strong_ctrl_login_cost, normal_login_cost, no_ctrl_login_cost,\n",
    "                                                  com_login_cnt_per_dau, free_login_cnt_per_dau, strong_ctrl_login_cnt_per_dau, normal_ctrl_login_cnt_per_dau, no_ctrl_login_cnt_per_dau,\n",
    "                                                  com_quality_coeff, free_quality_coeff, strong_ctrl_quality_coeff, normal_ctrl_quality_coeff, no_ctrl_quality_coeff)\n",
    "\n",
    "    # 求解\n",
    "    greedy_result = GreedySolver(target_login_days, businessrule_no_allocation_channel, businessrule_result, \n",
    "                                 channel_max_login_days,  channel_login_costs)\n",
    "\n",
    "    # 根据用户类型修正渠道分配方案    \n",
    "    # 结果最终修正1 不小于上月用户次数  \n",
    "    final_result = greedy_result\n",
    "    final_result['com'] = math.ceil(max(final_result['com'],com_login_cnt_last_month))\n",
    "    final_result['free'] = math.ceil(max(final_result['free'],free_login_cnt_last_month))\n",
    "    final_result['strong_ctrl'] = math.ceil(max(final_result['strong_ctrl'],strong_ctrl_login_cnt_last_month))\n",
    "    final_result['no_ctrl'] = math.ceil(max(final_result['no_ctrl'],no_ctrl_login_cnt_last_month))\n",
    "    \n",
    "    ## 修正2 可控置零\n",
    "    if user_label == 'A1':\n",
    "        final_result['normal_ctrl'] = 0\n",
    "        # # 短信渠道补量\n",
    "        # if (my_hash_code <= 5):\n",
    "        #     final_result['strong_ctrl'] += 1\n",
    "    else:\n",
    "        final_result['normal_ctrl'] = math.ceil(max(final_result['normal_ctrl'], normal_ctrl_login_cnt_last_month))\n",
    "        final_result['normal_ctrl'] = math.ceil(max(final_result['normal_ctrl'] - normal_ctrl_login_cnt_mtd, 0))\n",
    "    \n",
    "    # 结果最终修正3 减去渠道已完成\n",
    "    final_result['com'] = math.ceil(max(final_result['com'] - com_login_cnt_mtd, 1))\n",
    "    final_result['free'] = math.ceil(max(final_result['free'] - free_login_cnt_mtd, 0))\n",
    "    final_result['strong_ctrl'] = math.ceil(max(final_result['strong_ctrl'] - strong_ctrl_login_cnt_mtd, 0))\n",
    "    final_result['no_ctrl'] = math.ceil(max(final_result['no_ctrl'] - no_ctrl_login_cnt_mtd, 0))    \n",
    "\n",
    "    re = sum(list(final_result.values()))\n",
    "    target_flag = 1 if re >= target_login_days else 0\n",
    "    final_result['flag'] = target_flag       \n",
    "    return final_result\n",
    "\n",
    "def get_user_clv(clv_pred_1m):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        clv_pred_1m (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return max(clv_pred_1m,0)\n",
    "\n",
    "# 返回值必须全为Int, 否则类型不对的变量会被设为null\n",
    "# @udf(returnType=MapType(StringType(), IntegerType()))\n",
    "def BasicGuarantee(com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month, normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month):\n",
    "    \"\"\"获取渠道保量(用户上月该渠道引流成功次数,向上取整),渠道保量作为用户渠引流成功下限\n",
    "\n",
    "    Args:\n",
    "        com_login_cnt_last_month (_type_): _description_\n",
    "        free_login_cnt_last_month (_type_): _description_\n",
    "        strong_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        normal_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        no_ctrl_login_cnt_last_month (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        dict(str:int): 各渠道保量次数\n",
    "    \"\"\"\n",
    "    channel_guaranteed = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    \n",
    "    channel_guaranteed['com'] = max(math.ceil(com_login_cnt_last_month),0)\n",
    "    channel_guaranteed['free'] = max(math.ceil(free_login_cnt_last_month),0)\n",
    "    channel_guaranteed['strong_ctrl'] = max(math.ceil(strong_ctrl_login_cnt_last_month),0)\n",
    "    channel_guaranteed['normal_ctrl'] = max(math.ceil(normal_ctrl_login_cnt_last_month),0)\n",
    "    channel_guaranteed['no_ctrl'] = max(math.ceil(no_ctrl_login_cnt_last_month),0)\n",
    "    \n",
    "    return channel_guaranteed\n",
    "\n",
    "def BusinessRuleSupplement(basic_result, user_label,  year_clv_threshold, gmv_year, clv, month_clv_threshold, \n",
    "                           com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                           normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month, \n",
    "                           my_hash_code,month_hash):\n",
    "    \"\"\"根据用户逻辑进行方案调整\n",
    "\n",
    "    \"\"\"\n",
    "    channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "    businessrule_no_allocation_channel = []\n",
    "    businessrule_plan = basic_result\n",
    "    channel_businessrule_max = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    channel_businessrule_max_add = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    \n",
    "   \n",
    "    year_clv_threshold = 600.0\n",
    "\n",
    "    if user_label == 'A1':\n",
    "        # 根据业务逻辑调整渠道上限\n",
    "        com_adjust_pra = 1.2\n",
    "        hash_precent = 99\n",
    "        msg_add = 1\n",
    "    \n",
    "        # 京东可控置0 \n",
    "        businessrule_no_allocation_channel.append('normal_ctrl')\n",
    "\n",
    "        # 商业化渠道补量\n",
    "        # A1人群的商业化补量不超过20%\n",
    "        # 商业化在上月基础上调整1.2倍的抽样分配结果\n",
    "        com_adjust_day = sampling_supplement(channel_days = com_login_cnt_last_month,\n",
    "                                             adjust_day = com_adjust_pra * com_login_cnt_last_month, # 1.2\n",
    "                                             my_hash_code = my_hash_code)\n",
    "        \n",
    "        channel_businessrule_max['com'] = com_adjust_day  # A1人群的商业化补量不超过20%\n",
    "   \n",
    "        # 免费渠道补量\n",
    "        businessrule_plan['free'] +=  1 \n",
    "        channel_businessrule_max_add['free'] +=1\n",
    "        \n",
    "        # # 短信渠道补量\n",
    "        # if (my_hash_code <= hash_precent):\n",
    "        #     businessrule_plan['strong_ctrl'] += msg_add\n",
    "        #     channel_businessrule_max_add['strong_ctrl'] += msg_add     \n",
    "        # else:\n",
    "        #     pass\n",
    "       \n",
    "    elif user_label == 'A2':\n",
    "        if clv <= month_clv_threshold:\n",
    "            businessrule_plan = basic_result\n",
    "            \n",
    "            # clv<50, 如果京东可控保量=0 则按月维度抽样（50%+1）\n",
    "            if businessrule_plan['normal_ctrl'] == 0  and month_hash < 50:\n",
    "                businessrule_plan['normal_ctrl'] +=1\n",
    "                channel_businessrule_max_add['normal_ctrl'] += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    elif user_label == 'B':\n",
    "        # 返回基础方案 所有渠道不分配\n",
    "        businessrule_plan =  basic_result \n",
    "        businessrule_no_allocation_channel += channel_type      \n",
    "\n",
    "    elif user_label == 'C':\n",
    "        if gmv_year <= year_clv_threshold:\n",
    "            # 返回基础方案 所有渠道不分配\n",
    "            businessrule_plan = basic_result\n",
    "            businessrule_no_allocation_channel += channel_type \n",
    "        else:\n",
    "            businessrule_plan['normal_ctrl'] = min(20, 1.5 * normal_ctrl_login_cnt_last_month, businessrule_plan['normal_ctrl'])\n",
    "    \n",
    "    return businessrule_plan, businessrule_no_allocation_channel, channel_businessrule_max, channel_businessrule_max_add\n",
    "\n",
    "def sampling_supplement(channel_days,adjust_day,my_hash_code):\n",
    "    \"\"\"按随机抽样的方法对渠道天数进行修正，\n",
    "       举例说明: \n",
    "       假设该渠道有100人, 渠道干预次数默认值为2, 总干预次数为200\n",
    "       整体干预次数要提升1.2倍即240, 则每个人的渠道干预次数为2.4, \n",
    "       干预次数按照抽样方式调整, 所有人干预次数调整为2, 40%的人在2的基础上再增加1次, 保证整体的干预次数是调整了1.2倍\n",
    "\n",
    "    Args:\n",
    "        channel_days (_type_): 渠道干预天数\n",
    "        adjust_day (double): 需要调整的天数\n",
    "        my_hash_code (string): 用户hash值, 用于抽样\n",
    "        base_flag (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: 调整后的渠道干预天数\n",
    "    \"\"\"\n",
    "\n",
    "    adjust_day = adjust_day * 100 # 2.4\n",
    "    \n",
    "    adjust_day_base , adjust_day_hash_add = adjust_day//100 , int(adjust_day%100)\n",
    "    \n",
    "    # print(adjust_day_base , adjust_day_hash_add)\n",
    "    channel_days = adjust_day_base # 2\n",
    "    \n",
    "    if my_hash_code <= adjust_day_hash_add: # 0.4\n",
    "        channel_days += 1\n",
    "    \n",
    "    return channel_days\n",
    "\n",
    "def get_target_allocation_login(part_dt,lift_login, natura_login, current_login,no_ctrl_login):\n",
    "    \"\"\"获取目标登录次数\n",
    "\n",
    "    Args:\n",
    "        lift_login (_type_): 阶跃所需引流次数\n",
    "        natura_login (_type_): 本月自然预测登录次数\n",
    "        current_login (_type_): 当前登录次数\n",
    "        no_ctrl_login: 不可控渠道本月登录次数\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # part_dt = '2022-03-31'\n",
    "    # TODO 当前登录次数要用各渠道*质量归一后求和数据，当前使用的是事实数据\n",
    "    today =datetime.datetime.strptime(part_dt,'%Y-%m-%d') + timedelta(days=1)\n",
    "    if today.day==1: \n",
    "        # 每月1号方案需要对当前登录次数置零\n",
    "        current_login = min(current_login,0)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return lift_login - current_login - natura_login - no_ctrl_login\n",
    "\n",
    "def get_user_channel_max_func(priority_type,my_hash_code, channel_businessrule_max_add, channel_businessrule_max, \n",
    "                    com_max_login_count, free_max_login_count, strong_ctrl_max_login_count, normal_ctrl_max_login_count,no_ctrl_max_login_count,\n",
    "                    com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month, normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month,\n",
    "                    is_acce_by_com, is_acce_by_free, is_acce_by_strong_ctrl, is_acce_by_normal_ctrl, is_acce_by_no_ctrl,\n",
    "                    month_clv_threshold,channel_max_adjust,channel_preference):\n",
    "    \"\"\"返回用户各渠道上下限\n",
    "    Args:\n",
    "        priority_type (str): 用户标签\n",
    "        com_max_login_count (_type_): 商业化渠道上限(格子)\n",
    "        free_max_login_count (_type_): 免费渠道上限(格子)\n",
    "        strong_ctrl_max_login_count (_type_):强控渠道上限(格子)\n",
    "        normal_ctrl_max_login_count (_type_): 可控渠道上限(格子)\n",
    "        no_ctrl_max_login_count (_type_):不可控渠道上限(格子)\n",
    "        com_login_cnt_last_month (_type_):商业化渠道上月干预次数(用户)\n",
    "        free_login_cnt_last_month (_type_): 免费渠道上月干预次数(用户)\n",
    "        strong_ctrl_login_cnt_last_month (_type_): 强控渠道上月干预次数(用户)\n",
    "        normal_ctrl_login_cnt_last_month (_type_):可控渠道上月干预次数(用户)\n",
    "        no_ctrl_login_cnt_last_month (_type_): 不可控渠道上月干预次数(用户)\n",
    "        is_acce_by_com (bool): 商业化是否可达\n",
    "        is_acce_by_free (bool): 免费是否可达\n",
    "        is_acce_by_strong_ctrl (bool): 强控是否可达\n",
    "        is_acce_by_normal_ctrl (bool): 可控是否可达\n",
    "        is_acce_by_no_ctrl (bool): 不可控是否可达\n",
    "        is_guaranteed_by_com (bool): 商业化保量次数\n",
    "        is_guaranteed_by_free (bool): _description_\n",
    "        is_guaranteed_by_strong_ctrl (bool): _description_\n",
    "        is_guaranteed_by_normal_ctrl (bool): _description_\n",
    "        is_guaranteed_by_no_ctrl (bool): _description_\n",
    "        month_clv_threshold (_type_): a人群划分\n",
    "        channel_max_adjust (_type_): 方案档位调节系数\n",
    "        channel_preference (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        channel_max_login_days(dict): 用户各渠道上限\n",
    "        channel_min_login_days(dict): 用户各渠道下限\n",
    "    \"\"\"\n",
    "    \n",
    "    # channel_type = ['com','free','strong_ctrl','normal_ctrl','no_ctrl']\n",
    "    # 获得channel_max_login_days\n",
    "    is_acce_by_com= is_acce_by_com if is_acce_by_com else 1\n",
    "    is_acce_by_free= is_acce_by_free if is_acce_by_free else 1\n",
    "    is_acce_by_strong_ctrl= is_acce_by_strong_ctrl if is_acce_by_strong_ctrl else 1\n",
    "    is_acce_by_normal_ctrl= is_acce_by_normal_ctrl if is_acce_by_normal_ctrl else 1\n",
    "    is_acce_by_no_ctrl= is_acce_by_no_ctrl if is_acce_by_no_ctrl else 1\n",
    "\n",
    "    channel_max_login_days = {'com' :is_acce_by_com,\n",
    "                              'free':is_acce_by_free,\n",
    "                              'strong_ctrl':is_acce_by_strong_ctrl,\n",
    "                              'normal_ctrl':is_acce_by_normal_ctrl,\n",
    "                              'no_ctrl':is_acce_by_no_ctrl}\n",
    "    # 参数2 channel_max_adjust\n",
    "    if channel_max_adjust == 999:\n",
    "        channel_max_login_days['com'] = math.ceil(com_max_login_count) if is_acce_by_com >0 else channel_max_login_days['com'] \n",
    "        channel_max_login_days['free'] = math.ceil(free_max_login_count) if is_acce_by_free >0 else channel_max_login_days['free'] \n",
    "        channel_max_login_days['strong_ctrl'] = math.ceil(strong_ctrl_max_login_count) if is_acce_by_strong_ctrl >0 else channel_max_login_days['strong_ctrl'] \n",
    "        channel_max_login_days['normal_ctrl'] = math.ceil(normal_ctrl_max_login_count) if is_acce_by_normal_ctrl >0 else channel_max_login_days['normal_ctrl'] \n",
    "        \n",
    "    else:\n",
    "        # 上限修正:  1.2*上月>上限， 取上限； 1.2*上月<=上限，取1.2*上月\n",
    "        # 随机抽样法调整渠道上限\n",
    "        if (com_login_cnt_last_month * channel_max_adjust) > com_max_login_count:\n",
    "            channel_max_login_days['com'] = com_max_login_count\n",
    "        else:\n",
    "            channel_max_login_days['com'] = sampling_supplement(channel_days = channel_max_login_days['com'],\n",
    "                                                                adjust_day = com_login_cnt_last_month * channel_max_adjust,\n",
    "                                                                my_hash_code = my_hash_code)\n",
    "        # free 上限修正:  1.2*上月>上限，  取上限； 1.2*上月<=上限，取1.2*上月\n",
    "        if (free_login_cnt_last_month * channel_max_adjust) > free_max_login_count:\n",
    "            channel_max_login_days['free'] = free_max_login_count\n",
    "        else:    \n",
    "            channel_max_login_days['free'] = sampling_supplement(channel_days = channel_max_login_days['free'] , \n",
    "                                                             adjust_day = free_login_cnt_last_month * channel_max_adjust,\n",
    "                                                             my_hash_code = my_hash_code)\n",
    "        # strong 上限修正:  1.2*上月>上限，  取上限； 1.2*上月<=上限，取1.2*上月    \n",
    "        if (strong_ctrl_login_cnt_last_month * channel_max_adjust) > strong_ctrl_max_login_count:\n",
    "            channel_max_login_days['strong_ctrl'] = strong_ctrl_max_login_count\n",
    "        else:      \n",
    "            channel_max_login_days['strong_ctrl'] = sampling_supplement(channel_days = channel_max_login_days['strong_ctrl'],\n",
    "                                                            adjust_day = strong_ctrl_login_cnt_last_month * channel_max_adjust,\n",
    "                                                            my_hash_code = my_hash_code)\n",
    "        # normal  上限修正:  1.2*上月>上限，取上限； 1.2*上月<=上限，取1.2*上月  \n",
    "        if (normal_ctrl_login_cnt_last_month * channel_max_adjust) > normal_ctrl_max_login_count:\n",
    "            channel_max_login_days['normal_ctrl'] = normal_ctrl_max_login_count\n",
    "        else:    \n",
    "            channel_max_login_days['normal_ctrl'] = sampling_supplement(channel_days = channel_max_login_days['normal_ctrl'],\n",
    "                                                            adjust_day = normal_ctrl_login_cnt_last_month * channel_max_adjust,\n",
    "                                                            my_hash_code = my_hash_code)\n",
    "        \n",
    "    channel_max_login_days['no_ctrl'] = math.ceil(1.0 * no_ctrl_login_cnt_last_month)\n",
    "    \n",
    "    # 按业务规则修正渠道上限 不超过业务逻辑上限\n",
    "    # 业务规则加量则 渠道上限加量\n",
    "    for channel in channel_max_login_days:\n",
    "        channel_max_login_days[channel] += channel_businessrule_max_add[channel]\n",
    "        channel_max_login_days[channel] = min(channel_max_login_days[channel], channel_businessrule_max[channel])\n",
    "\n",
    "\n",
    "    # 获得channel_min_login_days\n",
    "    # is_guaranteed_by_com = is_guaranteed_by_com if is_guaranteed_by_com else 1\n",
    "    # is_guaranteed_by_free = is_guaranteed_by_free if is_guaranteed_by_free else 1\n",
    "    # is_guaranteed_by_strong_ctrl = is_guaranteed_by_strong_ctrl if is_guaranteed_by_strong_ctrl else 0\n",
    "    # is_guaranteed_by_normal_ctrl = is_guaranteed_by_normal_ctrl if is_guaranteed_by_normal_ctrl else 0\n",
    "    # is_guaranteed_by_no_ctrl = is_guaranteed_by_no_ctrl if is_guaranteed_by_no_ctrl else 0\n",
    "\n",
    "    # channel_min_login_days = {'com' : is_guaranteed_by_com,\n",
    "    #                           'free' : is_guaranteed_by_free,\n",
    "    #                           'strong_ctrl' : is_guaranteed_by_strong_ctrl,\n",
    "    #                           'normal_ctrl' : is_guaranteed_by_normal_ctrl,\n",
    "    #                           'no_ctrl' : is_guaranteed_by_no_ctrl} \n",
    "    # # 最大最小修正\n",
    "    # # TODO verify this\n",
    "    # for c_name in channel_max_login_days:\n",
    "    #     channel_max_day,channel_min_day = channel_max_login_days[c_name] , channel_min_login_days[c_name]\n",
    "    #     channel_max_login_days[c_name], channel_min_login_days[c_name] = max([channel_max_day, channel_min_day]), min([channel_max_day,channel_min_day])\n",
    "\n",
    "    return channel_max_login_days\n",
    "\n",
    "def get_channel_login_costs(channel_type,\n",
    "                            com_login_cost,free_login_cost,strong_ctrl_login_cost,normal_login_cost,no_ctrl_login_cost,\n",
    "                            com_login_cnt_per_dau,free_login_cnt_per_dau,strong_ctrl_login_cnt_per_dau,normal_ctrl_login_cnt_per_dau,no_ctrl_login_cnt_per_dau,\n",
    "                            com_quality_coeff,free_quality_coeff,strong_ctrl_quality_coeff,normal_quality_coeff,no_ctrl_quality_coeff):\n",
    "    \"\"\"  返回渠道成本\n",
    "\n",
    "    Args:\n",
    "        channel_type (_type_): _description_\n",
    "        com_login_cost (_type_): _description_\n",
    "        free_login_cost (_type_): _description_\n",
    "        strong_ctrl_login_cost (_type_): _description_\n",
    "        normal_login_cost (_type_): _description_\n",
    "        no_ctrl_login_cost (_type_): _description_\n",
    "        com_login_cnt_per_dau (_type_): _description_\n",
    "        free_login_cnt_per_dau (_type_): _description_\n",
    "        strong_ctrl_login_cnt_per_dau (_type_): _description_\n",
    "        normal_ctrl_login_cnt_per_dau (_type_): _description_\n",
    "        no_ctrl_login_cnt_per_dau (_type_): _description_\n",
    "        com_quality_coeff (_type_): _description_\n",
    "        free_quality_coeff (_type_): _description_\n",
    "        strong_ctrl_quality_coeff (_type_): _description_\n",
    "        normal_quality_coeff (_type_): _description_\n",
    "        no_ctrl_quality_coeff (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    channel_cost = [com_login_cost,free_login_cost,strong_ctrl_login_cost,normal_login_cost,no_ctrl_login_cost]\n",
    "    channel_pre_dau = [com_login_cnt_per_dau,free_login_cnt_per_dau,strong_ctrl_login_cnt_per_dau,normal_ctrl_login_cnt_per_dau,no_ctrl_login_cnt_per_dau,]\n",
    "    channel_coeff = [com_quality_coeff,free_quality_coeff,strong_ctrl_quality_coeff,normal_quality_coeff,no_ctrl_quality_coeff]\n",
    "\n",
    "    dau_cost =[]\n",
    "    for i in range(len(channel_cost)):\n",
    "        if (channel_pre_dau[i] > 0 ): \n",
    "            # check\n",
    "            cost = channel_cost[i] / channel_pre_dau[i] / channel_coeff[i]\n",
    "        else:\n",
    "            cost = channel_cost[i]\n",
    "        dau_cost.append(cost)\n",
    "\n",
    "    return dict(zip(channel_type, dau_cost))\n",
    "\n",
    "\n",
    "def GreedySolver(target_login_days, businessrule_no_allocation_channel, businessrule_result, \n",
    "                channel_max_login_days,  channel_login_costs):\n",
    "\n",
    "    # channel_type = ['com','free','strong_ctrl','normal_ctrl','no_ctrl']、\n",
    "    # 业务规则置零渠道  \n",
    "    no_allocation_channel_list = businessrule_no_allocation_channel\n",
    "    no_allocation_channel_list.append('no_ctrl')\n",
    "    # 业务规则输出的方案结果\n",
    "    greedy_plan = businessrule_result\n",
    "\n",
    "    login_costs_dict = channel_login_costs\n",
    "    sorted_costs = sorted(login_costs_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "\n",
    "    for i in range(len(sorted_costs)):    \n",
    "        \n",
    "        used_day = 0\n",
    "        index = sorted_costs[i][0]\n",
    "        # 被分配的次数 = 目标次数 - 渠道已分配的次数（保量+业务补量）\n",
    "        should_target_login_cnt = target_login_days - businessrule_result[index]\n",
    "        \n",
    "        # 渠道不可分配，则跳过\n",
    "        if index in no_allocation_channel_list:\n",
    "            continue\n",
    "        \n",
    "        # 渠道上限修正为 渠道上限 - 已分配次数\n",
    "        channel_max_day = math.ceil(channel_max_login_days[index])\n",
    "        channel_max_day = channel_max_day - businessrule_result[index]\n",
    "\n",
    "        used_day = min(channel_max_day, should_target_login_cnt)\n",
    "\n",
    "        target_login_days -= used_day\n",
    "        target_login_days = max(0, target_login_days)\n",
    "\n",
    "        greedy_plan[index] += used_day\n",
    "\n",
    "    return greedy_plan\n",
    "\n",
    "def get_lastday_data_no_allocation(part_dp, part_dt):\n",
    "    \n",
    "    used_sql = \"\"\"\n",
    "        SELECT\n",
    "            user_log_acct,\n",
    "            user_life_cycle_type_1st,\n",
    "            model_a_1st,\n",
    "            model_b_1st,\n",
    "            goal_group_1st,\n",
    "            annual_clv_1st,\n",
    "            grid_name_1st,\n",
    "            clv_pred_1m,\n",
    "            model_a,\n",
    "            model_b,\n",
    "            model_c,\n",
    "            model_l,\n",
    "            user_life_cycle_type,\n",
    "            login_cnt_mtd,\n",
    "            natural_login_cnt_mtd,\n",
    "            com_login_cnt_mtd,\n",
    "            free_login_cnt_mtd,\n",
    "            strong_ctrl_login_cnt_mtd,\n",
    "            normal_ctrl_login_cnt_mtd,\n",
    "            no_ctrl_login_cnt_mtd,\n",
    "            com_user_last_month_login_cnt,\n",
    "            free_user_last_month_login_cnt,\n",
    "            strong_ctrl_user_last_month_login_cnt,\n",
    "            normal_ctrl_user_last_month_login_cnt,\n",
    "            no_ctrl_user_last_month_login_cnt,\n",
    "            com_user_base_guarteed_cnt,\n",
    "            free_user_base_guarteed_cnt,\n",
    "            strong_ctrl_user_base_guarteed_cnt,\n",
    "            normal_ctrl_user_base_guarteed_cnt,\n",
    "            no_ctrl_user_base_guarteed_cnt,\n",
    "            com_user_acce_flag,\n",
    "            free_user_acce_flag,\n",
    "            strong_ctrl_user_acce_flag,\n",
    "            normal_ctrl_user_acce_flag,\n",
    "            no_ctrl_user_acce_flag,\n",
    "            com_grid_max_login_cnt,\n",
    "            free_grid_max_login_cnt,\n",
    "            strong_ctrl_grid_max_login_cnt,\n",
    "            normal_ctrl_grid_max_login_cnt,\n",
    "            no_ctrl_grid_max_login_cnt,\n",
    "            com_grid_last_month_total_cnt,\n",
    "            free_grid_last_month_total_cnt,\n",
    "            strong_ctrl_grid_last_month_total_cnt,\n",
    "            normal_ctrl_grid_last_month_total_cnt,\n",
    "            no_ctrl_grid_last_month_total_cnt,\n",
    "            com_grid_quality_coeff,\n",
    "            free_grid_quality_coeff,\n",
    "            strong_ctrl_grid_quality_coeff,\n",
    "            normal_ctrl_grid_quality_coeff,\n",
    "            no_ctrl_grid_quality_coeff,\n",
    "            com_grid_login_cnt_per_dau,\n",
    "            free_grid_login_cnt_per_dau,\n",
    "            strong_ctrl_grid_login_cnt_per_dau,\n",
    "            normal_grid_login_cnt_per_dau,\n",
    "            no_ctrl_grid_login_cnt_per_dau,\n",
    "            com_grid_last_login_cost,\n",
    "            free_grid_last_login_cost,\n",
    "            strong_ctrl_grid_last_login_cost,\n",
    "            normal_ctrl_grid_last_login_cost,\n",
    "            no_ctrl_grid_last_login_cost,\n",
    "            algo_total_info,\n",
    "            natural_pred_login_cnt_rest,\n",
    "            case when (com_login_cnt - com_login_cnt_mtd)>=0 then (com_login_cnt - com_login_cnt_mtd)\n",
    "                else 0 end as com_login_cnt,\n",
    "            case when (free_login_cnt - free_login_cnt_mtd)>=0 then (free_login_cnt - free_login_cnt_mtd)\n",
    "                else 0 end as free_login_cnt,\n",
    "            case when (strong_ctrl_login_cnt - strong_ctrl_login_cnt_mtd)>=0 then (strong_ctrl_login_cnt - strong_ctrl_login_cnt_mtd)\n",
    "                else 0 end as strong_ctrl_login_cnt,\n",
    "            case when (normal_ctrl_login_cnt - normal_ctrl_login_cnt_mtd)>=0 then (normal_ctrl_login_cnt - normal_ctrl_login_cnt_mtd)\n",
    "                else 0 end as normal_ctrl_login_cnt,\n",
    "            case when (no_ctrl_login_cnt - no_ctrl_login_cnt_mtd)>=0 then (no_ctrl_login_cnt - no_ctrl_login_cnt_mtd)\n",
    "                else 0 end as no_ctrl_login_cnt,\n",
    "            priority_level,\n",
    "            pred_com_dau,\n",
    "            pred_free_dau,\n",
    "            pred_strong_ctrl_dau,\n",
    "            pred_normal_ctrl_dau,\n",
    "            pred_no_ctrl_dau,\n",
    "            total_login_dau_ratio,\n",
    "            pred_total_dau,\n",
    "            case when (com_login_cnt + free_login_cnt + strong_ctrl_login_cnt + normal_ctrl_login_cnt + no_ctrl_login_cnt)>= (lower_lift_login_cnt-login_cnt_mtd) then 1\n",
    "                else 0 end as is_solvable,\n",
    "            end_time,\n",
    "            is_malice_user,\n",
    "            pred_natural_dau,\n",
    "            priority_type\n",
    "        FROM \n",
    "            app.app_yhzz_umc_algo_pin_interim\n",
    "        where \n",
    "            dt = '{part_dt}'\n",
    "            and dp ='{part_dp}'\n",
    "        )interim \n",
    "        left join\n",
    "        \n",
    "        (\n",
    "        select\n",
    "        -- 目标登录次数\n",
    "        grid_name_1st,\n",
    "            COALESCE(lower_lift_login_cnt,0) as lower_lift_login_cnt\n",
    "\n",
    "        FROM\n",
    "            app.app_yhzz_umc_unit_grid\n",
    "        WHERE\n",
    "            dt = '{part_dt}'\n",
    "            AND grid_name_1st is not null\n",
    "            AND is_grid_valid = 1\n",
    "        )grid on interim.grid_name_1st  = grid.grid_name_1st\n",
    "\n",
    "    \"\"\".format(part_dt = part_dt, part_dp = part_dp)\n",
    "    \n",
    "    print(\"get lastday data sql\", used_sql)\n",
    "    data = spark.sql(used_sql)\n",
    "    data.cache()\n",
    "    print(\"data columns\", data.columns)\n",
    "    print(\"data dtypes\", data.dtypes)\n",
    "\n",
    "    return data\n",
    "\n",
    "'''\n",
    "def get_base_plan(result, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                  strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_mont):\n",
    "    \"\"\"用户兜底方案\n",
    "\n",
    "    Args:\n",
    "        result (_type_): _description_\n",
    "        com_login_cnt_last_month (_type_): _description_\n",
    "        free_login_cnt_last_month (_type_): _description_\n",
    "        strong_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        normal_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        no_ctrl_login_cnt_last_mont (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        dict: 用户各渠道兜底干预次数\n",
    "    \"\"\"\n",
    "    # greedy_result = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "    base_result = result\n",
    "    base_result['com'] = math.ceil(com_login_cnt_last_month) # 向上取整\n",
    "    base_result['free'] = math.ceil(free_login_cnt_last_month) # 向上取整\n",
    "    base_result['strong_ctrl'] = math.ceil(strong_ctrl_login_cnt_last_month) # 向上取整\n",
    "    base_result['normal_ctrl'] = math.ceil(normal_ctrl_login_cnt_last_month) # 向上取整\n",
    "    base_result['no_ctrl'] = math.ceil(no_ctrl_login_cnt_last_mont) # 向上取整\n",
    "\n",
    "    return base_result\n",
    "'''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 获取基础参数\n",
    "    day_ago_1 =  sys.argv[1] # T-1\n",
    "    dp = sys.argv[2] #  [low,medium,high,max]\n",
    "    now = datetime.datetime.strptime(day_ago_1, '%Y-%m-%d')\n",
    "    day_ago_1 =  datetime.datetime.strptime(day_ago_1, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    now_month = now.month\n",
    "    this_month_end = datetime.datetime.strftime(datetime.datetime(now.year, now.month + 1, 1) - timedelta(seconds=1),\n",
    "                                                '%Y-%m-%d %H:%M:%S')\n",
    "    table_name = 'app.app_yhzz_umc_algo_pin_interim'\n",
    "    \n",
    "    # 根据方案档位，获取方案参数\n",
    "    print(\">\"*10,\"get plan pra\")\n",
    "    a1_threshold = 30\n",
    "    month_clv_threshold,  year_clv_threshold, channel_max_adjust, channel_preference = get_plan_pra(plan_level = dp)\n",
    "\n",
    "    print('-----model params-----')\n",
    "    print('day_ago_1(table_dt):   ', day_ago_1)\n",
    "    print('this_month_end:        ', this_month_end)\n",
    "    print('dp(table_dp):          ', dp)\n",
    "    print('table_name:            ', table_name)\n",
    "    print('month_clv_threshold:   ', month_clv_threshold)\n",
    "    print('year_clv_threshold:    ', year_clv_threshold)\n",
    "    print('channel_max_adjust:    ', channel_max_adjust)\n",
    "    print('channel_preference:    ', channel_preference)\n",
    "    print('a1_threshold:          ', a1_threshold)\n",
    "\n",
    "    \n",
    "    # 获取base数据\n",
    "    print(\">\"*10,\"get base data\")\n",
    "    base_data = get_base_data(part_dt = day_ago_1,\n",
    "                              part_month= now_month)\n",
    "\n",
    "    # 存储参数结果\n",
    "    base_data = base_data.withColumn('month_clv_threshold', lit(month_clv_threshold))\n",
    "    base_data = base_data.withColumn('year_clv_threshold', lit(year_clv_threshold))\n",
    "    base_data = base_data.withColumn('channel_max_adjust', lit(channel_max_adjust))\n",
    "    base_data = base_data.withColumn('channel_preference', array([lit(x) for x in channel_preference]))\n",
    "    base_data = base_data.withColumn('a1_threshold', lit(a1_threshold))\n",
    "\n",
    "\n",
    "    # 进行分配\n",
    "    print(\">\"*10,\"根据日期判断分配方式 进行流量分配\") \n",
    "    base_data = juge_how_allocation(run_day = day_ago_1,\n",
    "                                    base_data = base_data)\n",
    "    \n",
    "\n",
    "    print(\">\"*10,\"数据处理:新增渠道引流登端结果数据列等\")\n",
    "    base_data = add_channel_result_col(data = base_data,\n",
    "                                       this_month_end = this_month_end)    \n",
    "    \n",
    "    print(\">\"*10,\"基础校验\")\n",
    "    # todo 基础数据校验\n",
    "    print(\">\"*10,\"写表\")\n",
    "    \n",
    "    data_insert_table(data = base_data,\n",
    "                      table_name = table_name,\n",
    "                      table_dt = day_ago_1,\n",
    "                      tabel_dp = dp)    \n",
    "    \n",
    "    # current_time放在程序的末尾\n",
    "    current_time = time.time()\n",
    "    print(\"运行时间为\" + str(current_time - old_time) + \"s\")                                                                                                                                                                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重构函数\n",
    "\n",
    "@udf(returnType=MapType(StringType(), IntegerType()))\n",
    "def get_result(part_dt,month_clv_threshold,year_clv_threshold,channel_max_adjust,channel_preference,a1_threshold,priority_type,my_hash_code,\n",
    "                lower_lift_login_cnt, natural_pred_login_cnt_rest,login_cnt_mtd,natural_login_cnt_mtd,no_ctrl_login_cnt_mtd,\n",
    "                is_acce_by_com, is_acce_by_free, is_acce_by_strong_ctrl, is_acce_by_normal_ctrl,is_acce_by_no_ctrl,\n",
    "                com_max_login_count, free_max_login_count, strong_ctrl_max_login_count,normal_ctrl_max_login_count,no_ctrl_max_login_count,\n",
    "                is_guaranteed_by_com, is_guaranteed_by_free, is_guaranteed_by_strong_ctrl,is_guaranteed_by_normal_ctrl, \n",
    "                is_guaranteed_by_no_ctrl,\n",
    "                com_login_cost, free_login_cost, strong_ctrl_login_cost, normal_login_cost,no_ctrl_login_cost, \n",
    "                com_quality_coeff,free_quality_coeff,strong_ctrl_quality_coeff,normal_ctrl_quality_coeff,no_ctrl_quality_coeff,\n",
    "                com_login_cnt_per_dau, free_login_cnt_per_dau,  strong_ctrl_login_cnt_per_dau, normal_ctrl_login_cnt_per_dau, no_ctrl_login_cnt_per_dau,\n",
    "                clv_pred_1m,gmv_year,\n",
    "                login_cnt_last_month,\n",
    "                natural_login_cnt_last_month,com_login_cnt_last_month,free_login_cnt_last_month,strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month,\n",
    "                com_login_cnt_mtd,free_login_cnt_mtd,strong_ctrl_login_cnt_mtd,normal_ctrl_login_cnt_mtd,month_hash):\n",
    "# 修正3 处理渠道上限 减掉各渠道mtd值\n",
    "    channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "\n",
    "    # 目标\n",
    "    print('target') # part_dt,lift_login, natura_login, current_login,no_ctrl_login\n",
    "    target_login_days = get_target_allocation_login(part_dt = part_dt,\n",
    "                                              lift_login =lower_lift_login_cnt,\n",
    "                                              natura_login = (natural_login_cnt_last_month - natural_login_cnt_mtd), #用上月自然登录次数替代本月预测v4\n",
    "                                              current_login = login_cnt_mtd,\n",
    "                                              no_ctrl_login = (no_ctrl_login_cnt_last_month-no_ctrl_login_cnt_mtd))\n",
    "    # 渠道上下限 & 参数调整\n",
    "    channel_max_login_days, channel_min_login_days  = get_channel_max_and_min_func(priority_type,my_hash_code,\n",
    "                                                                                    com_max_login_count, free_max_login_count, strong_ctrl_max_login_count, normal_ctrl_max_login_count,no_ctrl_max_login_count,\n",
    "                                                                                    com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month, normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month,\n",
    "                                                                                    is_acce_by_com, is_acce_by_free, is_acce_by_strong_ctrl, is_acce_by_normal_ctrl, is_acce_by_no_ctrl,\n",
    "                                                                                    is_guaranteed_by_com, is_guaranteed_by_free, is_guaranteed_by_strong_ctrl,is_guaranteed_by_normal_ctrl, is_guaranteed_by_no_ctrl,\n",
    "                                                                                    month_clv_threshold,channel_max_adjust,channel_preference)\n",
    "\n",
    "    # 渠道成本\n",
    "    channel_login_costs = get_channel_login_costs(channel_type,\n",
    "                                                  com_login_cost, free_login_cost, strong_ctrl_login_cost,\n",
    "                                                  normal_login_cost, no_ctrl_login_cost,\n",
    "                                                  com_login_cnt_per_dau, free_login_cnt_per_dau,\n",
    "                                                  strong_ctrl_login_cnt_per_dau, normal_ctrl_login_cnt_per_dau,\n",
    "                                                  no_ctrl_login_cnt_per_dau,\n",
    "                                                  com_quality_coeff, free_quality_coeff, strong_ctrl_quality_coeff,\n",
    "                                                  normal_ctrl_quality_coeff, no_ctrl_quality_coeff)\n",
    "    \n",
    "    # 用户价值\n",
    "    clv = get_user_clv(clv_pred_1m)\n",
    "\n",
    "    # 贪心优化算法输出贪心解\n",
    "    greedy_result = greedy_solver(target_login_days,\n",
    "                                channel_max_login_days,\n",
    "                                channel_min_login_days,\n",
    "                                channel_login_costs,\n",
    "                                clv)\n",
    "\n",
    "    # 根据用户类型修正渠道分配方案\n",
    "    gmv_year = gmv_year if gmv_year else 0\n",
    "    user_label = priority_type\n",
    "    \n",
    "    final_result = check_user_plan(greedy_result, user_label, target_login_days, year_clv_threshold, gmv_year,clv,\n",
    "                                   month_clv_threshold, a1_threshold,channel_max_adjust, \n",
    "                                   com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                                   normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month,\n",
    "                                   login_cnt_last_month,\n",
    "                                   com_login_cnt_mtd,free_login_cnt_mtd,\n",
    "                                    strong_ctrl_login_cnt_mtd,normal_ctrl_login_cnt_mtd,no_ctrl_login_cnt_mtd,month_hash)\n",
    "    \n",
    "\n",
    "    # 结果最终修正1 不小于上月用户次数  \n",
    "    final_result['com'] = math.ceil(max(final_result['com'],com_login_cnt_last_month))\n",
    "    final_result['free'] = math.ceil(max(final_result['free'],free_login_cnt_last_month))\n",
    "    final_result['strong_ctrl'] = math.ceil(max(final_result['strong_ctrl'],strong_ctrl_login_cnt_last_month))\n",
    "    final_result['no_ctrl'] = math.ceil(max(final_result['no_ctrl'],no_ctrl_login_cnt_last_month))\n",
    "    \n",
    "    # 修正3 处理渠道上限 减掉各渠道mtd值\n",
    "    # 结果最终修正3 减去渠道已完成\n",
    "    final_result['com'] = math.ceil(max(final_result['com'] - com_login_cnt_mtd, 1))\n",
    "    final_result['free'] = math.ceil(max(final_result['free'] - free_login_cnt_mtd, 0))\n",
    "    final_result['strong_ctrl'] = math.ceil(max(final_result['strong_ctrl'] - strong_ctrl_login_cnt_mtd, 0))\n",
    "    final_result['no_ctrl'] = math.ceil(max(final_result['no_ctrl'] - no_ctrl_login_cnt_mtd, 0))\n",
    "    \n",
    "\n",
    "\n",
    "    re = sum(list(final_result.values()))\n",
    "    target_flag = 1 if re >= target_login_days else 0\n",
    "    final_result['flag'] = target_flag\n",
    "\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "def check_user_plan(greedy_result, user_label, target_login_days, year_clv_threshold, gmv_year,clv,\n",
    "                    month_clv_threshold, a1_threshold,channel_max_adjust,\n",
    "                    com_login_cnt_last_month, free_login_cnt_last_month, strong_ctrl_login_cnt_last_month,\n",
    "                    normal_ctrl_login_cnt_last_month, no_ctrl_login_cnt_last_month,\n",
    "                    login_cnt_last_month,\n",
    "                    com_login_cnt_mtd,free_login_cnt_mtd,\n",
    "                    strong_ctrl_login_cnt_mtd,normal_ctrl_login_cnt_mtd,no_ctrl_login_cnt_mtd,month_hash):\n",
    "    \"\"\"根据用户逻辑进行方案调整\n",
    "\n",
    "    Args:\n",
    "        greedy_result (_type_): _description_\n",
    "        user_label (_type_): _description_\n",
    "        target_login_days (_type_): _description_\n",
    "        year_clv_threshold (_type_): _description_\n",
    "        annual_clv_1st (_type_): _description_\n",
    "        clv (_type_): _description_\n",
    "        month_clv_threshold (_type_): _description_\n",
    "        a1_threshold (_type_): _description_\n",
    "        channel_max_adjust (_type_): _description_\n",
    "        com_login_cnt_last_month (_type_): _description_\n",
    "        free_login_cnt_last_month (_type_): _description_\n",
    "        strong_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        normal_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        no_ctrl_login_cnt_last_month (_type_): _description_\n",
    "        natural_pred_login_cnt_n30d (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "   \n",
    "    final_result = greedy_result\n",
    "    year_clv_threshold = 600.0\n",
    "    login_cnt_last_month = login_cnt_last_month if login_cnt_last_month else 5\n",
    "    a1_threshold = 10\n",
    "    user_week_random_num = month_hash\n",
    "\n",
    "    if user_label == 'A1':\n",
    "        pass\n",
    "        # if login_cnt_last_month< a1_threshold:\n",
    "        #     final_result['normal_ctrl'] = math.ceil(normal_ctrl_login_cnt_last_month)\n",
    "        # else:\n",
    "        #     final_result['normal_ctrl'] = 0\n",
    "        \n",
    "        # final_result['com'] = min(int(1.2 * com_login_cnt_last_month),final_result['com'] )\n",
    "\n",
    "    elif user_label == 'A2':\n",
    "        if clv <= month_clv_threshold:\n",
    "            # clv<50, 如果京东可控保量=0 则按月维度抽样（50%+1）\n",
    "            final_result = get_base_plan(greedy_result, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                                         strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month)\n",
    "            if final_result['normal_ctrl']==0 and user_week_random_num< 50:\n",
    "                final_result['normal_ctrl']+=1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    elif user_label == 'B':\n",
    "        final_result = get_base_plan(greedy_result, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                                         strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month)\n",
    "\n",
    "    elif user_label == 'C':\n",
    "        # TODO c人群修正\n",
    "        if gmv_year <= year_clv_threshold:\n",
    "            # 兜底\n",
    "            final_result = get_base_plan(greedy_result, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                                         strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            final_result['normal_ctrl'] = min(20, 1.5 * normal_ctrl_login_cnt_last_month,final_result['normal_ctrl'])\n",
    "    \n",
    "    ## 修正2 可控置零\n",
    "    if user_label == 'A1':\n",
    "        final_result['normal_ctrl'] = 0\n",
    "    else:\n",
    "        final_result['normal_ctrl'] = math.ceil(max(final_result['normal_ctrl'], normal_ctrl_login_cnt_last_month))\n",
    "        final_result['normal_ctrl'] = math.ceil(max(final_result['normal_ctrl'] - normal_ctrl_login_cnt_mtd, 0))\n",
    "\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> get plan pra\n",
      "-----model params-----\n",
      "day_ago_1(table_dt):    2022-05-01\n",
      "this_month_end:         2022-05-31 23:59:59\n",
      "dp(table_dp):           lowv2\n",
      "table_name:             app.app_yhzz_umc_algo_pin_interim\n",
      "month_clv_threshold:    50\n",
      "year_clv_threshold:     1\n",
      "channel_max_adjust:     1.0\n",
      "channel_preference:     [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "a1_threshold:           30\n",
      ">>>>>>>>>> 第一层分配 保量分配逻辑\n",
      ">>>>>>>>>> 第二层分配 动态分配\n",
      ">>>>>>>>>> 二次调控\n",
      ">>>>>>>>>> 数据处理:新增渠道引流登端结果数据列等\n"
     ]
    }
   ],
   "source": [
    "# 获取基础参数\n",
    "\n",
    "day_ago_1 =  '2022-05-01' # T-1\n",
    "dp = 'lowv2' #  [low,medium,high,max]\n",
    "now = datetime.datetime.strptime(day_ago_1, '%Y-%m-%d')\n",
    "day_ago_1 =  datetime.datetime.strptime(day_ago_1, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "now_month = now.month\n",
    "this_month_end = datetime.datetime.strftime(datetime.datetime(now.year, now.month + 1, 1) - timedelta(seconds=1),\n",
    "                                            '%Y-%m-%d %H:%M:%S')\n",
    "table_name = 'app.app_yhzz_umc_algo_pin_interim'\n",
    "\n",
    "# 根据方案档位，获取方案参数\n",
    "print(\">\"*10,\"get plan pra\")\n",
    "a1_threshold = 30\n",
    "month_clv_threshold,  year_clv_threshold, channel_max_adjust, channel_preference = get_plan_pra(plan_level = dp)\n",
    "\n",
    "print('-----model params-----')\n",
    "print('day_ago_1(table_dt):   ', day_ago_1)\n",
    "print('this_month_end:        ', this_month_end)\n",
    "print('dp(table_dp):          ', dp)\n",
    "print('table_name:            ', table_name)\n",
    "print('month_clv_threshold:   ', month_clv_threshold)\n",
    "print('year_clv_threshold:    ', year_clv_threshold)\n",
    "print('channel_max_adjust:    ', channel_max_adjust)\n",
    "print('channel_preference:    ', channel_preference)\n",
    "print('a1_threshold:          ', a1_threshold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 存储参数结果\n",
    "base_data = base_data.withColumn('month_clv_threshold', lit(month_clv_threshold))\n",
    "base_data = base_data.withColumn('year_clv_threshold', lit(year_clv_threshold))\n",
    "base_data = base_data.withColumn('channel_max_adjust', lit(channel_max_adjust))\n",
    "base_data = base_data.withColumn('channel_preference', array([lit(x) for x in channel_preference]))\n",
    "base_data = base_data.withColumn('a1_threshold', lit(a1_threshold))\n",
    "\n",
    "# 第一层分配(保量准则)\n",
    "print(\">\"*10,\"第一层分配 保量分配逻辑\")\n",
    "base_data = base_data.withColumn('guaranteed',get_channel_guaranteed_cnt('com_login_cnt_last_month',\n",
    "                                                                            'free_login_cnt_last_month',\n",
    "                                                                            'strong_ctrl_login_cnt_last_month',\n",
    "                                                                            'normal_ctrl_login_cnt_last_month',\n",
    "                                                                            'no_ctrl_login_cnt_last_month'))\n",
    "# 引流次数\n",
    "base_data = base_data.withColumn('is_guaranteed_by_com', base_data[\"guaranteed\"].getItem(\"com\"))\n",
    "base_data = base_data.withColumn('is_guaranteed_by_free', base_data[\"guaranteed\"].getItem(\"free\"))\n",
    "base_data = base_data.withColumn('is_guaranteed_by_strong_ctrl', base_data[\"guaranteed\"].getItem(\"strong_ctrl\"))\n",
    "base_data = base_data.withColumn('is_guaranteed_by_normal_ctrl', base_data[\"guaranteed\"].getItem(\"normal_ctrl\"))\n",
    "base_data = base_data.withColumn('is_guaranteed_by_no_ctrl', base_data[\"guaranteed\"].getItem(\"no_ctrl\"))\n",
    "\n",
    "# 第二层分配(动态分配)\n",
    "print(\">\"*10,\"第二层分配 动态分配\") \n",
    "base_data = base_data.withColumn('result',get_result('dt','month_clv_threshold','year_clv_threshold','channel_max_adjust',\n",
    "                                                        'channel_preference','a1_threshold','priority_type','my_hash_code',\n",
    "                                                        'lower_lift_login_cnt','natural_pred_login_cnt_rest','login_cnt_mtd','natural_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                                                        'is_acce_by_com','is_acce_by_free','is_acce_by_strong_ctrl',\n",
    "                                                        'is_acce_by_normal_ctrl','is_acce_by_no_ctrl',\n",
    "                                                        'com_max_login_count','free_max_login_count','strong_ctrl_max_login_count',\n",
    "                                                        'normal_ctrl_max_login_count','no_ctrl_max_login_count',\n",
    "                                                        'is_guaranteed_by_com','is_guaranteed_by_free','is_guaranteed_by_strong_ctrl',\n",
    "                                                        'is_guaranteed_by_normal_ctrl','is_guaranteed_by_no_ctrl',\n",
    "                                                        'com_login_cost','free_login_cost','strong_ctrl_login_cost','normal_login_cost',\n",
    "                                                        'no_ctrl_login_cost',\n",
    "                                                        'com_quality_coeff','free_quality_coeff','strong_ctrl_quality_coeff',\n",
    "                                                        'normal_ctrl_quality_coeff','no_ctrl_quality_coeff',\n",
    "                                                        'com_login_cnt_per_dau','free_login_cnt_per_dau',\n",
    "                                                        'strong_ctrl_login_cnt_per_dau','normal_ctrl_login_cnt_per_dau',\n",
    "                                                        'no_ctrl_login_cnt_per_dau',\n",
    "                                                        'clv_pred_1m','gmv_year',\n",
    "                                                        'login_cnt_last_month','natural_login_cnt_last_month','com_login_cnt_last_month','free_login_cnt_last_month','strong_ctrl_login_cnt_last_month','normal_ctrl_login_cnt_last_month','no_ctrl_login_cnt_last_month',\n",
    "                                                        'com_login_cnt_mtd','free_login_cnt_mtd','strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','month_hash'))\n",
    "                                                        # 修正3 处理渠道上限 减掉各渠道mtd值\n",
    "\n",
    "print(\">\"*10,\"二次调控\") \n",
    "# TODO 二次调控代码\n",
    "\n",
    "print(\">\"*10,\"数据处理:新增渠道引流登端结果数据列等\")\n",
    "base_data = add_channel_result_col(data = base_data,\n",
    "                                    this_month_end = this_month_end)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o506.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 6 times, most recent failure: Lost task 0.5 in stage 3.0 (TID 1210, BJHTYD-Hope-11-11-21-4.hadoop.jd.local, executor 50): java.io.IOException: Cannot run program \"/usr/local/anaconda3//bin/python\": error=2, No such file or directory\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:197)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:126)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:105)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:125)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1500)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: error=2, No such file or directory\n\tat java.lang.UNIXProcess.forkAndExec(Native Method)\n\tat java.lang.UNIXProcess.<init>(UNIXProcess.java:247)\n\tat java.lang.ProcessImpl.start(ProcessImpl.java:134)\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)\n\t... 37 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2187)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2136)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2135)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2135)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1069)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1069)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1069)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2367)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2316)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2305)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:880)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2186)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2283)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1086)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1068)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1490)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1477)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3397)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3378)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:81)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:128)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:76)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3377)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2772)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:262)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:299)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Cannot run program \"/usr/local/anaconda3//bin/python\": error=2, No such file or directory\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:197)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:126)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:105)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:125)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1500)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.io.IOException: error=2, No such file or directory\n\tat java.lang.UNIXProcess.forkAndExec(Native Method)\n\tat java.lang.UNIXProcess.<init>(UNIXProcess.java:247)\n\tat java.lang.ProcessImpl.start(ProcessImpl.java:134)\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)\n\t... 37 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-32668c41b16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# print(sql)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/servers/hope/mart_sch/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o506.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 6 times, most recent failure: Lost task 0.5 in stage 3.0 (TID 1210, BJHTYD-Hope-11-11-21-4.hadoop.jd.local, executor 50): java.io.IOException: Cannot run program \"/usr/local/anaconda3//bin/python\": error=2, No such file or directory\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:197)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:126)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:105)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:125)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1500)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: error=2, No such file or directory\n\tat java.lang.UNIXProcess.forkAndExec(Native Method)\n\tat java.lang.UNIXProcess.<init>(UNIXProcess.java:247)\n\tat java.lang.ProcessImpl.start(ProcessImpl.java:134)\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)\n\t... 37 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2187)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2136)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2135)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2135)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1069)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1069)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1069)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2367)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2316)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2305)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:880)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2186)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2283)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1086)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1068)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1490)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1477)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3397)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3378)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:81)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:128)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:76)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3377)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2772)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:262)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:299)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Cannot run program \"/usr/local/anaconda3//bin/python\": error=2, No such file or directory\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:197)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:126)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:829)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:352)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:316)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:105)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:125)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1500)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.io.IOException: error=2, No such file or directory\n\tat java.lang.UNIXProcess.forkAndExec(Native Method)\n\tat java.lang.UNIXProcess.<init>(UNIXProcess.java:247)\n\tat java.lang.ProcessImpl.start(ProcessImpl.java:134)\n\tat java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)\n\t... 37 more\n"
     ]
    }
   ],
   "source": [
    "base_data.createOrReplaceTempView('result_data_tmp')\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "    --  代码重构验数\n",
    "    SELECT\n",
    "        priority_type, \n",
    "        sum(com_login_cnt) as com_login_cnt,\n",
    "        sum(free_login_cnt) as free_login_cnt,\n",
    "        sum(strong_ctrl_login_cnt) as strong_ctrl_login_cnt,\n",
    "        sum(normal_ctrl_login_cnt) as normal_ctrl_login_cnt,\n",
    "        sum(no_ctrl_login_cnt) as no_ctrl_login_cnt\n",
    "    FROM\n",
    "        result_data_tmp\n",
    "    GROUP BY\n",
    "    priority_type\n",
    "    ORDER BY\n",
    "    priority_type\n",
    "\"\"\"\n",
    "# print(sql)\n",
    "result = spark.sql(sql)\n",
    "result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrafficAllocation():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    @staticmethod    \n",
    "    @udf(IntegerType())\n",
    "    def BasicGuarantee(base_plan):\n",
    "        base_plan = 1\n",
    "        return base_plan\n",
    "    \n",
    "    @staticmethod\n",
    "    @udf(IntegerType())\n",
    "    def BusinessSupplement(self):\n",
    "        yewu_plan = 1\n",
    "        return yewu_plan\n",
    "    \n",
    "    @staticmethod\n",
    "    @udf(IntegerType())\n",
    "    def GreedySolver(val):\n",
    "        val += 1\n",
    "        return val\n",
    "    \n",
    "    def get_allocation_result(self):\n",
    "        # 基础保量方案\n",
    "        self.data = self.data.withColumn('test', self.BasicGuarantee(col('com_base_cnt')))\n",
    "        \n",
    "        # 补量\n",
    "        # 动态调控\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = TrafficAllocation(test_data)\n",
    "func.get_allocation_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_threshold = 30\n",
    "month_clv_threshold = 130\n",
    "year_clv_threshold = 50 \n",
    "channel_max_adjust=1.2 \n",
    "channel_preference=[1,1,1,1,1]\n",
    "\n",
    "class TrafficAllocation():\n",
    "    \"\"\"流量分配函数, 包含基础保量、业务补量以及贪心阶跃算法\n",
    "    \"\"\"\n",
    "    def __init__(self,a1_threshold):\n",
    "        self.a1_threshold = a1_threshold\n",
    "    \n",
    "    def get_target_allocation_login(self,part_dt,lift_login, natura_login, current_login,no_ctrl_login):\n",
    "        \n",
    "        today =datetime.datetime.strptime(part_dt,'%Y-%m-%d') + timedelta(days=1)\n",
    "        if today.day==1: \n",
    "            # 每月1号方案需要对当前登录次数置零\n",
    "            current_login = min(current_login,0)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        return lift_login - current_login - natura_login - no_ctrl_login\n",
    "        \n",
    "        \n",
    "    def BasicGuarantee(self, user_lastmonth_channel_login):\n",
    "        \n",
    "        user_lastmonth_channel_login = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "        user_channel_basicguaranteed = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "        \n",
    "        for channel_name in user_lastmonth_channel_login:\n",
    "            print(channel_name)\n",
    "            user_channel_basicguaranteed[channel_name] = max(math.ceil(user_lastmonth_channel_login[channel_name]),0)\n",
    "        \n",
    "        return user_channel_basicguaranteed\n",
    "    \n",
    "    def BusinessRuleSupplement(self, base_plan, user_type, my_hash_code, user_month_hash,\n",
    "                                com_login_cnt_last_month, free_login_cnt_last_month, \n",
    "                                strong_ctrl_login_cnt_last_month, normal_ctrl_login_cnt_last_month, \n",
    "                                no_ctrl_login_cnt_last_month,\n",
    "                                com_login_cnt_mtd, free_login_cnt_mtd, strong_ctrl_login_cnt_mtd, \n",
    "                                normal_ctrl_login_cnt_mtd, no_ctrl_login_cnt_mtd\n",
    "                                user_month_clv):\n",
    "        \"\"\"业务补量有三个操作, 渠道置零、加量、不超过某上限\n",
    "        \"\"\"\n",
    "        businessrule_no_allocation_channel = []\n",
    "        businessrule_plan = base_plan\n",
    "        channel_businessrule_max = {'com': 0, 'free': 0, 'strong_ctrl': 0, 'normal_ctrl': 0, 'no_ctrl': 0}\n",
    "        user_lastmonth_channel_login = {'com': com_login_cnt_last_month, \n",
    "                                        'free': free_login_cnt_last_month, \n",
    "                                        'strong_ctrl': strong_ctrl_login_cnt_last_month, \n",
    "                                        'normal_ctrl': normal_ctrl_login_cnt_last_month, \n",
    "                                        'no_ctrl': no_ctrl_login_cnt_last_month}\n",
    "\n",
    "\n",
    "        if user_type== 'A1':\n",
    "            com_adjust_pra = 1.2\n",
    "            hash_precent = 28\n",
    "            msg_add = 1\n",
    "        \n",
    "            # 京东可控置0 \n",
    "            businessrule_no_allocation_channel.append('normal_ctrl')\n",
    "            # 商业化渠道补量#A1人群的商业化补量不超过20%\n",
    "            # 商业化在上月基础上调整1.2倍的抽样分配结果 \n",
    "            com_adjust_day = sampling_supplement(channel_days = user_lastmonth_channel_login['com'],\n",
    "                                                 adjust_day = com_adjust_pra * user_lastmonth_channel_login['com'], # 1.2\n",
    "                                                 my_hash_code = my_hash_code)\n",
    "            # A1人群的商业化补量不超过20%\n",
    "            channel_businessrule_max['com'] = com_adjust_day \n",
    "            # 免费渠道补量\n",
    "            businessrule_plan['free'] +=1 \n",
    "            # 短信渠道补量\n",
    "            if (my_hash_code<= hash_precent):\n",
    "                businessrule_plan['strong_ctrl'] += msg_add\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        elif user_type=='A2':\n",
    "            month_clv_threshold = 50 \n",
    "            \n",
    "            if user_month_clv <= month_clv_threshold:\n",
    "                # clv<50, 如果京东可控保量=0 则按月维度抽样（50%+1）\n",
    "                businessrule_plan = get_base_plan(businessrule_plan, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                                            strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month)\n",
    "            # 可控为0则 50%概率+1    \n",
    "            if businessrule_plan['normal_ctrl'] == 0 and user_month_hash < 50:\n",
    "                    businessrule_plan['normal_ctrl'] += 1\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        elif user_type =='B':\n",
    "            businessrule_plan = get_base_plan(businessrule_plan, com_login_cnt_last_month,free_login_cnt_last_month,\n",
    "                                         strong_ctrl_login_cnt_last_month,normal_ctrl_login_cnt_last_month,no_ctrl_login_cnt_last_month)\n",
    "        \n",
    "        elif user_type=='C':\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        return businessrule_plan\n",
    " \n",
    "    def GreedySolver(self):\n",
    "        print(self.val)\n",
    "        self.val += 1\n",
    "        return int(self.val)\n",
    "    \n",
    "@udf(IntegerType())\n",
    "def get_allocation_result(lower_lift_login_cnt,natural_login_cnt_last_month,no_ctrl_login_cnt_last_month,\n",
    "                          login_cnt_mtd,natural_login_cnt_mtd, no_ctrl_login_cnt_mtd):\n",
    "    \n",
    "    func = TrafficAllocation(channel_max_adjust)\n",
    "    \n",
    "    # 基础保量方案\n",
    "    basic_plan = func.BasicGuarantee()\n",
    "    \n",
    "    # 业务补量\n",
    "    business_plan = func.BusinessSupplement(basic_plan)\n",
    "    \n",
    "    # 贪心阶跃\n",
    "    greedy_plan = func.GreedySolver(business_plan)\n",
    "    \n",
    "    # 数据校验\n",
    "    finnal_plan = greedy_plan\n",
    "    \n",
    "    return finnal_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_supplement(channel_days,adjust_day,my_hash_code):\n",
    "    \"\"\"按随机抽样的方法对渠道天数进行修正，\n",
    "       举例说明: \n",
    "       假设该渠道有100人, 渠道干预次数默认值为2, 总干预次数为200\n",
    "       整体干预次数要提升1.2倍即240, 则每个人的渠道干预次数为2.4, \n",
    "       干预次数按照抽样方式调整, 所有人干预次数调整为2, 40%的人在2的基础上再增加1次, 保证整体的干预次数是调整了1.2倍\n",
    "\n",
    "    Args:\n",
    "        channel_days (_type_): 渠道干预天数\n",
    "        adjust_day (double): 需要调整的天数\n",
    "        my_hash_code (string): 用户hash值, 用于抽样\n",
    "        base_flag (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: 调整后的渠道干预天数\n",
    "    \"\"\"\n",
    "\n",
    "    adjust_day = adjust_day * 100 # 2.4\n",
    "    \n",
    "    adjust_day_base , adjust_day_hash_add = adjust_day//100 , int(adjust_day%100)\n",
    "    \n",
    "    # print(adjust_day_base , adjust_day_hash_add)\n",
    "    channel_days = adjust_day_base # 2\n",
    "    \n",
    "    if my_hash_code <= adjust_day_hash_add: # 0.4\n",
    "        channel_days += 1\n",
    "    \n",
    "    return channel_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n",
      "| id|Age|Gender|\n",
      "+---+---+------+\n",
      "|  1| 10|     F|\n",
      "|  2|  2|     M|\n",
      "+---+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l =[(1,   10   ,  'F')\n",
    ",(2 ,   2   ,  'M')\n",
    ",(2 ,  10  ,   'F')\n",
    ",(2 ,  3  ,    'F')\n",
    ",(3 ,  10,     'M')]\n",
    "columns = ['id',  'Age',  'Gender']\n",
    "df=spark.createDataFrame(l, columns)\n",
    "df.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('test',get_allocation_result('id','Age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----+\n",
      "| id|Age|Gender|test|\n",
      "+---+---+------+----+\n",
      "|  1| 10|     F|   2|\n",
      "|  2|  2|     M|   2|\n",
      "+---+---+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com', 'free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "businessrule_no_allocation_channel = []\n",
    "channel_type = ['com','free', 'strong_ctrl', 'normal_ctrl', 'no_ctrl']\n",
    "businessrule_no_allocation_channel+=channel_type\n",
    "businessrule_no_allocation_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessrule_no_allocation_channel.append('no_ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'no_ctrl' in businessrule_no_allocation_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二次调控梳理\n",
    "T为首日,day为现在的时间\n",
    "* 判断当前时间选择的调控方式（当前高活）\n",
    "    * day = T ，直接跑首日分配逻辑\n",
    "    * 高活 （day-T）是3的倍数 重跑首日分配\n",
    "    * 高活  （day-T）== 7 渠道内调控\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-3ac120340dd4>\", line 1, in <module>\n",
      "    @udf(returnType=MapType(StringType(), IntegerType()))\n",
      "NameError: name 'udf' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2016, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/local/anaconda3/lib/python3.6/posixpath.py\", line 376, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-05-15'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_day = '2022-05-16'\n",
    "first_allocation_day = datetime.datetime.strptime('2022-05-15','%Y-%m-%d')\n",
    "run_day = datetime.datetime.strptime(run_day,'%Y-%m-%d')\n",
    "day1_ago_runday = datetime.datetime.strftime(run_day- timedelta(days=1),'%Y-%m-%d')\n",
    "day1_ago_runday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6%3 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juge_how_allocation(run_day, base_data):\n",
    "    \n",
    "    # TODO 5月临时方案 修改为整体方案\n",
    "    first_allocation_day = datetime.datetime.strptime('2022-05-15','%Y-%M-%d')\n",
    "    run_day = datetime.datetime.strptime(run_day,'%Y-%M-%d')\n",
    "    day1_ago_runday = datetime.datetime.strftime(run_day- timedelta(days=1),'%Y-%M-%d')\n",
    "    \n",
    "    delta_day = (run_day-first_allocation_day).days\n",
    "    \n",
    "    if delta_day == 0:\n",
    "        #  首日分配\n",
    "        print(\">\"*10,\"进行首日分配\") \n",
    "        final_data = base_data.withColumn('result',get_allocation_result('dt','month_clv_threshold','year_clv_threshold','channel_max_adjust',\n",
    "                                                         'channel_preference','a1_threshold','priority_type','my_hash_code',\n",
    "                                                         'lower_lift_login_cnt','natural_pred_login_cnt_rest','login_cnt_mtd','natural_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                                                         'is_acce_by_com','is_acce_by_free','is_acce_by_strong_ctrl',\n",
    "                                                         'is_acce_by_normal_ctrl','is_acce_by_no_ctrl',\n",
    "                                                         'com_max_login_count','free_max_login_count','strong_ctrl_max_login_count',\n",
    "                                                         'normal_ctrl_max_login_count','no_ctrl_max_login_count',\n",
    "                                                         'com_login_cost','free_login_cost','strong_ctrl_login_cost','normal_login_cost',\n",
    "                                                         'no_ctrl_login_cost',\n",
    "                                                         'com_quality_coeff','free_quality_coeff','strong_ctrl_quality_coeff',\n",
    "                                                         'normal_ctrl_quality_coeff','no_ctrl_quality_coeff',\n",
    "                                                         'com_login_cnt_per_dau','free_login_cnt_per_dau',\n",
    "                                                         'strong_ctrl_login_cnt_per_dau','normal_ctrl_login_cnt_per_dau',\n",
    "                                                         'no_ctrl_login_cnt_per_dau',\n",
    "                                                         'clv_pred_1m','gmv_year',\n",
    "                                                         'login_cnt_last_month','natural_login_cnt_last_month','com_login_cnt_last_month','free_login_cnt_last_month','strong_ctrl_login_cnt_last_month','normal_ctrl_login_cnt_last_month','no_ctrl_login_cnt_last_month',\n",
    "                                                         'com_login_cnt_mtd','free_login_cnt_mtd','strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','month_hash'))\n",
    "\n",
    "    elif delta_day%3 == 0:\n",
    "        # TODO 高活和低活的调整周期不一样 现在只写了高活\n",
    "        # 3日-高活 渠道内调整 执行首日分配算法\n",
    "        print(\">\"*10,\"进行高活用户 渠道内调整\") \n",
    "        final_data = base_data.withColumn('result',get_allocation_result('dt','month_clv_threshold','year_clv_threshold','channel_max_adjust',\n",
    "                                                         'channel_preference','a1_threshold','priority_type','my_hash_code',\n",
    "                                                         'lower_lift_login_cnt','natural_pred_login_cnt_rest','login_cnt_mtd','natural_login_cnt_mtd','no_ctrl_login_cnt_mtd',\n",
    "                                                         'is_acce_by_com','is_acce_by_free','is_acce_by_strong_ctrl',\n",
    "                                                         'is_acce_by_normal_ctrl','is_acce_by_no_ctrl',\n",
    "                                                         'com_max_login_count','free_max_login_count','strong_ctrl_max_login_count',\n",
    "                                                         'normal_ctrl_max_login_count','no_ctrl_max_login_count',\n",
    "                                                         'com_login_cost','free_login_cost','strong_ctrl_login_cost','normal_login_cost',\n",
    "                                                         'no_ctrl_login_cost',\n",
    "                                                         'com_quality_coeff','free_quality_coeff','strong_ctrl_quality_coeff',\n",
    "                                                         'normal_ctrl_quality_coeff','no_ctrl_quality_coeff',\n",
    "                                                         'com_login_cnt_per_dau','free_login_cnt_per_dau',\n",
    "                                                         'strong_ctrl_login_cnt_per_dau','normal_ctrl_login_cnt_per_dau',\n",
    "                                                         'no_ctrl_login_cnt_per_dau',\n",
    "                                                         'clv_pred_1m','gmv_year',\n",
    "                                                         'login_cnt_last_month','natural_login_cnt_last_month','com_login_cnt_last_month','free_login_cnt_last_month','strong_ctrl_login_cnt_last_month','normal_ctrl_login_cnt_last_month','no_ctrl_login_cnt_last_month',\n",
    "                                                         'com_login_cnt_mtd','free_login_cnt_mtd','strong_ctrl_login_cnt_mtd','normal_ctrl_login_cnt_mtd','month_hash'))\n",
    "   \n",
    "    elif (delta_day==7) or (delta_day-7)%6==0:\n",
    "        # TODO 无渠道间调整\n",
    "        # 7日 监控期，然后高活6d周期 渠道间调整\n",
    "        print(\">\"*10,\"进行高活用户 渠道间调整\") \n",
    "        lastday_data = get_lastday_data_no_allocation(dp, day1_ago_runday)\n",
    "        final_data = lastday_data\n",
    "    \n",
    "    elif delta_day%3 > 0:\n",
    "        # 非首日 非调控期 取昨日分区减去昨日已完成\n",
    "        print(\">\"*10,\"非首日，非调控期，取昨日分区减去昨日已完成\") \n",
    "        lastday_data = get_lastday_data_no_allocation(dp, day1_ago_runday)\n",
    "        final_data = lastday_data\n",
    "    \n",
    "    return final_data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lastday_data_no_allocation(part_dp, part_dt):\n",
    "    \n",
    "    used_sql = \"\"\"\n",
    "        SELECT\n",
    "            user_log_acct,\n",
    "            user_life_cycle_type_1st,\n",
    "            model_a_1st,\n",
    "            model_b_1st,\n",
    "            goal_group_1st,\n",
    "            annual_clv_1st,\n",
    "            grid_name_1st,\n",
    "            clv_pred_1m,\n",
    "            model_a,\n",
    "            model_b,\n",
    "            model_c,\n",
    "            model_l,\n",
    "            user_life_cycle_type,\n",
    "            login_cnt_mtd,\n",
    "            natural_login_cnt_mtd,\n",
    "            com_login_cnt_mtd,\n",
    "            free_login_cnt_mtd,\n",
    "            strong_ctrl_login_cnt_mtd,\n",
    "            normal_ctrl_login_cnt_mtd,\n",
    "            no_ctrl_login_cnt_mtd,\n",
    "            com_user_last_month_login_cnt,\n",
    "            free_user_last_month_login_cnt,\n",
    "            strong_ctrl_user_last_month_login_cnt,\n",
    "            normal_ctrl_user_last_month_login_cnt,\n",
    "            no_ctrl_user_last_month_login_cnt,\n",
    "            com_user_base_guarteed_cnt,\n",
    "            free_user_base_guarteed_cnt,\n",
    "            strong_ctrl_user_base_guarteed_cnt,\n",
    "            normal_ctrl_user_base_guarteed_cnt,\n",
    "            no_ctrl_user_base_guarteed_cnt,\n",
    "            com_user_acce_flag,\n",
    "            free_user_acce_flag,\n",
    "            strong_ctrl_user_acce_flag,\n",
    "            normal_ctrl_user_acce_flag,\n",
    "            no_ctrl_user_acce_flag,\n",
    "            com_grid_max_login_cnt,\n",
    "            free_grid_max_login_cnt,\n",
    "            strong_ctrl_grid_max_login_cnt,\n",
    "            normal_ctrl_grid_max_login_cnt,\n",
    "            no_ctrl_grid_max_login_cnt,\n",
    "            com_grid_last_month_total_cnt,\n",
    "            free_grid_last_month_total_cnt,\n",
    "            strong_ctrl_grid_last_month_total_cnt,\n",
    "            normal_ctrl_grid_last_month_total_cnt,\n",
    "            no_ctrl_grid_last_month_total_cnt,\n",
    "            com_grid_quality_coeff,\n",
    "            free_grid_quality_coeff,\n",
    "            strong_ctrl_grid_quality_coeff,\n",
    "            normal_ctrl_grid_quality_coeff,\n",
    "            no_ctrl_grid_quality_coeff,\n",
    "            com_grid_login_cnt_per_dau,\n",
    "            free_grid_login_cnt_per_dau,\n",
    "            strong_ctrl_grid_login_cnt_per_dau,\n",
    "            normal_grid_login_cnt_per_dau,\n",
    "            no_ctrl_grid_login_cnt_per_dau,\n",
    "            com_grid_last_login_cost,\n",
    "            free_grid_last_login_cost,\n",
    "            strong_ctrl_grid_last_login_cost,\n",
    "            normal_ctrl_grid_last_login_cost,\n",
    "            no_ctrl_grid_last_login_cost,\n",
    "            algo_total_info,\n",
    "            natural_pred_login_cnt_rest,\n",
    "            case when (com_login_cnt - com_login_cnt_mtd)>=0 then (com_login_cnt - com_login_cnt_mtd)\n",
    "                else 0 end as com_login_cnt,\n",
    "            case when (free_login_cnt - free_login_cnt_mtd)>=0 then (free_login_cnt - free_login_cnt_mtd)\n",
    "                else 0 end as free_login_cnt,\n",
    "            case when (strong_ctrl_login_cnt - strong_ctrl_login_cnt_mtd)>=0 then (strong_ctrl_login_cnt - strong_ctrl_login_cnt_mtd)\n",
    "                else 0 end as strong_ctrl_login_cnt,\n",
    "            case when (normal_ctrl_login_cnt - normal_ctrl_login_cnt_mtd)>=0 then (normal_ctrl_login_cnt - normal_ctrl_login_cnt_mtd)\n",
    "                else 0 end as normal_ctrl_login_cnt,\n",
    "            case when (no_ctrl_login_cnt - no_ctrl_login_cnt_mtd)>=0 then (no_ctrl_login_cnt - no_ctrl_login_cnt_mtd)\n",
    "                else 0 end as no_ctrl_login_cnt,\n",
    "            priority_level,\n",
    "            pred_com_dau,\n",
    "            pred_free_dau,\n",
    "            pred_strong_ctrl_dau,\n",
    "            pred_normal_ctrl_dau,\n",
    "            pred_no_ctrl_dau,\n",
    "            total_login_dau_ratio,\n",
    "            pred_total_dau,\n",
    "            case when (com_login_cnt + free_login_cnt + strong_ctrl_login_cnt + normal_ctrl_login_cnt + no_ctrl_login_cnt)>= (lower_lift_login_cnt-login_cnt_mtd) then 1\n",
    "                else 0 end as is_solvable,\n",
    "            end_time,\n",
    "            is_malice_user,\n",
    "            pred_natural_dau,\n",
    "            priority_type\n",
    "        FROM \n",
    "            app.app_yhzz_umc_algo_pin_interim\n",
    "        where \n",
    "            dt = '{part_dt}'\n",
    "            and dp ='{part_dp}'\n",
    "        )interim \n",
    "        left join\n",
    "        \n",
    "        (\n",
    "        select\n",
    "        -- 目标登录次数\n",
    "        grid_name_1st,\n",
    "            COALESCE(lower_lift_login_cnt,0) as lower_lift_login_cnt\n",
    "\n",
    "        FROM\n",
    "            app.app_yhzz_umc_unit_grid\n",
    "        WHERE\n",
    "            dt = '{part_dt}'\n",
    "            AND grid_name_1st is not null\n",
    "            AND is_grid_valid = 1\n",
    "        )grid on interim.grid_name_1st  = grid.grid_name_1st\n",
    "\n",
    "    \"\"\".format(part_dt = part_dt, part_dp = part_dp)\n",
    "    \n",
    "    print(\"get lastday data sql\", used_sql)\n",
    "    data = spark.sql(used_sql)\n",
    "    data.cache()\n",
    "    print(\"data columns\", data.columns)\n",
    "    print(\"data dtypes\", data.dtypes)\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-06-01'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_month_firstday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本月首日为 2022-06-01 00:00:00\n",
      "分区为 2022-06-01\n",
      "计划执行日期为 2022-06-02 00:00:00\n",
      "the delta_day is 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 运行分区\n",
    "run_day = '2022-06-01' \n",
    "# 分配计划执行时间 = 运行分区 + 1\n",
    "plan_day = datetime.datetime.strptime(run_day,'%Y-%m-%d') - timedelta(days=- 1)\n",
    "plan_year = plan_day.year\n",
    "plan_month = plan_day.month\n",
    "\n",
    "# 获取每月首日分配方案时间   \n",
    "if plan_month== 5 and run_day < '2022-05-30':\n",
    "    # 5月是05-15分区 ，05-16开始执行\n",
    "    first_allocation_day = datetime.datetime.strptime('2022-05-16','%Y-%m-%d')\n",
    "    \n",
    "else:\n",
    "    # 其他是每月第一天\n",
    "    run_month_firstday = datetime.datetime.strftime(datetime.datetime(plan_year, plan_month, 1),'%Y-%m-%d')  \n",
    "    first_allocation_day = datetime.datetime.strptime(run_month_firstday,'%Y-%m-%d')\n",
    "\n",
    "\n",
    "day1_ago_runday = datetime.datetime.strftime(datetime.datetime.strptime(run_day,'%Y-%m-%d') - timedelta(days=1),'%Y-%m-%d')\n",
    "delta_day = (plan_day -first_allocation_day).days\n",
    "plan_flag = \"none\"\n",
    "\n",
    "\n",
    "print(\"本月首日为\", first_allocation_day)\n",
    "print(\"分区为\",run_day)\n",
    "print(\"计划执行日期为\",plan_day)\n",
    "print(\"the delta_day is\",delta_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-113"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datetime.datetime.strptime(run_day,'%Y-%M-%d') -first_allocation_day).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 22, 0, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime(run_day,'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelcols_to_channeldict(col1, col2, col3, col4, col5):\n",
    "    \n",
    "    cols_list = [col1, col2, col3, col4, col5]\n",
    "    cols_dicts = dict(zip(channel_type,cols_list))\n",
    "    \n",
    "    return cols_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'com': 1, 'free': 2, 'strong_ctrl': 3, 'normal_ctrl': 4, 'no_ctrl': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_type = [\"com\", \"free\", \"strong_ctrl\", \"normal_ctrl\", \"no_ctrl\"]\n",
    "channelcols_to_channeldict(channel_type, 1 ,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(sql_file, 'r') as f:\n",
    "    used_sql = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'udf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-17f7bf8fdf2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mglobal_var1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mglobal_var1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'udf' is not defined"
     ]
    }
   ],
   "source": [
    "global_var1 = 100\n",
    "@udf\n",
    "def f1(x1):\n",
    "    return x1 + global_var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'free': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'free':0}\n",
    "businessrule_plan = test\n",
    "businessrule_plan['free'] +=  1 \n",
    "businessrule_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_plan_list = np.zeros((31, 6))\n",
    "day_plan_list[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_select_natural =np.ones((1, 30))\n",
    "day_select_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, -1, 23, 13,  5, 27, 25,  4,  7,  3, 22, 17, 21, 16, 19, 14, 15,\n",
       "       11,  1,  2, 20,  0,  8,  9, 28, 10, 12, 24,  6, 29])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_natural = np.stack(day_select_natural.astype('int64'))\n",
    "idx_natural-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_plan_list[:,0]\n",
    "## 次数是31次的结果为什么只有第一条是1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_probability_2=np.array([[0.10335037,0.03985507,0.17425432,0.,0.07294118,0.138833]\n",
    "                   ,[0.18270869,0.07246377,0.27629513,0.,0.13176471,0.17303823]\n",
    ",[0.2423339,0.09299517,0.34850863,0.66666667,0.17529412,0.19315895]\n",
    ",[0.29386712,0.12801932,0.42543171,0.66666667,0.21882353,0.21830986]\n",
    ",[0.33333333,0.14009662,0.44270016,0.66666667,0.24235294,0.25251509]\n",
    ",[0.36825667,0.15942029,0.48508634,0.66666667,0.27176471,0.2806841]\n",
    ",[0.39664963,0.1884058,0.52904239,0.66666667,0.29882353,0.31187123]\n",
    ",[0.42887564,0.20652174,0.57299843,0.66666667,0.32352941,0.34104628]\n",
    ",[0.45528109,0.24275362,0.58712716,0.66666667,0.35882353,0.36217304]\n",
    ",[0.48495173,0.26570048,0.59654631,0.66666667,0.39529412,0.37927565]\n",
    ",[0.50695627,0.29227053,0.60753532,0.66666667,0.43058824,0.40744467]\n",
    ",[0.5330778,0.32850242,0.62166405,0.66666667,0.45294118,0.42454728]\n",
    ",[0.5552243,0.34057971,0.64207221,0.66666667,0.49058824,0.44567404]\n",
    ",[0.57637706,0.36594203,0.67503925,0.66666667,0.50941176,0.4668008,]\n",
    ",[0.59923339,0.39492754,0.69387755,0.66666667,0.54823529,0.51509054]\n",
    ",[0.63202726,0.43719807,0.71742543,0.66666667,0.57529412,0.54225352]\n",
    ",[0.6568711,0.45289855,0.74568289,0.66666667,0.59882353,0.56237425]\n",
    ",[0.67915957,0.48309179,0.76609105,0.66666667,0.63176471,0.57344064]\n",
    ",[0.7044293,0.51328502,0.77708006,0.66666667,0.67647059,0.59356137]\n",
    ",[0.7245883,0.53864734,0.79905808,0.66666667,0.70117647,0.61267606]\n",
    ",[0.75014196,0.55555556,0.82103611,0.66666667,0.71764706,0.63782696]\n",
    ",[0.7673197,0.58333333,0.82574568,0.66666667,0.73764706,0.65291751]\n",
    ",[0.79358319,0.62801932,0.83830455,0.66666667,0.76,0.67102616]\n",
    ",[0.82027257,0.67270531,0.84929356,0.66666667,0.78352941,0.69919517]\n",
    ",[0.84085747,0.7089372,0.8744113,0.66666667,0.81294118,0.73038229]\n",
    ",[0.86697899,0.74516908,0.88540031,0.66666667,0.82823529,0.75653924]\n",
    ",[0.89040318,0.79589372,0.91522763,0.66666667,0.86588235,0.79476861]\n",
    ",[0.91993186,0.85024155,0.95290424,0.66666667,0.89411765,0.85412475]\n",
    ",[0.93796139,0.90700483,0.96546311,0.66666667,0.91529412,0.8943662]\n",
    ",[0.96919364,0.96497585,0.97645212,0.66666667,0.95294118,0.95171026]\n",
    ",[1.,1.,1.,1.,1.,1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed_natural = np.random.rand(1,20)\n",
    "# 分配结果微调\n",
    "def create_uniques(arr):\n",
    "    unq,c = np.unique(arr,return_counts=1)\n",
    "\n",
    "    m = np.isin(arr,unq[c>1])\n",
    "\n",
    "    newvals = np.setdiff1d(np.arange(31),arr[~m])\n",
    "    np.random.shuffle(newvals)\n",
    "    \n",
    "    cnt = m.tolist().count(True)\n",
    "    newvals = newvals[:cnt]\n",
    "    arr[m] = newvals\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    # 将随机数和累积分布挨个对比，概率大的那天区间也大，被选中的概率自然大\n",
    "    for j in cum_probability_2[:,0]:\n",
    "        if j >=  rand_seed_natural[0,i]: \n",
    "            day_select_natural[0,i] = cum_probability_2[:,0].tolist().index(j)+1\n",
    "            break\n",
    "# 微调，作用是若有的天被分配大于1次，则将这天重新打散分配，用create_uniques函数\n",
    "day_select_natural = create_uniques(np.array(day_select_natural[0]).astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27,  0, 24, 14,  6, 28, 26,  5,  8,  4, 23, 18, 22, 17, 20, 15, 16,\n",
       "       12,  2,  3, 21,  1,  9, 10, 29, 11, 13, 25,  7, 30])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_select_natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43840969, 0.85466365, 0.30925827, 0.790468  , 0.18639407,\n",
       "        0.60621843, 0.88316462, 0.10326071, 0.82266334, 0.84382056]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros(31)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in [1,2,3]:\n",
    "   # print(i)\n",
    "    test[i] =1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[1,2,3]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_type = ['natural','com','free','jd_strong_ctrl', 'jd_normal_ctrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_type.index('com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-a6b23c2a7235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mday_cnt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'natural'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "day_cnt_dict = {'natural',[0]*31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-07-04'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_ago_1 =  '2022-07-01' # T-1\n",
    "\n",
    "\n",
    "now = datetime.datetime.strptime(day_ago_1, '%Y-%m-%d')\n",
    "day_ago_1 =  datetime.datetime.strptime(day_ago_1, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "day_ago_3 = datetime.datetime.strftime(now - timedelta(days=-3),'%Y-%m-%d')\n",
    "day_ago_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
