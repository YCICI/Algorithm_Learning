# 01基础知识

## 1.2 RDD基础概念

### 什么是RDD？

RDD 是构建 Spark 分布式内存计算引擎的基石，很多 Spark 核心概念与核心组件。

无论采用哪种 API 或是哪种开发语言，你的应用在 Spark 内部最终都会转化为 RDD 之上的分布式计算。

把 RDD 看作是数组，通过对比 RDD 与数组之间的差异认识一下 RDD。

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20dd9251dc3ec549f0920b49c62d6a4a08/Untitled.png)

在数组中，承载数据的基本单元是元素，而 RDD 中承载数据的基本单元是数据分片。在分布式计算环境中，一份完整的数据集，会按照某种规则切割成多份数据分片。这些数据分片被均匀地分发给集群内不同的计算节点和执行进程，从而实现分布式并行计算。

数据分片（Partitions）是 RDD 抽象的重要属性之一。

### RDD 4 大属性

- partitions：数据分片
- partitioner：分片切割规则
- dependencies：RDD 依赖
- compute：转换函数

### 编程模型与延迟计算

RDD了解数据形态和数据形态之间的转化。

**数据形态：**RDD 是 Spark 对于分布式数据集的抽象，每一个 RDD 都代表着一种分布式数据形态。比如 lineRDD，它表示数据在集群中以行（Line）的形式存在；而 wordRDD 则意味着数据的形态是单词，分布在计算集群中。

数据形态转换：RDD 到 RDD 之间的转换，本质上是数据形态上的转换（Transformations）。

而数据形容转换的过程，一般有两种算子，Transformations 类算子和 Actions 类算子。

1、开发者需要使用 Transformations 类算子，定义并描述数据形态的转换过程，

2、然后调用 Actions 类算子，将计算结果收集起来、或是物化到磁盘。

在这样的编程模型下，Spark 在运行时的计算被划分为两个环节。基于不同数据形态之间的转换，构建计算流图（DAG，Directed Acyclic Graph）；通过 Actions 类算子，以回溯的方式去触发执行这个计算流图。

常用算子的类型如下：

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Untitled%201.png)

## 1.3 ****RDD常用算子（一）：RDD内部的数据转换****map、mapPartitions、flatMap、filter

重点讲解 map、mapPartitions、flatMap、filter

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Untitled%202.png)

### **创建 RDD**

在 Spark 中，创建 RDD 的典型方式有两种：

方式一，通过 SparkContext.parallelize 在内部数据之上创建 RDD；

方式二、通过 SparkContext.textFile 等 API 从外部数据创建 RDD。

其实是自定义数据和外部读取，可以从pandas的库理解，自定义dataframe和读取excel、读取csv、txt、excel。

方式一示例：parallelize API 的典型用法，是在“小数据”之上创建 RDD。

```scala
import org.apache.spark.rdd.RDD
val words: Array[String] = Array("Spark", "is", "cool")
val rdd: RDD[String] = sc.parallelize(words)
```

方式二示例：大数据的话，还是通过 SparkContext.textFile 等 API 从外部数据创建 RDD。

```scala
import org.apache.spark.rdd.RDD
val rootPath: String = _
val file: String = s"${rootPath}/wikiOfSpark.txt"// 读取文件内容
val lineRDD: RDD[String] = spark.sparkContext.textFile(file)
```

### Map算子：以元素粒度为算子

map 算子的用法：给定映射函数 f，map(f) 以元素为粒度对 RDD 做数据转换。

map的使用分为两种方式，一种是匿名函数，一种是自定义函数，使用函数名称

```scala
// 把RDD元素转换为（Key，Value）的形式
// 匿名函数
val kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word => (word, 1))

// 自定义函数
// 定义映射函数f
def f(word: String): (String, Int) = {
return (word, 1)
}
val kvRDD: RDD[(String, Int)] = cleanWordRDD.map(f)
```

map(f) 是以元素为粒度对 RDD 做数据转换的，在某些计算场景下，这个特点会严重影响执行效率。

因此有了按照分区来执行map的数据转换函数，mapPartitions 和 mapPartitionsWithIndex

### mapPartitions：以数据分区为粒度的数据转换

### flatMap：从元素到集合、再从集合到元素

flatMap 也是用来做数据映射的，在实现上，对于给定映射函数 f，flatMap(f) 以元素为粒度，对 RDD 进行数据转换。

flatMap 的映射函数 f 有着显著的不同。对于 map 和 mapPartitions 来说，其映射函数 f 的类型，都是（元素） => （元素），即元素到元素。而 flatMap 映射函数 f 的类型，是（元素） => （集合），即元素到集合（如数组、列表等）。

因此，flatMap 的映射过程在逻辑上分为两步：以元素为单位，创建集合；去掉集合“外包装”，提取集合元素。

示例代码：

```scala

// 以行为单位提取相邻单词
val wordPairRDD: RDD[String] = lineRDD.flatMap( line => {
  // 将行转换为单词数组
  val words: Array[String] = line.split(" ")
  // 将单个单词数组，转换为相邻单词数组
  for (i <- 0 until words.length - 1) yield words(i) + "-" + words(i+1)
})
```

for 循环返回的依然是数组，也即类型为 Array[String]的词对数组。由此可见，函数 f 的类型是（String） => （Array[String]），也就是刚刚说的第一步，从元素到集合。

map、mapPartitions的转化过程都是元素到元素。

流程图示：

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Untitled%203.png)

### filter：过滤 RDD

对 RDD 进行过滤。和 map 算子依赖其映射函数一样，filter 算子也需要借助一个判定函数 f，才能实现对 RDD 的过滤转换。

上面 flatMap 例子的最后，我们得到了元素为相邻词汇对的 wordPairRDD，它包含的是像“Spark-is”、“is-cool”这样的字符串。为了仅保留有意义的词对元素，我们希望结合标点符号列表，对 wordPairRDD 进行过滤。例如，我们希望过滤掉像“Spark-&”、“|-data”这样的词对。

```scala
// 定义特殊字符列表
val list: List[String] = List("&", "|", "#", "^", "@")
 
// 定义判定函数f
def f(s: String): Boolean = {
val words: Array[String] = s.split("-")
val b1: Boolean = list.contains(words(0))
val b2: Boolean = list.contains(words(1))
return !b1 && !b2 // 返回不在特殊字符列表中的词汇对
}
 
// 使用filter(f)对RDD进行过滤
val cleanedPairRDD: RDD[String] = wordPairRDD.filter(f)
```

## 1.3 ****进程模型与分布式部署****

分布式计算的精髓，在于如何把抽象的计算流图，转化为实实在在的分布式计算任务，然后以并行计算的方式交付执行。

### 进程模型

在 Spark 分布式计算环境中，有且仅有一个 JVM 进程运行这样的 main 函数，这个特殊的 JVM 进程，在 Spark 中有个专门的术语，叫作“Driver”。

Driver：分配任务，解析用户代码、构建计算流图，然后将计算流图转化为分布式任务，并把任务分发给集群中的执行进程交付运行。

Executor：执行任务，执行进程。

在 Spark 的 Driver 进程中，DAGScheduler、TaskScheduler 和 SchedulerBackend 这三个对象通力合作，依次完成分布式任务调度的 3 个核心步骤，也就是：

1. 根据用户代码构建计算流图；

2. 根据计算流图拆解出分布式任务；

3. 将分布式任务分发到 Executors 中去。

### spark-shell过程解析

当我们把 Word Count 的示例代码依次敲入到 spark-shell 中，Driver 进程和 3 个 Executors 进程之间是如何通力合作来执行分布式任务的。

图示：

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Untitled%204.png)

1、首先，Driver 通过 take 这个 Action 算子，来触发执行先前构建好的计算流图。沿着计算流图的执行方向，也就是图中从上到下的方向，Driver 以 Shuffle 为边界创建、分发分布式任务。Shuffle 的本意是扑克牌中的“洗牌”，在大数据领域的引申义，表示的是集群范围内跨进程、跨节点的数据交换。

*`我们在专栏后续的内容中会对 Shuffle 做专门的讲解，这里我们不妨先用 Word Count 的例子，来简单地对 Shuffle 进行理解。在 reduceByKey 算子之前，同一个单词，比如“spark”，可能散落在不用的 Executors 进程，比如图中的 Executor-0、Executor-1 和 Executor-2。换句话说，这些 Executors 处理的数据分片中，都包含单词“spark”。那么，要完成对“spark”的计数，我们需要把所有“spark”分发到同一个 Executor 进程，才能完成计算。而这个把原本散落在不同 Executors 的单词，分发到同一个 Executor 的过程，就是 Shuffle。`*

2、对于 reduceByKey 之前的所有操作，也就是 textFile、flatMap、filter、map 等，Driver 会把它们“捏合”成一份任务，然后一次性地把这份任务打包、分发给每一个 Executors。三个 Executors 接收到任务之后，先是对任务进行解析，把任务拆解成 textFile、flatMap、filter、map 这 4 个步骤，然后分别对自己负责的数据分片进行处理。

为了方便说明，我们不妨假设并行度为 3，也就是原始数据文件 wikiOfSpark.txt 被切割成了 3 份，这样每个 Executors 刚好处理其中的一份。数据处理完毕之后，分片内容就从原来的 RDD[String]转换成了包含键值对的 RDD[(String, Int)]，其中每个单词的计数都置位 1。

3、此时 Executors 会及时地向 Driver 汇报自己的工作进展，从而方便 Driver 来统一协调大家下一步的工作。这个时候，要继续进行后面的聚合计算，也就是计数操作，就必须进行刚刚说的 Shuffle 操作。在不同 Executors 完成单词的数据交换之后，Driver 继续创建并分发下一个阶段的任务，也就是按照单词做分组计数。数据交换之后，所有相同的单词都分发到了相同的 Executors 上去，这个时候，各个 Executors 拿到 reduceByKey 的任务，只需要各自独立地去完成统计计数即可。完成计数之后，Executors 会把最终的计算结果统一返回给 Driver。

## 1.4 ****分布式计算的精髓****

分布式计算的精髓，在于如何把抽象的计算图，转化为实实在在的分布式计算任务，然后以并行计算的方式交付执行。

### 核心组件及分工

![Untitled](01%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Untitled%205.png)